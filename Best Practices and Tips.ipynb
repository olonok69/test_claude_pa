{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a7587a-b9b6-4d69-a20b-c70b71b33ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/3039328626124250', creation_time=1755624146266, experiment_id='3039328626124250', last_update_time=1755875139361, lifecycle_stage='active', name='/Users/j.huertas@closerstillmedia.com/prophet', tags={'mlflow.databricks.filesystem.experiment_permissions_check': 'test',\n",
       " 'mlflow.experiment.sourceName': '/Users/j.huertas@closerstillmedia.com/prophet',\n",
       " 'mlflow.experimentKind': 'custom_model_development',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'b.relf@closerstillmedia.com',\n",
       " 'mlflow.ownerId': '7931383772120950'}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "experiment_name = \"/Users/j.huertas@closerstillmedia.com/prophet\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    print(\"experiment exists\")\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454202d1-a730-4f70-8a10-726563a10e42",
   "metadata": {},
   "source": [
    "# Data Preparation Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518d3e4f-5fdb-43fe-b5e3-f225d4c4fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prophet_data(data, date_col, value_col, freq=\"D\"):\n",
    "    \"\"\"\n",
    "    Prepare data for Prophet training.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame with time series data\n",
    "        date_col: Name of date column\n",
    "        value_col: Name of value column\n",
    "        freq: Frequency of the time series\n",
    "    \"\"\"\n",
    "\n",
    "    # Prophet requires columns named 'ds' (datestamp) and 'y' (value)\n",
    "    prophet_df = data[[date_col, value_col]].copy()\n",
    "    prophet_df.columns = [\"ds\", \"y\"]\n",
    "\n",
    "    # Ensure ds is datetime\n",
    "    prophet_df[\"ds\"] = pd.to_datetime(prophet_df[\"ds\"])\n",
    "\n",
    "    # Sort by date\n",
    "    prophet_df = prophet_df.sort_values(\"ds\").reset_index(drop=True)\n",
    "\n",
    "    # Handle missing dates if needed\n",
    "    if freq:\n",
    "        full_date_range = pd.date_range(\n",
    "            start=prophet_df[\"ds\"].min(), end=prophet_df[\"ds\"].max(), freq=freq\n",
    "        )\n",
    "\n",
    "        # Reindex to fill missing dates\n",
    "        prophet_df = prophet_df.set_index(\"ds\").reindex(full_date_range).reset_index()\n",
    "        prophet_df.columns = [\"ds\", \"y\"]\n",
    "\n",
    "        # Log data quality metrics\n",
    "        missing_dates = prophet_df[\"y\"].isna().sum()\n",
    "        print(f\"Missing dates filled: {missing_dates}\")\n",
    "\n",
    "    return prophet_df\n",
    "\n",
    "def prophet_data_best_practices():\n",
    "    \"\"\"Demonstrate Prophet data preparation best practices.\"\"\"\n",
    "\n",
    "    best_practices = {\n",
    "        \"data_frequency\": \"Use consistent frequency (daily, weekly, monthly)\",\n",
    "        \"missing_values\": \"Prophet handles missing values, but document them\",\n",
    "        \"outliers\": \"Consider outlier detection and handling\",\n",
    "        \"data_volume\": \"Minimum 2-3 seasonal cycles (2-3 years for yearly seasonality)\",\n",
    "        \"column_names\": \"Always use 'ds' for dates and 'y' for values\",\n",
    "        \"date_format\": \"Ensure dates are properly parsed as datetime\",\n",
    "        \"timezone_handling\": \"Be consistent with timezone handling\",\n",
    "    }\n",
    "\n",
    "    print(\"Prophet Data Preparation Best Practices:\")\n",
    "    for practice, description in best_practices.items():\n",
    "        print(f\"- {practice}: {description}\")\n",
    "\n",
    "    return best_practices\n",
    "\n",
    "\n",
    "# Data validation function\n",
    "def validate_prophet_data(df):\n",
    "    \"\"\"Validate data for Prophet modeling.\"\"\"\n",
    "\n",
    "    issues = []\n",
    "    recommendations = []\n",
    "\n",
    "    # Check required columns\n",
    "    if not all(col in df.columns for col in [\"ds\", \"y\"]):\n",
    "        issues.append(\"Missing required columns 'ds' and/or 'y'\")\n",
    "\n",
    "    # Check data types\n",
    "    if \"ds\" in df.columns and not pd.api.types.is_datetime64_any_dtype(df[\"ds\"]):\n",
    "        issues.append(\"Column 'ds' is not datetime type\")\n",
    "        recommendations.append(\n",
    "            \"Convert 'ds' to datetime: df['ds'] = pd.to_datetime(df['ds'])\"\n",
    "        )\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if len(df) < 100:\n",
    "        issues.append(f\"Insufficient data points: {len(df)} (recommend >100)\")\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_y = df[\"y\"].isnull().sum()\n",
    "    if missing_y > 0:\n",
    "        recommendations.append(f\"Consider handling {missing_y} missing values in 'y'\")\n",
    "\n",
    "    # Check for duplicate dates\n",
    "    if \"ds\" in df.columns:\n",
    "        duplicates = df[\"ds\"].duplicated().sum()\n",
    "        if duplicates > 0:\n",
    "            issues.append(f\"Found {duplicates} duplicate dates\")\n",
    "\n",
    "    # Check data range\n",
    "    if \"ds\" in df.columns and len(df) > 0:\n",
    "        date_range = (df[\"ds\"].max() - df[\"ds\"].min()).days\n",
    "        if date_range < 365:\n",
    "            recommendations.append(\n",
    "                \"Less than 1 year of data may limit seasonality detection\"\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"issues\": issues,\n",
    "        \"recommendations\": recommendations,\n",
    "        \"data_points\": len(df),\n",
    "        \"date_range_days\": date_range if \"ds\" in df.columns and len(df) > 0 else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "# Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5afc5d9d-3aba-4741-9466-d3a72962f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dates filled: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds     y\n",
       "0 2021-01-01   941\n",
       "1 2021-01-02  1157\n",
       "2 2021-01-03  1149\n",
       "3 2021-01-04   944\n",
       "4 2021-01-05  1071"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data =  pd.read_csv(\"sales_data_2023_2025_v3.csv\")\n",
    "df = prepare_prophet_data(raw_data, 'date', 'sales', freq='D')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00afd526-fbc4-4fe9-8ec6-b20eeac65112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: {'issues': [], 'recommendations': [], 'data_points': 1826, 'date_range_days': 1825}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation_results = validate_prophet_data(df)\n",
    "print(\"Validation Results:\", validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60cf5b2-dd9b-4dbd-a773-b5db29fb4208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: {'issues': [], 'recommendations': ['Less than 1 year of data may limit seasonality detection'], 'data_points': 100, 'date_range_days': 99}\n"
     ]
    }
   ],
   "source": [
    "validation_results = validate_prophet_data(df[:100])\n",
    "print(\"Validation Results:\", validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f6eb13-dd48-4868-91d4-27a69af0e7e6",
   "metadata": {},
   "source": [
    "# Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f6c6619-de05-45ef-abd7-170bb255e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_prophet_performance():\n",
    "    \"\"\"Tips for optimizing Prophet performance.\"\"\"\n",
    "\n",
    "    optimization_tips = {\n",
    "        \"parallel_processing\": {\n",
    "            \"cross_validation\": \"Use parallel='threads' or 'processes' in cross_validation()\",\n",
    "            \"multiple_models\": \"Use joblib.Parallel for training multiple models\",\n",
    "        },\n",
    "        \"model_configuration\": {\n",
    "            \"mcmc_samples\": \"Set mcmc_samples=0 for faster MAP estimation\",\n",
    "            \"uncertainty_samples\": \"Reduce uncertainty_samples for faster predictions\",\n",
    "            \"stan_backend\": \"Use 'CMDSTANPY' backend for better performance\",\n",
    "        },\n",
    "        \"data_preprocessing\": {\n",
    "            \"frequency\": \"Aggregate to appropriate frequency (daily vs hourly)\",\n",
    "            \"outliers\": \"Remove extreme outliers before training\",\n",
    "            \"data_size\": \"Consider sampling for very large datasets\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return optimization_tips\n",
    "\n",
    "\n",
    "# Example of parallel cross-validation\n",
    "def parallel_prophet_evaluation(models_dict, df):\n",
    "    \"\"\"Evaluate multiple Prophet models in parallel.\"\"\"\n",
    "\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    def evaluate_single_model(name, model):\n",
    "        try:\n",
    "            cv_results = cross_validation(\n",
    "                model.fit(df),\n",
    "                initial=\"365 days\",\n",
    "                period=\"90 days\",\n",
    "                horizon=\"30 days\",\n",
    "                parallel=\"threads\",\n",
    "            )\n",
    "            metrics = performance_metrics(cv_results)\n",
    "            return name, metrics[\"mape\"].mean()\n",
    "        except Exception as e:\n",
    "            return name, float(\"inf\")\n",
    "\n",
    "    # Parallel evaluation\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(evaluate_single_model)(name, model)\n",
    "        for name, model in models_dict.items()\n",
    "    )\n",
    "\n",
    "    return dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc7bf4-17ae-4651-8af8-5a3c5c0b46e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
