{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "929c26c6-f5ad-4528-9ecc-bdec85a15be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NATS Image Consumer Configuration:\n",
      "NATS URL: nats://localhost:4222\n",
      "Tagging Stream: IMAGE-RESULTS-TAGGER\n",
      "Tagging Subject: tagger.results.completed.>\n",
      "Captioning Stream: IMAGE-RESULTS-CAPTIONING\n",
      "Captioning Subject: caption.results.completed.>\n",
      "Local Environment: 1\n",
      "Output Directory: output_images\n",
      "  - Tagging Results: output_images/tagging\n",
      "  - Captioning Results: output_images/captioning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import nats\n",
    "from nats.js.api import StreamConfig, RetentionPolicy, DiscardPolicy\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(os.path.join(\"keys\", \".env\"))\n",
    "\n",
    "# NATS connection settings\n",
    "NAT_URL = os.getenv(\"NAT_URL\", \"nats://localhost:4222\")\n",
    "\n",
    "# Get mode-specific stream and subject settings - use the new separated streams\n",
    "INPUT_STREAM_TAGGER = os.getenv(\"INPUT_STREAM_TAGGER\", \"IMAGE-TASKS-TAGGER\")\n",
    "INPUT_SUBJECT_TAGGER = os.getenv(\"INPUT_SUBJECT_TAGGER\", \"tagger.tasks.started.>\")\n",
    "\n",
    "INPUT_STREAM_CAPTIONING = os.getenv(\"INPUT_STREAM_CAPTIONING\", \"IMAGE-TASKS-CAPTIONING\")\n",
    "INPUT_SUBJECT_CAPTIONING = os.getenv(\"INPUT_SUBJECT_CAPTIONING\", \"caption.tasks.started.>\") \n",
    "\n",
    "LOCAL_ENV = os.getenv(\"LOCAL_ENV\", \"1\")\n",
    "\n",
    "# Display current configuration\n",
    "print(\"NATS Image Producer Configuration:\")\n",
    "print(f\"NATS URL: {NAT_URL}\")\n",
    "print(f\"Tagging Stream: {INPUT_STREAM_TAGGER}\")\n",
    "print(f\"Tagging Subject: {INPUT_SUBJECT_TAGGER}\")\n",
    "print(f\"Captioning Stream: {INPUT_STREAM_CAPTIONING}\")\n",
    "print(f\"Captioning Subject: {INPUT_SUBJECT_CAPTIONING}\")\n",
    "print(f\"Local Environment: {LOCAL_ENV}\")\n",
    "\n",
    "# Input directory for images\n",
    "INPUT_DIR = \"images_local\"\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca3b8a1-90aa-419e-9fb7-36a7db17fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_results(data, mode=\"auto\"):\n",
    "    \"\"\"\n",
    "    Analyze image processing results from a single result\n",
    "\n",
    "    Args:\n",
    "        data: The result data to analyze\n",
    "        mode: Processing mode - \"tagging\", \"captioning\", or \"auto\" (detect)\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to analyze\")\n",
    "        return\n",
    "\n",
    "    # Extract the data section from the result\n",
    "    documents = data.get(\"data\", [])\n",
    "\n",
    "    if not documents:\n",
    "        print(\"No documents found in result\")\n",
    "        return\n",
    "\n",
    "    # Detect mode if set to auto\n",
    "    if mode == \"auto\":\n",
    "        # Check the first document's content format to determine the mode\n",
    "        if documents and \"source\" in documents[0]:\n",
    "            content = documents[0][\"source\"].get(\"content\", [])\n",
    "            # If content is a list of dictionaries with 'label' and 'confidence', it's tagging\n",
    "            if isinstance(content, list) and content and isinstance(content, list):\n",
    "                if content and isinstance(content[0], dict) and \"label\" in content[0] and \"confidence\" in content[0]:\n",
    "                    mode = \"tagging\"\n",
    "                # If content is a list of strings, it's captioning\n",
    "                elif content and isinstance(content[0], str):\n",
    "                    mode = \"captioning\"\n",
    "                else:\n",
    "                    mode = \"unknown\"\n",
    "\n",
    "    print(f\"Analyzing results in {mode.upper()} mode\")\n",
    "\n",
    "    # Analyze based on detected or specified mode\n",
    "    if mode == \"tagging\":\n",
    "        analyze_tagging_results(documents)\n",
    "    elif mode == \"captioning\":\n",
    "        analyze_captioning_results(documents)\n",
    "    else:\n",
    "        print(f\"Unknown result format - cannot analyze\")\n",
    "\n",
    "\n",
    "def analyze_tagging_results(documents):\n",
    "    \"\"\"Analyze image tagging results\"\"\"\n",
    "    total_documents = len(documents)\n",
    "    total_tags = 0\n",
    "    tags_by_confidence = {}\n",
    "\n",
    "    for document in documents:\n",
    "        # Extract source information for display\n",
    "        source_info = document.get(\"source\", {})\n",
    "        file_name = source_info.get(\"file_name\", \"unknown\")\n",
    "\n",
    "        print(f\"\\nDocument: {document.get('id', 'unknown')}\")\n",
    "        print(f\"File: {file_name}\")\n",
    "\n",
    "        # Extract tags/labels\n",
    "        tags = source_info.get(\"content\", [])\n",
    "        total_tags += len(tags)\n",
    "\n",
    "        # Display tags with confidence\n",
    "        if tags:\n",
    "            print(\"\\nTags:\")\n",
    "            for tag in tags:\n",
    "                label = tag.get(\"label\", \"unknown\")\n",
    "                confidence = tag.get(\"confidence\", 0)\n",
    "\n",
    "                # Group tags by confidence level\n",
    "                confidence_level = round(confidence * 10) / 10  # Round to 1 decimal\n",
    "                if confidence_level in tags_by_confidence:\n",
    "                    tags_by_confidence[confidence_level].append(label)\n",
    "                else:\n",
    "                    tags_by_confidence[confidence_level] = [label]\n",
    "\n",
    "                print(f\"  - {label}: {confidence:.4f}\")\n",
    "        else:\n",
    "            print(\"No tags found for this document\")\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total documents analyzed: {total_documents}\")\n",
    "    print(f\"Total tags found: {total_tags}\")\n",
    "    print(\"\\nTags by confidence level:\")\n",
    "    for confidence, tags in sorted(tags_by_confidence.items(), key=lambda x: x[0], reverse=True):\n",
    "        print(f\"  Confidence {confidence:.1f}: {len(tags)} tags\")\n",
    "        if confidence >= 0.5:  # Only show high confidence tags in summary\n",
    "            tag_list = \", \".join(tags)\n",
    "            print(f\"    Tags: {tag_list}\")\n",
    "\n",
    "\n",
    "def analyze_captioning_results(documents):\n",
    "    \"\"\"Analyze image captioning results\"\"\"\n",
    "    total_documents = len(documents)\n",
    "\n",
    "    print(f\"\\nCAPTIONING RESULTS\")\n",
    "    print(f\"Total documents analyzed: {total_documents}\")\n",
    "\n",
    "    for document in documents:\n",
    "        # Extract source information for display\n",
    "        source_info = document.get(\"source\", {})\n",
    "        file_name = source_info.get(\"file_name\", \"unknown\")\n",
    "\n",
    "        print(f\"\\nDocument: {document.get('id', 'unknown')}\")\n",
    "        print(f\"File: {file_name}\")\n",
    "\n",
    "        # Extract caption/description\n",
    "        captions = source_info.get(\"content\", [])\n",
    "\n",
    "        # Display captions\n",
    "        if captions:\n",
    "            print(\"\\nCaption:\")\n",
    "            for caption in captions:\n",
    "                print(f\"  {caption}\")\n",
    "        else:\n",
    "            print(\"No caption found for this document\")\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Processed {total_documents} image(s) with the captioning model\")\n",
    "\n",
    "\n",
    "def visualize_top_tags(data, max_tags=10):\n",
    "    \"\"\"Create a simple visualization of top tags from the data\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    # Extract the data section from the result\n",
    "    documents = data.get(\"data\", [])\n",
    "\n",
    "    if not documents:\n",
    "        return\n",
    "\n",
    "    # Check if this is tagging data\n",
    "    if not documents or \"source\" not in documents[0]:\n",
    "        print(\"No tagging data to visualize\")\n",
    "        return\n",
    "\n",
    "    # Get first document to check content format\n",
    "    first_doc = documents[0]\n",
    "    content = first_doc.get(\"source\", {}).get(\"content\", [])\n",
    "\n",
    "    # Check if this is tagging data\n",
    "    if not content or not isinstance(content, list) or not isinstance(content[0], dict) or \"label\" not in content[0]:\n",
    "        print(\"This appears to be captioning data, not tagging data - no visualization available\")\n",
    "        return\n",
    "\n",
    "    # Collect all tags with their confidences\n",
    "    tag_counts = {}\n",
    "\n",
    "    for document in documents:\n",
    "        tags = document.get(\"source\", {}).get(\"content\", [])\n",
    "\n",
    "        for tag in tags:\n",
    "            label = tag.get(\"label\", \"unknown\")\n",
    "            confidence = tag.get(\"confidence\", 0)\n",
    "\n",
    "            if label in tag_counts:\n",
    "                tag_counts[label] = max(tag_counts[label], confidence)  # Keep highest confidence\n",
    "            else:\n",
    "                tag_counts[label] = confidence\n",
    "\n",
    "    # Sort by confidence and get top tags\n",
    "    top_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:max_tags]\n",
    "\n",
    "    if not top_tags:\n",
    "        print(\"No tags to visualize\")\n",
    "        return\n",
    "\n",
    "    # Create visualization\n",
    "    labels = [tag[0] for tag in top_tags]\n",
    "    confidences = [tag[1] for tag in top_tags]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(labels, confidences, color='skyblue')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.title('Top Tags by Confidence')\n",
    "    plt.xlim(0, 1.0)\n",
    "    plt.gca().invert_yaxis()  # Highest confidence at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f42134-0aba-4dc8-aad9-1a03297b7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def publish_images_to_nats(\n",
    "    folder_path, \n",
    "    nats_url=NAT_URL,\n",
    "    mode=\"tagging\",\n",
    "    local_env=LOCAL_ENV,\n",
    "    num_labels=5,\n",
    "    prompt=\"OD\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Publish all image files from a folder to the NATS input stream/subject.\n",
    "\n",
    "    Args:\n",
    "        folder_path: Path to the folder containing image files to process\n",
    "        nats_url: The NATS server URL\n",
    "        mode: Processing mode (\"tagging\" or \"captioning\")\n",
    "        local_env: Local environment flag\n",
    "        num_labels: Number of labels to return for each image (for tagging)\n",
    "        prompt: Prompt for Florence-2 model (\"OD\" or \"MORE_DETAILED_CAPTION\")\n",
    "    \"\"\"\n",
    "    # Check if folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"Folder not found: {folder_path}\")\n",
    "\n",
    "    # Determine the appropriate stream and subject based on mode\n",
    "    if mode == \"tagging\":\n",
    "        input_stream = INPUT_STREAM_TAGGER\n",
    "        input_subject = INPUT_SUBJECT_TAGGER\n",
    "    else:  # mode == \"captioning\"\n",
    "        input_stream = INPUT_STREAM_CAPTIONING\n",
    "        input_subject = INPUT_SUBJECT_CAPTIONING\n",
    "\n",
    "    print(f\"Using mode: {mode}, stream: {input_stream}, subject: {input_subject}, prompt: {prompt}\")\n",
    "\n",
    "    # Ensure the appropriate stream exists with the subject\n",
    "    await ensure_stream_exists(\n",
    "        nats_url=nats_url,\n",
    "        stream_name=input_stream,\n",
    "        subjects=[input_subject]\n",
    "    )\n",
    "\n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "\n",
    "    # Track files published\n",
    "    files_published = []\n",
    "\n",
    "    try:\n",
    "        # Process each image file in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            # Filter for common image file extensions\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                print(f\"Processing image file: {filename}\")\n",
    "\n",
    "                try:\n",
    "                    # Create a temporary HTTP server URL or file URL\n",
    "                    # For local testing, we'll use file:// URLs\n",
    "                    if local_env == \"1\":\n",
    "                        # Using absolute path for file:// URLs\n",
    "                        abs_path = os.path.abspath(file_path)\n",
    "                        uri = f\"file://{abs_path}\"\n",
    "                    else:\n",
    "                        # In production, this might be an HTTP URL\n",
    "                        uri = f\"file://{file_path}\"\n",
    "\n",
    "                    # Create message payload\n",
    "                    message = {\n",
    "                        \"source\": {\n",
    "                            \"uri\": uri,\n",
    "                            \"type\": \"image\"\n",
    "                        },\n",
    "                        \"state\": {\n",
    "                            \"status\": \"STARTED\",\n",
    "                            \"timestamp\": datetime.now().isoformat()\n",
    "                        },\n",
    "                        \"prompt\": prompt\n",
    "                    }\n",
    "\n",
    "                    # Add num_labels only for tagging mode\n",
    "                    if mode == \"tagging\":\n",
    "                        message[\"num_labels\"] = num_labels\n",
    "\n",
    "                    # Create message headers with filename\n",
    "                    headers = {\n",
    "                        \"filename\": filename\n",
    "                    }\n",
    "\n",
    "                    # Publish message to input subject in the appropriate stream\n",
    "                    await js.publish(\n",
    "                        input_subject, \n",
    "                        json.dumps(message).encode(), \n",
    "                        headers=headers,\n",
    "                        stream=input_stream\n",
    "                    )\n",
    "\n",
    "                    print(f\"Published file {filename} to {input_subject} in stream {input_stream}\")\n",
    "                    files_published.append(filename)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "\n",
    "    return files_published\n",
    "\n",
    "async def process_folder_with_mode(folder_path, mode=\"tagging\", num_labels=5, prompt=None):\n",
    "    \"\"\"\n",
    "    Publish all image files in the folder to NATS with specified mode\n",
    "\n",
    "    Args:\n",
    "        folder_path: Path to folder containing images\n",
    "        mode: \"tagging\" or \"captioning\"\n",
    "        num_labels: Number of labels for tagging mode\n",
    "        prompt: Override the default prompt (if None, will use mode-appropriate default)\n",
    "    \"\"\"\n",
    "    # Set default prompt based on mode if not provided\n",
    "    if prompt is None:\n",
    "        if mode == \"tagging\":\n",
    "            prompt = \"OD\"\n",
    "        else:  # mode == \"captioning\"\n",
    "            prompt = \"MORE_DETAILED_CAPTION\"\n",
    "\n",
    "    print(f\"Publishing image files from {folder_path} to NATS using {mode} mode...\")\n",
    "    files_published = await publish_images_to_nats(\n",
    "        folder_path, \n",
    "        mode=mode, \n",
    "        num_labels=num_labels, \n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    if files_published:\n",
    "        print(f\"\\nPublished {len(files_published)} files to NATS\")\n",
    "        print(\"Files published:\")\n",
    "        for file in files_published:\n",
    "            print(f\"- {file}\")\n",
    "    else:\n",
    "        print(\"No files were published to NATS\")\n",
    "\n",
    "    return files_published\n",
    "\n",
    "\n",
    "async def process_folder_both_modes(folder_path, num_labels=5):\n",
    "    \"\"\"\n",
    "    Publish all image files in the folder to both tagging and captioning streams\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to folder containing images\n",
    "        num_labels: Number of labels for tagging mode\n",
    "    \"\"\"\n",
    "    print(f\"Publishing image files from {folder_path} to both tagging and captioning streams...\")\n",
    "    \n",
    "    # First process with tagging mode\n",
    "    tagging_files = await process_folder_with_mode(\n",
    "        folder_path, \n",
    "        mode=\"tagging\", \n",
    "        num_labels=num_labels, \n",
    "        prompt=\"OD\"\n",
    "    )\n",
    "    \n",
    "    # Then process with captioning mode\n",
    "    captioning_files = await process_folder_with_mode(\n",
    "        folder_path, \n",
    "        mode=\"captioning\", \n",
    "        prompt=\"MORE_DETAILED_CAPTION\"\n",
    "    )\n",
    "    \n",
    "    # Combine unique files from both modes\n",
    "    all_files = list(set(tagging_files + captioning_files))\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total files published: {len(all_files)}\")\n",
    "    print(f\"Files published to tagging stream: {len(tagging_files)}\")\n",
    "    print(f\"Files published to captioning stream: {len(captioning_files)}\")\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d0eec6-88d8-49ab-bf38-a1b73be4dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing image files from images_local to NATS using tagging mode...\n",
      "Using mode: tagging, stream: IMAGE-TASKS-TAGGER, subject: tagger.tasks.started.>, prompt: OD\n",
      "Stream 'IMAGE-TASKS-TAGGER' already exists with subjects: ['tagger.tasks.started.>']\n",
      "Processing image file: 2Persons.jpg\n",
      "Published file 2Persons.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: baseball.jpg\n",
      "Published file baseball.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: beach.jpg\n",
      "Published file beach.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: buildings.jpg\n",
      "Published file buildings.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: buterfly.jpg\n",
      "Published file buterfly.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: cow.jpg\n",
      "Published file cow.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: download.png\n",
      "Published file download.png to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: forest.jpg\n",
      "Published file forest.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: road.jpg\n",
      "Published file road.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: shrek.jpg\n",
      "Published file shrek.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: van.jpg\n",
      "Published file van.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "Processing image file: woman.jpg\n",
      "Published file woman.jpg to tagger.tasks.started.> in stream IMAGE-TASKS-TAGGER\n",
      "\n",
      "Published 12 files to NATS\n",
      "Files published:\n",
      "- 2Persons.jpg\n",
      "- baseball.jpg\n",
      "- beach.jpg\n",
      "- buildings.jpg\n",
      "- buterfly.jpg\n",
      "- cow.jpg\n",
      "- download.png\n",
      "- forest.jpg\n",
      "- road.jpg\n",
      "- shrek.jpg\n",
      "- van.jpg\n",
      "- woman.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2Persons.jpg',\n",
       " 'baseball.jpg',\n",
       " 'beach.jpg',\n",
       " 'buildings.jpg',\n",
       " 'buterfly.jpg',\n",
       " 'cow.jpg',\n",
       " 'download.png',\n",
       " 'forest.jpg',\n",
       " 'road.jpg',\n",
       " 'shrek.jpg',\n",
       " 'van.jpg',\n",
       " 'woman.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. For tagging mode (using dedicated stream)\n",
    "await process_folder_with_mode(INPUT_DIR, mode=\"tagging\", num_labels=5, prompt=\"OD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a65f6c-93b3-48f5-9aaa-1dbcd06023cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing image files from images_local to NATS using captioning mode...\n",
      "Using mode: captioning, stream: IMAGE-TASKS-CAPTIONING, subject: caption.tasks.started.>, prompt: MORE_DETAILED_CAPTION\n",
      "Stream 'IMAGE-TASKS-CAPTIONING' already exists with subjects: ['caption.tasks.started.>']\n",
      "Processing image file: 2Persons.jpg\n",
      "Published file 2Persons.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: baseball.jpg\n",
      "Published file baseball.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: beach.jpg\n",
      "Published file beach.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: buildings.jpg\n",
      "Published file buildings.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: buterfly.jpg\n",
      "Published file buterfly.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: cow.jpg\n",
      "Published file cow.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: download.png\n",
      "Published file download.png to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: forest.jpg\n",
      "Published file forest.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: road.jpg\n",
      "Published file road.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: shrek.jpg\n",
      "Published file shrek.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: van.jpg\n",
      "Published file van.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "Processing image file: woman.jpg\n",
      "Published file woman.jpg to caption.tasks.started.> in stream IMAGE-TASKS-CAPTIONING\n",
      "\n",
      "Published 12 files to NATS\n",
      "Files published:\n",
      "- 2Persons.jpg\n",
      "- baseball.jpg\n",
      "- beach.jpg\n",
      "- buildings.jpg\n",
      "- buterfly.jpg\n",
      "- cow.jpg\n",
      "- download.png\n",
      "- forest.jpg\n",
      "- road.jpg\n",
      "- shrek.jpg\n",
      "- van.jpg\n",
      "- woman.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2Persons.jpg',\n",
       " 'baseball.jpg',\n",
       " 'beach.jpg',\n",
       " 'buildings.jpg',\n",
       " 'buterfly.jpg',\n",
       " 'cow.jpg',\n",
       " 'download.png',\n",
       " 'forest.jpg',\n",
       " 'road.jpg',\n",
       " 'shrek.jpg',\n",
       " 'van.jpg',\n",
       " 'woman.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. For captioning mode (using dedicated stream)\n",
    "await process_folder_with_mode(INPUT_DIR, mode=\"captioning\", prompt=\"MORE_DETAILED_CAPTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b5e18-3655-4964-b891-f7e7be66e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Process folder to both streams simultaneously\n",
    "await process_folder_both_modes(INPUT_DIR, num_labels=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pii)",
   "language": "python",
   "name": "pii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
