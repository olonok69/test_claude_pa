{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSFW Analysis - Consumer Notebook\n",
    "\n",
    "This notebook consumes NSFW analysis results from the NATS endpoint and processes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import nats\n",
    "from nats.js.api import StreamConfig, ConsumerConfig, AckPolicy, RetentionPolicy, DiscardPolicy\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, JSON, Image as IPImage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(os.path.join(\"keys\", \".env_file\"))\n",
    "\n",
    "# NATS connection settings\n",
    "NAT_URL = os.getenv(\"NAT_URL\", \"nats://localhost:4222\")\n",
    "\n",
    "# Get NSFW stream and subject settings\n",
    "OUTPUT_STREAM = os.getenv(\"OUTPUT_STREAM\", \"NSFW-RESULTS\")\n",
    "OUTPUT_SUBJECT = os.getenv(\"OUTPUT_SUBJECT\", \"nsfw.results.completed.>\")\n",
    "\n",
    "LOCAL_ENV = os.getenv(\"LOCAL_ENV\", \"1\")\n",
    "\n",
    "# Create output directories for results\n",
    "OUTPUT_DIR = \"nsfw_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Display current configuration\n",
    "print(\"NATS NSFW Consumer Configuration:\")\n",
    "print(f\"NATS URL: {NAT_URL}\")\n",
    "print(f\"NSFW Results Stream: {OUTPUT_STREAM}\")\n",
    "print(f\"NSFW Results Subject: {OUTPUT_SUBJECT}\")\n",
    "print(f\"Local Environment: {LOCAL_ENV}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_nsfw_results(data):\n",
    "    \"\"\"\n",
    "    Analyze NSFW processing results from a single result\n",
    "    \n",
    "    Args:\n",
    "        data: The result data to analyze\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Check if data contains nsfw_results\n",
    "    if \"nsfw_results\" not in data:\n",
    "        print(\"Invalid data format - no NSFW results found\")\n",
    "        return\n",
    "    \n",
    "    # Extract file information\n",
    "    file_name = data.get(\"file_name\", \"unknown\")\n",
    "    file_type = data.get(\"file_type\", \"unknown\")\n",
    "    threshold = data.get(\"threshold\", 0.5)\n",
    "    \n",
    "    print(f\"File: {file_name} (Type: {file_type}, Threshold: {threshold})\")\n",
    "    \n",
    "    # Extract and display NSFW results\n",
    "    nsfw_results = data[\"nsfw_results\"]\n",
    "    \n",
    "    if isinstance(nsfw_results, list) and len(nsfw_results) > 0:\n",
    "        for i, result in enumerate(nsfw_results):\n",
    "            print(f\"\\nResult {i+1}:\")\n",
    "            \n",
    "            # Check if it's a video result (multiple frames) or image result\n",
    "            if \"nsfw\" in result:\n",
    "                # Image result\n",
    "                nsfw_flag = result[\"nsfw\"]\n",
    "                print(f\"NSFW Classification: {'NSFW' if nsfw_flag == 1 else 'SFW'}\")\n",
    "                \n",
    "                # Check if we have class probabilities\n",
    "                if \"class_probabilities\" in result:\n",
    "                    probs = result[\"class_probabilities\"]\n",
    "                    print(\"\\nClass Probabilities:\")\n",
    "                    for cls, prob in probs.items():\n",
    "                        print(f\"  - {cls}: {prob:.4f}\")\n",
    "                    \n",
    "                    # Calculate total NSFW probability\n",
    "                    nsfw_prob = probs.get(\"sexy\", 0) + probs.get(\"hentai\", 0) + probs.get(\"porn\", 0)\n",
    "                    print(f\"\\nTotal NSFW Probability: {nsfw_prob:.4f} (Threshold: {threshold})\")\n",
    "            elif \"prediction\" in result:\n",
    "                # Video result or simplified format\n",
    "                score = result.get(\"prediction\", 0)\n",
    "                nsfw_flag = result.get(\"nsfw\", 0) \n",
    "                description = result.get(\"description\", \"\")\n",
    "                \n",
    "                print(f\"NSFW Classification: {'NSFW' if nsfw_flag == 1 else 'SFW'}\")\n",
    "                print(f\"Score: {score:.4f} (Threshold: {threshold})\")\n",
    "                if description:\n",
    "                    print(f\"Description: {description}\")\n",
    "    else:\n",
    "        print(\"No NSFW analysis results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_nsfw_results(data):\n",
    "    \"\"\"\n",
    "    Visualize NSFW analysis results with a bar chart\n",
    "    \n",
    "    Args:\n",
    "        data: The result data to visualize\n",
    "    \"\"\"\n",
    "    if not data or \"nsfw_results\" not in data:\n",
    "        print(\"No data to visualize\")\n",
    "        return\n",
    "    \n",
    "    nsfw_results = data[\"nsfw_results\"]\n",
    "    \n",
    "    if not nsfw_results or not isinstance(nsfw_results, list) or len(nsfw_results) == 0:\n",
    "        print(\"No NSFW results to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Check if we have class probabilities (image analysis)\n",
    "    if \"class_probabilities\" in nsfw_results[0]:\n",
    "        # Extract class probabilities for visualization\n",
    "        probs = nsfw_results[0][\"class_probabilities\"]\n",
    "        \n",
    "        # Create bar chart\n",
    "        labels = list(probs.keys())\n",
    "        values = [probs[label] for label in labels]\n",
    "        \n",
    "        # Calculate combined NSFW probability for special highlight\n",
    "        nsfw_classes = [\"sexy\", \"hentai\", \"porn\"]\n",
    "        nsfw_indices = [i for i, label in enumerate(labels) if label in nsfw_classes]\n",
    "        \n",
    "        # Create colors, highlighting NSFW classes in red\n",
    "        colors = ['#1f77b4' if i not in nsfw_indices else '#d62728' for i in range(len(labels))]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(labels, values, color=colors)\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title('NSFW Class Probabilities')\n",
    "        plt.ylim(0, 1.0)\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                     f'{height:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Add horizontal line for threshold\n",
    "        threshold = data.get(\"threshold\", 0.5)\n",
    "        if threshold is not None:\n",
    "            plt.axhline(y=threshold, color='r', linestyle='--', alpha=0.3)\n",
    "            plt.text(0, threshold + 0.03, f'Threshold: {threshold}', color='r')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Also show aggregated NSFW probability\n",
    "        nsfw_prob = sum(probs.get(cls, 0) for cls in nsfw_classes)\n",
    "        sfw_prob = 1 - nsfw_prob  # Simplified assumption\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(['SFW', 'NSFW'], [sfw_prob, nsfw_prob], \n",
    "                color=['#1f77b4', '#d62728'])\n",
    "        plt.xlabel('Classification')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title('SFW vs. NSFW Probability')\n",
    "        plt.ylim(0, 1.0)\n",
    "        \n",
    "        # Add value labels\n",
    "        plt.text(0, sfw_prob + 0.02, f'{sfw_prob:.3f}', ha='center')\n",
    "        plt.text(1, nsfw_prob + 0.02, f'{nsfw_prob:.3f}', ha='center')\n",
    "        \n",
    "        # Add threshold line\n",
    "        if threshold is not None:\n",
    "            plt.axhline(y=threshold, color='r', linestyle='--', alpha=0.3)\n",
    "            plt.text(0, threshold + 0.03, f'Threshold: {threshold}', color='r')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif \"prediction\" in nsfw_results[0]:\n",
    "        # Video result or simplified format\n",
    "        # For videos, we might have multiple frames with predictions\n",
    "        if len(nsfw_results) > 1:\n",
    "            # Multiple frames\n",
    "            scores = [result.get(\"prediction\", 0) for result in nsfw_results]\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(scores, '-o', color='#1f77b4')\n",
    "            plt.xlabel('Frame')\n",
    "            plt.ylabel('NSFW Score')\n",
    "            plt.title('NSFW Scores Across Video Frames')\n",
    "            plt.ylim(0, 1.0)\n",
    "            \n",
    "            # Add threshold line\n",
    "            threshold = data.get(\"threshold\", 0.5)\n",
    "            if threshold is not None:\n",
    "                plt.axhline(y=threshold, color='r', linestyle='--', alpha=0.6)\n",
    "                plt.text(0, threshold + 0.03, f'Threshold: {threshold}', color='r')\n",
    "            \n",
    "            # Mark frames that exceed threshold\n",
    "            for i, score in enumerate(scores):\n",
    "                if score > threshold:\n",
    "                    plt.plot(i, score, 'ro', markersize=8)\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Show summary statistics\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "            max_score = max(scores)\n",
    "            nsfw_frames = sum(1 for s in scores if s > threshold)\n",
    "            nsfw_percentage = (nsfw_frames / len(scores)) * 100\n",
    "            \n",
    "            print(f\"\\nVideo Summary Statistics:\")\n",
    "            print(f\"Total Frames Analyzed: {len(scores)}\")\n",
    "            print(f\"Average NSFW Score: {avg_score:.4f}\")\n",
    "            print(f\"Maximum NSFW Score: {max_score:.4f}\")\n",
    "            print(f\"NSFW Frames: {nsfw_frames} ({nsfw_percentage:.1f}%)\")\n",
    "            \n",
    "            # Show histogram of scores\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(scores, bins=20, color='#1f77b4', alpha=0.7)\n",
    "            plt.xlabel('NSFW Score')\n",
    "            plt.ylabel('Number of Frames')\n",
    "            plt.title('Distribution of NSFW Scores Across Video Frames')\n",
    "            \n",
    "            # Add threshold line\n",
    "            if threshold is not None:\n",
    "                plt.axvline(x=threshold, color='r', linestyle='--', alpha=0.6)\n",
    "                plt.text(threshold + 0.02, plt.ylim()[1] * 0.9, \n",
    "                         f'Threshold: {threshold}', color='r')\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Single result\n",
    "            score = nsfw_results[0].get(\"prediction\", 0)\n",
    "            threshold = data.get(\"threshold\", 0.5)\n",
    "            \n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.bar(['Score'], [score], color='#1f77b4' if score <= threshold else '#d62728')\n",
    "            plt.xlabel('NSFW Analysis')\n",
    "            plt.ylabel('Score')\n",
    "            plt.title('NSFW Analysis Result')\n",
    "            plt.ylim(0, 1.0)\n",
    "            \n",
    "            # Add value label\n",
    "            plt.text(0, score + 0.02, f'{score:.3f}', ha='center')\n",
    "            \n",
    "            # Add threshold line\n",
    "            if threshold is not None:\n",
    "                plt.axhline(y=threshold, color='r', linestyle='--', alpha=0.3)\n",
    "                plt.text(0, threshold + 0.03, f'Threshold: {threshold}', color='r')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NATS Monitoring and Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_stream(js, stream_name, subjects):\n",
    "    \"\"\"\n",
    "    Ensure a NATS stream exists with the given configuration\n",
    "    \n",
    "    Args:\n",
    "        js: JetStream context\n",
    "        stream_name: Name of the stream\n",
    "        subjects: List of subject patterns for the stream\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if stream already exists\n",
    "        stream_info = await js.stream_info(stream_name)\n",
    "        print(f\"Stream '{stream_name}' already exists with {stream_info.state.messages} messages\")\n",
    "    except Exception:\n",
    "        # Create the stream\n",
    "        stream_config = StreamConfig(\n",
    "            name=stream_name,\n",
    "            subjects=subjects,\n",
    "            retention=RetentionPolicy.LIMITS,\n",
    "            max_age=30 * 24 * 60 * 60,  # 30 days\n",
    "            duplicate_window=120,  # 2 minutes\n",
    "            discard=DiscardPolicy.OLD\n",
    "        )\n",
    "        await js.add_stream(config=stream_config)\n",
    "        print(f\"Created stream '{stream_name}' with subjects: {subjects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def monitor_nsfw_results(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    stream_name=OUTPUT_STREAM,\n",
    "    subject=OUTPUT_SUBJECT,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1,  # Seconds between polling the stream\n",
    "    visualize=True  # Whether to visualize results\n",
    "):\n",
    "    \"\"\"\n",
    "    Monitor a NATS stream for new NSFW results.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        stream_name: The stream name to read from\n",
    "        subject: The subject to monitor\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "        visualize: Whether to visualize the results\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "    \n",
    "    # Ensure the stream exists\n",
    "    await setup_stream(js, stream_name, [subject])\n",
    "    \n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "    \n",
    "    # Initialize start_time\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Get stream info to find the current last sequence\n",
    "        try:\n",
    "            stream_info = await js.stream_info(stream_name)\n",
    "            last_seq = stream_info.state.last_seq\n",
    "            print(f\"Connected to stream '{stream_name}'\")\n",
    "            print(f\"Stream contains {stream_info.state.messages} messages\")\n",
    "            print(f\"Last sequence is {last_seq}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting stream info: {e}\")\n",
    "            return messages_processed\n",
    "        \n",
    "        print(f\"Stream monitor will run for {run_time_seconds} seconds or until interrupted\")\n",
    "        print(f\"Results will be saved to {output_dir}\")\n",
    "        print(\"Monitoring for new NSFW analysis results...\")\n",
    "        \n",
    "        # Current sequence to start from\n",
    "        current_seq = last_seq + 1\n",
    "        \n",
    "        # Poll the stream until the run time is reached\n",
    "        while (datetime.now() - start_time).total_seconds() < run_time_seconds:\n",
    "            try:\n",
    "                # Get the current stream info\n",
    "                stream_info = await js.stream_info(stream_name)\n",
    "                new_last_seq = stream_info.state.last_seq\n",
    "                \n",
    "                # Check if there are new messages\n",
    "                if new_last_seq >= current_seq:\n",
    "                    print(f\"Found {new_last_seq - current_seq + 1} new messages\")\n",
    "                    \n",
    "                    # Get messages from current_seq to new_last_seq\n",
    "                    for seq in range(current_seq, new_last_seq + 1):\n",
    "                        try:\n",
    "                            # Get the message at this sequence\n",
    "                            msg = await js.get_msg(stream_name, seq)\n",
    "                            \n",
    "                            # Check if message subject matches our pattern\n",
    "                            if not msg.subject.startswith(subject.rstrip(\">\")):\n",
    "                                print(f\"Skipping message with subject {msg.subject}\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Parse message data\n",
    "                            data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "                            \n",
    "                            # Extract file info from headers if available\n",
    "                            file_info = \"\"\n",
    "                            if hasattr(msg, 'headers') and msg.headers:\n",
    "                                if \"filename\" in msg.headers:\n",
    "                                    file_info = msg.headers[\"filename\"]\n",
    "                                elif \"file_name\" in msg.headers:\n",
    "                                    file_info = msg.headers[\"file_name\"]\n",
    "                            \n",
    "                            # Generate a filename for the result\n",
    "                            if file_info:\n",
    "                                filename = f\"nsfw_result_{file_info}.json\"\n",
    "                            else:\n",
    "                                # Use data from message or generate a timestamp\n",
    "                                if \"file_name\" in data:\n",
    "                                    file_info = data[\"file_name\"]\n",
    "                                    filename = f\"nsfw_result_{file_info}.json\"\n",
    "                                else:\n",
    "                                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                    filename = f\"nsfw_result_{timestamp}_{seq}.json\"\n",
    "                            \n",
    "                            # Save result to file\n",
    "                            output_path = os.path.join(output_dir, filename)\n",
    "                            with open(output_path, \"w\") as f:\n",
    "                                json.dump(data, f, indent=2)\n",
    "                            \n",
    "                            # Increment counter and display info\n",
    "                            messages_processed += 1\n",
    "                            print(f\"\\nReceived NSFW result #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "                            \n",
    "                            # Analyze the results\n",
    "                            print(\"\\nNSFW Analysis:\")\n",
    "                            analyze_nsfw_results(data)\n",
    "                            \n",
    "                            # Visualize results if requested\n",
    "                            if visualize:\n",
    "                                print(\"\\nVisualizing NSFW results:\")\n",
    "                                visualize_nsfw_results(data)\n",
    "                            \n",
    "                            print(\"-\" * 50)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing message with seq={seq}: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Update current_seq\n",
    "                    current_seq = new_last_seq + 1\n",
    "                else:\n",
    "                    # No new messages\n",
    "                    print(\"No new messages found. Waiting...\")\n",
    "                \n",
    "                # Wait before polling again\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error polling stream: {str(e)}\")\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nReceived interrupt signal, shutting down...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in monitor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "    \n",
    "    # Print summary\n",
    "    run_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"\\nMonitor summary:\")\n",
    "    print(f\"- Run time: {run_time:.2f} seconds\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {output_dir}\")\n",
    "    \n",
    "    return messages_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_existing_results(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    stream_name=OUTPUT_STREAM,\n",
    "    subject=OUTPUT_SUBJECT,\n",
    "    limit=100,  # Maximum number of messages to process\n",
    "    visualize=True  # Whether to visualize results\n",
    "):\n",
    "    \"\"\"\n",
    "    Process existing NSFW results in a stream (historical data).\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        stream_name: The stream name to read from\n",
    "        subject: The subject to filter by\n",
    "        limit: Maximum number of messages to process\n",
    "        visualize: Whether to visualize the results\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "    \n",
    "    # Ensure the stream exists\n",
    "    await setup_stream(js, stream_name, [subject])\n",
    "    \n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "    \n",
    "    try:\n",
    "        # Get stream info\n",
    "        try:\n",
    "            stream_info = await js.stream_info(stream_name)\n",
    "            total_messages = stream_info.state.messages\n",
    "            first_seq = stream_info.state.first_seq\n",
    "            last_seq = stream_info.state.last_seq\n",
    "            \n",
    "            print(f\"Connected to stream '{stream_name}'\")\n",
    "            print(f\"Stream contains {total_messages} messages\")\n",
    "            print(f\"Sequence range: {first_seq} to {last_seq}\")\n",
    "            print(f\"Will process up to {limit} most recent messages\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting stream info: {e}\")\n",
    "            return messages_processed\n",
    "        \n",
    "        # If no messages, return early\n",
    "        if total_messages == 0:\n",
    "            print(\"Stream is empty. No messages to process.\")\n",
    "            return 0\n",
    "        \n",
    "        # Determine range of sequences to process (most recent first)\n",
    "        start_seq = max(first_seq, last_seq - limit + 1)\n",
    "        \n",
    "        print(f\"Processing messages from sequence {start_seq} to {last_seq}...\")\n",
    "        \n",
    "        # Process messages in reverse order (newest first)\n",
    "        for seq in range(last_seq, start_seq - 1, -1):\n",
    "            try:\n",
    "                # Get the message at this sequence\n",
    "                msg = await js.get_msg(stream_name, seq)\n",
    "                \n",
    "                # Check if message subject matches our pattern\n",
    "                if not msg.subject.startswith(subject.rstrip(\">\")):\n",
    "                    print(f\"Skipping message with subject {msg.subject}\")\n",
    "                    continue\n",
    "                \n",
    "                # Parse message data\n",
    "                data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "                \n",
    "                # Extract file info from headers if available\n",
    "                file_info = \"\"\n",
    "                if hasattr(msg, 'headers') and msg.headers:\n",
    "                    if \"filename\" in msg.headers:\n",
    "                        file_info = msg.headers[\"filename\"]\n",
    "                    elif \"file_name\" in msg.headers:\n",
    "                        file_info = msg.headers[\"file_name\"]\n",
    "                \n",
    "                # Generate a filename for the result\n",
    "                if file_info:\n",
    "                    filename = f\"nsfw_result_{file_info}.json\"\n",
    "                else:\n",
    "                    # Use data from message or generate a timestamp\n",
    "                    if \"file_name\" in data:\n",
    "                        file_info = data[\"file_name\"]\n",
    "                        filename = f\"nsfw_result_{file_info}.json\"\n",
    "                    else:\n",
    "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                        filename = f\"nsfw_result_{timestamp}_{seq}.json\"\n",
    "                \n",
    "                # Save result to file\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "                with open(output_path, \"w\") as f:\n",
    "                    json.dump(data, f, indent=2)\n",
    "                \n",
    "                # Increment counter and display info\n",
    "                messages_processed += 1\n",
    "                print(f\"\\nProcessed NSFW result #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "                \n",
    "                # Analyze the results\n",
    "                print(\"\\nNSFW Analysis:\")\n",
    "                analyze_nsfw_results(data)\n",
    "                \n",
    "                # Visualize results if requested\n",
    "                if visualize:\n",
    "                    print(\"\\nVisualizing NSFW results:\")\n",
    "                    visualize_nsfw_results(data)\n",
    "                \n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing message with seq={seq}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error in processor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nProcessor summary:\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {output_dir}\")\n",
    "    \n",
    "    return messages_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_and_monitor_results(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    stream_name=OUTPUT_STREAM,\n",
    "    subject=OUTPUT_SUBJECT,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1,  # Seconds between polling the stream\n",
    "    process_existing=True,  # Whether to process existing messages\n",
    "    limit_existing=10,  # Limit for existing messages\n",
    "    visualize=True  # Whether to visualize results\n",
    "):\n",
    "    \"\"\"\n",
    "    Process existing results and then monitor for new ones.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        stream_name: The stream name to read from\n",
    "        subject: The subject to monitor\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "        process_existing: Whether to process existing messages\n",
    "        limit_existing: Maximum number of existing messages to process\n",
    "        visualize: Whether to visualize the results\n",
    "    \"\"\"\n",
    "    # Process existing messages if requested\n",
    "    if process_existing:\n",
    "        print(\"Processing existing NSFW analysis results...\")\n",
    "        existing_count = await process_existing_results(\n",
    "            output_dir=output_dir,\n",
    "            nats_url=nats_url,\n",
    "            stream_name=stream_name,\n",
    "            subject=subject,\n",
    "            limit=limit_existing,\n",
    "            visualize=visualize\n",
    "        )\n",
    "        print(f\"Processed {existing_count} existing NSFW analysis results\")\n",
    "    \n",
    "    # Now monitor for new messages\n",
    "    print(\"\\nMonitoring for new NSFW analysis results...\")\n",
    "    new_count = await monitor_nsfw_results(\n",
    "        output_dir=output_dir,\n",
    "        nats_url=nats_url,\n",
    "        stream_name=stream_name,\n",
    "        subject=subject,\n",
    "        run_time_seconds=run_time_seconds,\n",
    "        poll_interval=poll_interval,\n",
    "        visualize=visualize\n",
    "    )\n",
    "    \n",
    "    # Total count\n",
    "    total_count = (existing_count if process_existing else 0) + new_count\n",
    "    print(f\"\\nTotal NSFW analysis results processed: {total_count}\")\n",
    "    \n",
    "    return total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process NSFW Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one option:\n",
    "\n",
    "# Option 1: Only monitor for new results\n",
    "# await monitor_nsfw_results(run_time_seconds=3600)\n",
    "\n",
    "# Option 2: Process existing results (up to 20) but don't monitor for new ones\n",
    "# await process_existing_results(limit=20)\n",
    "\n",
    "# Option 3: Process existing results and then monitor for new ones (recommended)\n",
    "await process_and_monitor_results(\n",
    "    run_time_seconds=3600,  # 1 hour\n",
    "    process_existing=True,\n",
    "    limit_existing=10,      # Process up to 10 existing results\n",
    "    visualize=True          # Create visualizations for the results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Saved Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_saved_results(results_dir=OUTPUT_DIR, limit=None, visualize=True):\n",
    "    \"\"\"\n",
    "    Load and analyze NSFW results saved to disk\n",
    "    \n",
    "    Args:\n",
    "        results_dir: Directory containing saved JSON results\n",
    "        limit: Maximum number of files to analyze (None for all)\n",
    "        visualize: Whether to create visualizations\n",
    "    \"\"\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        print(f\"Results directory not found: {results_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Get all JSON files in the directory\n",
    "    json_files = [f for f in os.listdir(results_dir) if f.endswith('.json')]\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"No JSON result files found in {results_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Sort by modification time (newest first)\n",
    "    json_files.sort(key=lambda f: os.path.getmtime(os.path.join(results_dir, f)), reverse=True)\n",
    "    \n",
    "    # Apply limit if specified\n",
    "    if limit:\n",
    "        json_files = json_files[:limit]\n",
    "        \n",
    "    print(f\"Found {len(json_files)} result files in {results_dir}\")\n",
    "    print(f\"Analyzing {len(json_files)} files...\")\n",
    "    \n",
    "    # Process each file\n",
    "    for i, filename in enumerate(json_files):\n",
    "        file_path = os.path.join(results_dir, filename)\n",
    "        print(f\"\\n{'-' * 50}\")\n",
    "        print(f\"Result {i+1}/{len(json_files)}: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Analyze the results\n",
    "            print(\"\\nNSFW Analysis:\")\n",
    "            analyze_nsfw_results(data)\n",
    "            \n",
    "            # Visualize results if requested\n",
    "            if visualize:\n",
    "                print(\"\\nVisualizing NSFW results:\")\n",
    "                visualize_nsfw_results(data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nCompleted analysis of {len(json_files)} result files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze previously saved results (if any)\n",
    "# load_and_analyze_saved_results(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Analysis of All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_nsfw_results(results_dir=OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    Analyze all NSFW results in the directory and generate aggregate statistics\n",
    "    \n",
    "    Args:\n",
    "        results_dir: Directory containing saved JSON results\n",
    "    \"\"\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        print(f\"Results directory not found: {results_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Get all JSON files in the directory\n",
    "    json_files = [f for f in os.listdir(results_dir) if f.endswith('.json')]\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"No JSON result files found in {results_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(json_files)} result files in {results_dir}\")\n",
    "    print(\"Generating aggregate statistics...\")\n",
    "    \n",
    "    # Statistics to collect\n",
    "    total_files = 0\n",
    "    nsfw_files = 0\n",
    "    images_count = 0\n",
    "    videos_count = 0\n",
    "    nsfw_images = 0\n",
    "    nsfw_videos = 0\n",
    "    \n",
    "    # Collect probabilities\n",
    "    all_scores = []\n",
    "    image_class_probs = {'drawings': [], 'hentai': [], 'neutral': [], 'porn': [], 'sexy': []}\n",
    "    \n",
    "    # Process all files\n",
    "    for filename in json_files:\n",
    "        file_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            if \"nsfw_results\" not in data:\n",
    "                continue\n",
    "                \n",
    "            total_files += 1\n",
    "            file_type = data.get(\"file_type\", \"\")\n",
    "            \n",
    "            # Determine if file is image or video based on file_type or analysis\n",
    "            is_video = False\n",
    "            if file_type and file_type.lower() in ['mp4', 'avi', 'mov', 'mkv', 'wmv', 'flv', 'webm']:\n",
    "                is_video = True\n",
    "                videos_count += 1\n",
    "            else:\n",
    "                images_count += 1\n",
    "                \n",
    "            # Extract NSFW results\n",
    "            nsfw_results = data[\"nsfw_results\"]\n",
    "            \n",
    "            if not nsfw_results or not isinstance(nsfw_results, list) or len(nsfw_results) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Check if it's NSFW\n",
    "            is_nsfw = False\n",
    "            \n",
    "            # Check different result formats\n",
    "            if \"nsfw\" in nsfw_results[0]:\n",
    "                # Image result\n",
    "                nsfw_flag = nsfw_results[0][\"nsfw\"]\n",
    "                is_nsfw = (nsfw_flag == 1)\n",
    "                \n",
    "                # Check if we have class probabilities\n",
    "                if \"class_probabilities\" in nsfw_results[0]:\n",
    "                    probs = nsfw_results[0][\"class_probabilities\"]\n",
    "                    for cls in image_class_probs.keys():\n",
    "                        if cls in probs:\n",
    "                            image_class_probs[cls].append(probs[cls])\n",
    "                    \n",
    "                    # Calculate total NSFW probability and add to all_scores\n",
    "                    nsfw_prob = probs.get(\"sexy\", 0) + probs.get(\"hentai\", 0) + probs.get(\"porn\", 0)\n",
    "                    all_scores.append(nsfw_prob)\n",
    "            \n",
    "            elif \"prediction\" in nsfw_results[0]:\n",
    "                # Video result or simplified format\n",
    "                score = nsfw_results[0].get(\"prediction\", 0)\n",
    "                nsfw_flag = nsfw_results[0].get(\"nsfw\", 0)\n",
    "                \n",
    "                is_nsfw = (nsfw_flag == 1)\n",
    "                all_scores.append(score)\n",
    "            \n",
    "            # Update counts\n",
    "            if is_nsfw:\n",
    "                nsfw_files += 1\n",
    "                if is_video:\n",
    "                    nsfw_videos += 1\n",
    "                else:\n",
    "                    nsfw_images += 1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Generate statistics\n",
    "    print(f\"\\nNSFW Analysis Summary:\")\n",
    "    print(f\"Total files analyzed: {total_files}\")\n",
    "    print(f\"NSFW files detected: {nsfw_files} ({(nsfw_files / total_files * 100) if total_files > 0 else 0:.1f}%)\")\n",
    "    print(f\"\\nBy file type:\")\n",
    "    print(f\"Images: {images_count} total, {nsfw_images} NSFW ({(nsfw_images / images_count * 100) if images_count > 0 else 0:.1f}%)\")\n",
    "    print(f\"Videos: {videos_count} total, {nsfw_videos} NSFW ({(nsfw_videos / videos_count * 100) if videos_count > 0 else 0:.1f}%)\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    if all_scores:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(all_scores, bins=20, color='#1f77b4', alpha=0.7)\n",
    "        plt.xlabel('NSFW Score')\n",
    "        plt.ylabel('Number of Files')\n",
    "        plt.title('Distribution of NSFW Scores Across All Files')\n",
    "        plt.axvline(x=0.5, color='r', linestyle='--', alpha=0.6)\n",
    "        plt.text(0.52, plt.ylim()[1] * 0.9, 'Default Threshold: 0.5', color='r')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Visualize class probabilities for images\n",
    "    if any(len(probs) > 0 for probs in image_class_probs.values()):\n",
    "        # Calculate average probability for each class\n",
    "        avg_probs = {}\n",
    "        for cls, probs in image_class_probs.items():\n",
    "            if probs:\n",
    "                avg_probs[cls] = sum(probs) / len(probs)\n",
    "            else:\n",
    "                avg_probs[cls] = 0\n",
    "        \n",
    "        # Create bar chart\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        labels = list(avg_probs.keys())\n",
    "        values = [avg_probs[label] for label in labels]\n",
    "        \n",
    "        # Calculate combined NSFW probability for special highlight\n",
    "        nsfw_classes = [\"sexy\", \"hentai\", \"porn\"]\n",
    "        nsfw_indices = [i for i, label in enumerate(labels) if label in nsfw_classes]\n",
    "        \n",
    "        # Create colors, highlighting NSFW classes in red\n",
    "        colors = ['#1f77b4' if i not in nsfw_indices else '#d62728' for i in range(len(labels))]\n",
    "        \n",
    "        bars = plt.bar(labels, values, color=colors)\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Average Probability')\n",
    "        plt.title('Average NSFW Class Probabilities Across All Images')\n",
    "        plt.ylim(0, 1.0)\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                     f'{height:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show NSFW vs SFW breakdown\n",
    "        nsfw_avg = sum(avg_probs.get(cls, 0) for cls in nsfw_classes)\n",
    "        sfw_avg = 1 - nsfw_avg  # Simplified assumption\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(['SFW', 'NSFW'], [sfw_avg, nsfw_avg], \n",
    "                color=['#1f77b4', '#d62728'])\n",
    "        plt.xlabel('Classification')\n",
    "        plt.ylabel('Average Probability')\n",
    "        plt.title('Average SFW vs. NSFW Probability Across All Images')\n",
    "        plt.ylim(0, 1.0)\n",
    "        \n",
    "        # Add value labels\n",
    "        plt.text(0, sfw_avg + 0.02, f'{sfw_avg:.3f}', ha='center')\n",
    "        plt.text(1, nsfw_avg + 0.02, f'{nsfw_avg:.3f}', ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate analysis of all saved results\n",
    "# aggregate_nsfw_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
