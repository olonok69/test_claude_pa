# Perplexity MCP Server with Caching

A high-performance Model Context Protocol (MCP) server that provides AI-powered web search capabilities using the Perplexity API. This server uses Server-Sent Events (SSE) for real-time communication and includes intelligent caching to optimize API usage and response times.

## üöÄ Features

### **Core Capabilities**
- **AI-Powered Web Search**: Leverage Perplexity's advanced AI models for intelligent web search
- **Recency Filtering**: Filter search results by time period (day, week, month, year)
- **Multiple Model Support**: Compatible with all Perplexity AI models
- **Advanced Search Parameters**: Fine-tune searches with custom model, temperature, and token settings
- **Automatic Citations**: All search results include source citations

### **Performance Optimizations**
- **Intelligent Caching**: 30-minute cache for API responses to reduce costs and latency
- **Cache Management**: Tools to inspect and clear cache as needed
- **Health Check Caching**: 5-minute cache for health status to minimize overhead
- **No External API Calls on Health Checks**: Health endpoint validates configuration without making API calls

### **Technical Features**
- **SSE Protocol**: Real-time communication using Server-Sent Events
- **Async Architecture**: High-performance async/await implementation
- **Comprehensive Logging**: Detailed logging for debugging and monitoring
- **Environment Configuration**: Flexible configuration via environment variables
- **Fixed Port**: Server runs on port 8003

## üìã Prerequisites

- Python 3.11+
- Perplexity API key (get one at [perplexity.ai](https://perplexity.ai))
- Docker (optional, for containerized deployment)

## üõ†Ô∏è Installation & Setup

### 1. Environment Configuration

Create a `.env` file in the server directory:

```env
# Required
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# Optional (defaults to 'sonar')
PERPLEXITY_MODEL=sonar
```

### 2. Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Run the server
python perplexity_sse_server.py
```

The server will start on `http://0.0.0.0:8003`

### 3. Docker Deployment

```bash
# Build the Docker image
docker build -t perplexity-mcp-sse .

# Run the container
docker run -p 8003:8003 \
  -e PERPLEXITY_API_KEY=your_api_key_here \
  -e PERPLEXITY_MODEL=sonar \
  perplexity-mcp-sse
```

## üîß Available Tools (4 Tools)

### **1. perplexity_search_web**
Standard web search with recency filtering and automatic caching.

**Parameters:**
- `query` (string, required): The search query
- `recency` (string, optional): Time filter - "day", "week", "month", "year" (default: "month")

**Response includes:**
- Search results with AI-generated content
- Source citations
- Token usage statistics
- Cache status indicator

**Example:**
```python
result = await perplexity_search_web(
    query="latest developments in AI",
    recency="week"
)
```

### **2. perplexity_advanced_search**
Advanced search with full parameter control and caching support.

**Parameters:**
- `query` (string, required): The search query
- `recency` (string, optional): Time filter (default: "month")
- `model` (string, optional): Override the default model
- `max_tokens` (int, optional): Maximum response tokens (1-2048, default: 512)
- `temperature` (float, optional): Response randomness (0.0-1.0, default: 0.2)

**Example:**
```python
result = await perplexity_advanced_search(
    query="quantum computing breakthroughs",
    recency="month",
    model="sonar-pro",
    max_tokens=1000,
    temperature=0.5
)
```

### **3. clear_api_cache**
Clear all cached API responses to force fresh data retrieval.

**No parameters required**

**Returns:**
- Number of entries cleared
- Cache statistics before clearing

### **4. get_cache_stats**
Get current cache performance statistics.

**No parameters required**

**Returns:**
- Total cached entries
- Valid (non-expired) entries
- Expired entries
- Cache TTL configuration

## üìä Available Models

The server supports all Perplexity AI models:

- **sonar-deep-research**: 128k context - Enhanced research capabilities
- **sonar-reasoning-pro**: 128k context - Advanced reasoning with professional focus
- **sonar-reasoning**: 128k context - Enhanced reasoning capabilities
- **sonar-pro**: 200k context - Professional grade model
- **sonar**: 128k context - Default model (recommended for general use)
- **r1-1776**: 128k context - Alternative architecture

Set your preferred model using the `PERPLEXITY_MODEL` environment variable.

## üîå API Endpoints

### **Health Check**
```
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "message": "Server operational - API key configured",
  "version": "0.1.8",
  "timestamp": "2025-01-22T12:00:00.000Z",
  "server_info": {
    "model": "sonar",
    "api_key_configured": true,
    "api_test_disabled": "Health checks do not test external APIs to avoid unnecessary calls",
    "uptime_seconds": 3600
  },
  "cache_stats": {
    "total_entries": 10,
    "valid_entries": 8,
    "expired_entries": 2,
    "ttl_seconds": 1800
  },
  "available_models": [...],
  "available_tools": [
    "perplexity_search_web",
    "perplexity_advanced_search",
    "clear_api_cache",
    "get_cache_stats"
  ],
  "optimization_features": {
    "api_caching": true,
    "cache_ttl_seconds": 1800,
    "health_check_caching": true,
    "external_api_calls_avoided": "Health checks do not call external APIs"
  }
}
```

### **SSE Endpoint**
```
GET /sse
```
Used for MCP client connections via Server-Sent Events.

### **Message Endpoint**
```
POST /messages/
```
Used for MCP message handling.

## üíæ Caching System

### **API Response Cache**
- **TTL**: 30 minutes (1800 seconds)
- **Key Generation**: Based on query + all parameters
- **Automatic Expiration**: Expired entries removed on access
- **Cache Hit Indicator**: Responses indicate if they were served from cache

### **Cache Benefits**
- **Cost Reduction**: Fewer API calls to Perplexity
- **Improved Latency**: Instant responses for cached queries
- **Rate Limit Protection**: Reduces risk of hitting API limits
- **Consistent Results**: Same query returns same results within TTL

### **Cache Management**
```python
# Check cache statistics
stats = await get_cache_stats()

# Clear cache when needed
await clear_api_cache()
```

## üéØ Usage Examples

### **Basic Web Search**
```python
# Simple search with default settings
result = await perplexity_search_web("what is quantum computing")

# Search with recency filter
recent_news = await perplexity_search_web(
    query="AI regulations news",
    recency="day"
)
```

### **Advanced Search with Custom Parameters**
```python
# Use a more powerful model with more tokens
detailed_result = await perplexity_advanced_search(
    query="explain transformer architecture in detail",
    model="sonar-pro",
    max_tokens=2000,
    temperature=0.3
)
```

### **Cache-Aware Workflow**
```python
# First call - hits API
result1 = await perplexity_search_web("climate change impacts")

# Second call within 30 minutes - served from cache (instant)
result2 = await perplexity_search_web("climate change impacts")

# Force fresh data
await clear_api_cache()
result3 = await perplexity_search_web("climate change impacts")
```

## üîí Security & Best Practices

### **API Key Security**
- Store API key in environment variables, never in code
- Use `.env` file for local development (add to .gitignore)
- In production, use secure secret management

### **Rate Limiting**
- Cache helps prevent rate limit issues
- Monitor usage with cache statistics
- Consider implementing request queuing for high-volume use

### **Error Handling**
- Server includes comprehensive error handling
- API errors are logged and returned gracefully
- Health checks don't consume API quota

## üêõ Troubleshooting

### **Common Issues**

**API Key Not Found:**
```
Error: PERPLEXITY_API_KEY environment variable is required
```
**Solution**: Ensure `.env` file exists with valid API key

**Invalid Model:**
```
Warning: Model 'invalid-model' not recognized
```
**Solution**: Check available models list and update PERPLEXITY_MODEL

**Cache Not Working:**
```
Every request hits the API even for identical queries
```
**Solution**: Check cache stats with `get_cache_stats()` tool

### **Performance Tips**
- Use caching effectively - identical queries within 30 minutes use cache
- Choose appropriate model - 'sonar' is fast and cost-effective for most uses
- Adjust max_tokens based on needs - lower values are faster and cheaper
- Monitor cache hit rate to optimize query patterns

## üöÄ Production Deployment

### **Docker Compose Configuration**
```yaml
version: '3.8'

services:
  perplexity-mcp:
    build: .
    ports:
      - "8003:8003"
    environment:
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY}
      - PERPLEXITY_MODEL=${PERPLEXITY_MODEL:-sonar}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 60s
      timeout: 10s
      start-period: 5s
      retries: 3
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

### **Environment Variables**
| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| PERPLEXITY_API_KEY | Yes | - | Your Perplexity API key |
| PERPLEXITY_MODEL | No | sonar | Default model to use |

### **Monitoring Recommendations**
- Track cache hit rate via `get_cache_stats()`
- Monitor health endpoint for uptime
- Log API usage and costs
- Set up alerts for API errors

## üîÑ Integration Examples

### **Python Client**
```python
import httpx
from mcp import Client

# Connect to the server
client = Client("http://localhost:8003/sse")

# Perform a search
result = await client.call_tool(
    "perplexity_search_web",
    {"query": "latest AI news", "recency": "day"}
)
```

### **JavaScript/TypeScript Client**
```javascript
// Using MCP client library
const client = new MCPClient('http://localhost:8003/sse');

// Search with caching
const result = await client.callTool('perplexity_search_web', {
    query: 'machine learning trends',
    recency: 'week'
});

// Check cache statistics
const stats = await client.callTool('get_cache_stats');
```

## üìà Performance Metrics

### **Typical Response Times**
- **Cached responses**: < 10ms
- **Fresh API calls**: 500-2000ms (depends on query complexity)
- **Health checks**: < 5ms (cached for 5 minutes)

### **Cache Efficiency**
- **Hit Rate**: Typically 40-60% for normal usage patterns
- **Memory Usage**: ~1MB per 100 cached responses
- **Cost Savings**: Up to 50% reduction in API costs with effective caching

## ü§ù Contributing

Contributions are welcome! Areas for improvement:
- Add more Perplexity API features
- Implement cache persistence
- Add request queuing for rate limiting
- Enhance error handling and retry logic

## üìÑ License

This project is licensed under the MIT License.

---

**Version**: 0.1.8  
**Server Port**: 8003  
**Cache TTL**: 30 minutes  
**Health Check Cache**: 5 minutes  
**Supported Models**: 6 (all Perplexity models)  
**Tools**: 4 (2 search + 2 cache management)