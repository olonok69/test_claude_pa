{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olonok69/projects_ai/blob/main/Prompt_OLLama_DeepSeek_Phi3_5_LLama3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1xfwhesRgTz",
        "outputId": "3f5a67cd-eaa2-4618-cdc0-8931cb63bc84"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46lpPSqkSAEP"
      },
      "outputs": [],
      "source": [
        "%%capture output\n",
        "! pip install -r /content/drive/MyDrive/models/requirements.txt -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUCYDz1wSHQY"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture output\n",
        "! pip install langchain-ollama \"ollama==0.4.2\" -qqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Em8JUPSIhs"
      },
      "source": [
        "# Install Ollama\n",
        "- curl https://ollama.ai/install.sh | sh\n",
        "\n",
        "- Run server with: ollama serve &\n",
        "\n",
        "- Pull model ollama: pull llama3:8b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBzNjtDwZPvw"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3EXOkQuden6"
      },
      "outputs": [],
      "source": [
        "session_data_path = \"/content/drive/MyDrive/data/CSM/speaker_aggregated_info.json\"  # For Recommendation engine\n",
        "session_data_path = \"/content/drive/MyDrive/data/CSM/badge_id_aggregated_results.json\"\n",
        "nomenclature_embeddings_path = (\n",
        "    \"/content/drive/MyDrive/data/CSM/cluster_numeculature.json\"\n",
        ")\n",
        "output_path = \"/content/drive/MyDrive/data/CSM/badge/embeddings_badges_mistral.json\"\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/data/CSM/new_claire_db_badge_cluster_data_with_aggregated_info_GIO_GT_LABELS.csv\"\n",
        "# csv_path = '/content/drive/MyDrive/data/CSM/20240512_new_labels_WITH_AGGINFO.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sx-NBWyDv4xX",
        "outputId": "9773eb09-2279-451e-b812-2c838e44434d"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(csv_path)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK03xeagv4sv",
        "outputId": "8c17b9ae-40f2-470f-826d-4ebe46b0f7f8"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "5isNWQy-v4o3",
        "outputId": "d852334b-be52-4124-bd00-2f319121fa3e"
      },
      "outputs": [],
      "source": [
        "data.ClusterId.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_1V4rzpv4j-"
      },
      "outputs": [],
      "source": [
        "df_networking = data[data[\"ClusterId\"] == \"Networking\"]\n",
        "df_learning = data[data[\"ClusterId\"] == \"Learning\"]\n",
        "df_searching = data[data[\"ClusterId\"] == \"Searching\"]\n",
        "df_sourcing_early = data[data[\"ClusterId\"] == \"Sourcing – Early\"]\n",
        "df_sourcing_inprocess = data[data[\"ClusterId\"] == \"Sourcing – In Process\"]\n",
        "df_sourcing_deciding = data[data[\"ClusterId\"] == \"Sourcing – Deciding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c96Uu4Vw_kQ"
      },
      "outputs": [],
      "source": [
        "example_networking = df_networking[0:1].to_dict()\n",
        "example_learning = df_learning[0:1].to_dict()\n",
        "example_searching = df_searching[0:1].to_dict()\n",
        "example_sourcing_early = df_sourcing_early[0:1].to_dict()\n",
        "example_sourcing_inprocess = df_sourcing_inprocess[0:1].to_dict()\n",
        "example_sourcing_deciding = df_sourcing_deciding[0:1].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoJPwhDW1o0U"
      },
      "outputs": [],
      "source": [
        "list_examples = [\n",
        "    example_networking,\n",
        "    example_learning,\n",
        "    example_searching,\n",
        "    example_sourcing_early,\n",
        "    example_sourcing_inprocess,\n",
        "    example_sourcing_deciding,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua4QuuKDypuD"
      },
      "outputs": [],
      "source": [
        "examples = {}\n",
        "for example in list_examples:\n",
        "\n",
        "    examples[list(example[\"ClusterId\"].values())[0]] = list(\n",
        "        example[\"AggregatedInfo\"].values()\n",
        "    )[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj22BkkoyzVW",
        "outputId": "6541489d-35d5-418b-c693-d5d9d0752480"
      },
      "outputs": [],
      "source": [
        "examples.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8c_ZqA3w_fR"
      },
      "outputs": [],
      "source": [
        "df_networking = df_networking[1:]\n",
        "df_learning = df_learning[1:]\n",
        "df_searching = df_searching[1:]\n",
        "df_sourcing_early = df_sourcing_early[1:]\n",
        "df_sourcing_inprocess = df_sourcing_inprocess[1:]\n",
        "df_sourcing_deciding = df_sourcing_deciding[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtXFr8ySxqcU"
      },
      "outputs": [],
      "source": [
        "with open(nomenclature_embeddings_path, \"r\") as f:\n",
        "    nomenclatures = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y63Sg73kx89-"
      },
      "outputs": [],
      "source": [
        "# nomenclatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcgAnjblx85y"
      },
      "outputs": [],
      "source": [
        "text_example = df_searching[0:1][\"AggregatedInfo\"].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74H9E_P8x81y"
      },
      "outputs": [],
      "source": [
        "# Function to generate the classification prompt\n",
        "def generate_prompt(label_dict, examples, text_example):\n",
        "    prompt = \"Categories and Descriptions:\\n\\n\"\n",
        "    for label, description in label_dict.items():\n",
        "        prompt += f\"Category: {label} --> {description[len(label)+1:]}\\n\"\n",
        "\n",
        "    prompt += \"\\nExamples: (1 text associated to a category)\\n\"\n",
        "    for label, example in examples.items():\n",
        "        prompt += f\"Category: {label} --> {example}\\n\"\n",
        "\n",
        "    prompt += \"\\nText to classify:\\n\"\n",
        "    prompt += \"----------------------------------------------------\\n\"\n",
        "    prompt += text_example\n",
        "    prompt += \"----------------------------------------------------\\n\"\n",
        "    prompt += \"\\n\\n Only return a class label among these 6:\\\n",
        "        'Networking', 'Learning', 'Searching', 'Sourcing – Early', 'Sourcing – In Process', 'Sourcing – Deciding' \"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdNYZNqix8xI",
        "outputId": "d9165348-d836-48e1-8fb6-884baa3eb6ce"
      },
      "outputs": [],
      "source": [
        "prompt = generate_prompt(nomenclatures, examples, text_example)\n",
        "len(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28gJFqEbx8tb",
        "outputId": "f7735f1d-46a1-4170-95d8-e02cb01f1aeb"
      },
      "outputs": [],
      "source": [
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Qkn62CgQto"
      },
      "source": [
        "# DeepSeek R1 Distill Qwen 1.5B\n",
        "\n",
        "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
        "\n",
        "https://ollama.com/library/deepseek-r1\n",
        "\n",
        "ollama run deepseek-r1:1.5b\n",
        "\n",
        "Q4_K - Medium\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yaT-v9iY4ck"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.messages import AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sZlODj6rZIVb",
        "outputId": "f6ebce44-4bee-40bb-894b-8f4e7f324eb9"
      },
      "outputs": [],
      "source": [
        "llm = ChatOllama(\n",
        "    model=\"deepseek-r1:1.5b\",\n",
        "    temperature=0.5,\n",
        "    num_ctx=16000,\n",
        ")\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a clever chatbot specialized in classify text.Only provide Label, no other Information. Let's think step by Step\",\n",
        "    ),\n",
        "    (\"human\", prompt),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "\n",
        "print(ai_msg.content)\n",
        "print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Odsh7Be-uer",
        "outputId": "63a2772e-e440-4304-988d-7ed29dee1475"
      },
      "outputs": [],
      "source": [
        "llm = ChatOllama(\n",
        "    model=\"llama3.2:3b-instruct-q4_K_M\",\n",
        "    temperature=0.5,\n",
        "    num_ctx=16000,\n",
        ")\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a clever chatbot specialized in classify text.Only provide Label, no other Information. Let's think step by Step\",\n",
        "    ),\n",
        "    (\"human\", prompt),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "\n",
        "print(ai_msg.content)\n",
        "print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92KmSNXD-_Xh",
        "outputId": "0d55f22c-df4c-43a0-81e3-644c52529348"
      },
      "outputs": [],
      "source": [
        "llm = ChatOllama(\n",
        "    model=\"phi3.5\",\n",
        "    temperature=0.5,\n",
        "    num_ctx=16000,\n",
        ")\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a clever chatbot specialized in classify text.Only provide Label, no other Information. Let's think step by Step\",\n",
        "    ),\n",
        "    (\"human\", prompt),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "\n",
        "print(ai_msg.content)\n",
        "print(\"-\" * 100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO4LnEnRj3PEK9mbN8vnpjy",
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
