{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03671e7c-c954-4ca6-8610-7921e5c9df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import nats\n",
    "from nats.js.api import StreamConfig, ConsumerConfig, AckPolicy, RetentionPolicy, DiscardPolicy\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(os.path.join(\"keys\", \".env\"))\n",
    "\n",
    "# NATS connection settings\n",
    "NAT_URL = os.getenv(\"NAT_URL\", \"nats://localhost:4222\")\n",
    "OUTPUT_STREAM = os.getenv(\"OUTPUT_STREAM\", \"PII-RESULTS\")\n",
    "OUTPUT_SUBJECT = os.getenv(\"OUTPUT_SUBJECT\", \"pii.results.completed\")  # Removed '>' suffix\n",
    "LOCAL_ENV = os.getenv(\"LOCAL_ENV\", \"1\")\n",
    "\n",
    "# Create output directory for results\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Display current configuration\n",
    "print(\"NATS Consumer Configuration:\")\n",
    "print(f\"NATS URL: {NAT_URL}\")\n",
    "print(f\"Output Stream: {OUTPUT_STREAM}\")\n",
    "print(f\"Output Subject: {OUTPUT_SUBJECT}\")\n",
    "print(f\"Local Environment: {LOCAL_ENV}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622f386-d7d0-491f-8015-5b3c127bd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pii_results(data):\n",
    "    \"\"\"Analyze PII findings from a single result\"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Extract the data section from the result\n",
    "    documents = data.get(\"result\", {}).get(\"data\", [])\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"No documents found in result\")\n",
    "        return\n",
    "    \n",
    "    total_documents = len(documents)\n",
    "    total_pii_items = 0\n",
    "    pii_by_type = {}\n",
    "    \n",
    "    for document in documents:\n",
    "        # Extract PII items\n",
    "        pii_items = document.get(\"pii_items\", [])\n",
    "        total_pii_items += len(pii_items)\n",
    "        \n",
    "        # Count by PII type\n",
    "        for item in pii_items:\n",
    "            pii_type = item.get(\"type\", \"unknown\")\n",
    "            if pii_type in pii_by_type:\n",
    "                pii_by_type[pii_type] += 1\n",
    "            else:\n",
    "                pii_by_type[pii_type] = 1\n",
    "    \n",
    "    print(f\"Total documents analyzed: {total_documents}\")\n",
    "    print(f\"Total PII items found: {total_pii_items}\")\n",
    "    print(\"\\nPII by type:\")\n",
    "    for pii_type, count in sorted(pii_by_type.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  - {pii_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a022a-558f-4cf1-92c2-07d2215f7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def monitor_stream_for_new_messages(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    stream_name=OUTPUT_STREAM,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1  # Seconds between polling the stream\n",
    "):\n",
    "    \"\"\"\n",
    "    Monitor a NATS stream for new messages based on the last seen sequence.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        stream_name: The stream name to read from\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "    \n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "    \n",
    "    # Initialize start_time\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Get stream info to find the current last sequence\n",
    "        try:\n",
    "            stream_info = await js.stream_info(stream_name)\n",
    "            last_seq = stream_info.state.last_seq\n",
    "            print(f\"Connected to stream '{stream_name}'\")\n",
    "            print(f\"Stream contains {stream_info.state.messages} messages\")\n",
    "            print(f\"Last sequence is {last_seq}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting stream info: {e}\")\n",
    "            return messages_processed\n",
    "        \n",
    "        print(f\"Stream monitor will run for {run_time_seconds} seconds or until interrupted\")\n",
    "        print(f\"Results will be saved to {output_dir}\")\n",
    "        print(\"Monitoring for new messages...\")\n",
    "        \n",
    "        # Current sequence to start from\n",
    "        current_seq = last_seq + 1\n",
    "        \n",
    "        # Poll the stream until the run time is reached\n",
    "        while (datetime.now() - start_time).total_seconds() < run_time_seconds:\n",
    "            try:\n",
    "                # Get the current stream info\n",
    "                stream_info = await js.stream_info(stream_name)\n",
    "                new_last_seq = stream_info.state.last_seq\n",
    "                \n",
    "                # Check if there are new messages\n",
    "                if new_last_seq >= current_seq:\n",
    "                    print(f\"Found {new_last_seq - current_seq + 1} new messages\")\n",
    "                    \n",
    "                    # Get messages from current_seq to new_last_seq\n",
    "                    for seq in range(current_seq, new_last_seq + 1):\n",
    "                        try:\n",
    "                            # Get the message at this sequence\n",
    "                            msg = await js.get_msg(stream_name, seq)\n",
    "                            \n",
    "                            # Parse message data\n",
    "                            data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "                            \n",
    "                            # Extract filename from headers if available\n",
    "                            if hasattr(msg, 'headers') and msg.headers and \"filename\" in msg.headers:\n",
    "                                filename = msg.headers[\"filename\"]\n",
    "                            else:\n",
    "                                # Generate a unique filename\n",
    "                                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                filename = f\"result_{timestamp}_{seq}.json\"\n",
    "                            \n",
    "                            # Save result to file\n",
    "                            output_path = os.path.join(output_dir, filename)\n",
    "                            with open(output_path, \"w\") as f:\n",
    "                                json.dump(data, f, indent=2)\n",
    "                            \n",
    "                            # Increment counter and display info\n",
    "                            messages_processed += 1\n",
    "                            print(f\"Received message #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "                            \n",
    "                            # Analyze the PII findings\n",
    "                            print(\"\\nPII Analysis:\")\n",
    "                            analyze_pii_results(data)\n",
    "                            print(\"-\" * 50)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing message with seq={seq}: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Update current_seq\n",
    "                    current_seq = new_last_seq + 1\n",
    "                else:\n",
    "                    # No new messages\n",
    "                    print(\"No new messages found. Waiting...\")\n",
    "                \n",
    "                # Wait before polling again\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error polling stream: {str(e)}\")\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nReceived interrupt signal, shutting down...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in monitor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "    \n",
    "    # Print summary\n",
    "    run_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"\\nMonitor summary:\")\n",
    "    print(f\"- Run time: {run_time:.2f} seconds\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {output_dir}\")\n",
    "    \n",
    "    return messages_processed\n",
    "\n",
    "# Alternative approach: Process existing messages and then monitor for new ones\n",
    "async def process_and_monitor_stream(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    stream_name=OUTPUT_STREAM,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1,  # Seconds between polling the stream\n",
    "    start_from_beginning=False  # Whether to process all existing messages\n",
    "):\n",
    "    \"\"\"\n",
    "    Process existing messages in a stream and then monitor for new ones.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        stream_name: The stream name to read from\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "        start_from_beginning: Whether to process all existing messages\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "    \n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "    \n",
    "    # Initialize start_time\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Get stream info\n",
    "        try:\n",
    "            stream_info = await js.stream_info(stream_name)\n",
    "            total_messages = stream_info.state.messages\n",
    "            first_seq = stream_info.state.first_seq\n",
    "            last_seq = stream_info.state.last_seq\n",
    "            \n",
    "            print(f\"Connected to stream '{stream_name}'\")\n",
    "            print(f\"Stream contains {total_messages} messages\")\n",
    "            print(f\"Sequence range: {first_seq} to {last_seq}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting stream info: {e}\")\n",
    "            return messages_processed\n",
    "        \n",
    "        # Determine starting sequence\n",
    "        if start_from_beginning and total_messages > 0:\n",
    "            current_seq = first_seq\n",
    "            print(f\"Will process all existing messages starting from sequence {current_seq}\")\n",
    "        else:\n",
    "            current_seq = last_seq + 1\n",
    "            print(f\"Will only process new messages starting from sequence {current_seq}\")\n",
    "        \n",
    "        print(f\"Stream processor will run for {run_time_seconds} seconds or until interrupted\")\n",
    "        print(f\"Results will be saved to {output_dir}\")\n",
    "        print(\"Processing messages...\")\n",
    "        \n",
    "        # Process messages until the run time is reached\n",
    "        while (datetime.now() - start_time).total_seconds() < run_time_seconds:\n",
    "            try:\n",
    "                # Get the current stream info\n",
    "                stream_info = await js.stream_info(stream_name)\n",
    "                new_last_seq = stream_info.state.last_seq\n",
    "                \n",
    "                # Check if there are messages to process\n",
    "                if new_last_seq >= current_seq:\n",
    "                    if current_seq <= last_seq:\n",
    "                        print(f\"Processing {min(new_last_seq, last_seq) - current_seq + 1} existing messages\")\n",
    "                    else:\n",
    "                        print(f\"Found {new_last_seq - current_seq + 1} new messages\")\n",
    "                    \n",
    "                    # Get messages from current_seq to new_last_seq\n",
    "                    for seq in range(current_seq, new_last_seq + 1):\n",
    "                        try:\n",
    "                            # Get the message at this sequence\n",
    "                            msg = await js.get_msg(stream_name, seq)\n",
    "                            \n",
    "                            # Parse message data\n",
    "                            data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "                            \n",
    "                            # Extract filename from headers if available\n",
    "                            if hasattr(msg, 'headers') and msg.headers and \"filename\" in msg.headers:\n",
    "                                filename = msg.headers[\"filename\"]\n",
    "                            else:\n",
    "                                # Generate a unique filename\n",
    "                                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                filename = f\"result_{timestamp}_{seq}.json\"\n",
    "                            \n",
    "                            # Save result to file\n",
    "                            output_path = os.path.join(output_dir, filename)\n",
    "                            with open(output_path, \"w\") as f:\n",
    "                                json.dump(data, f, indent=2)\n",
    "                            \n",
    "                            # Increment counter and display info\n",
    "                            messages_processed += 1\n",
    "                            print(f\"Processed message #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "                            \n",
    "                            # Analyze the PII findings\n",
    "                            print(\"\\nPII Analysis:\")\n",
    "                            analyze_pii_results(data)\n",
    "                            print(\"-\" * 50)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing message with seq={seq}: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Update current_seq\n",
    "                    current_seq = new_last_seq + 1\n",
    "                else:\n",
    "                    # No new messages\n",
    "                    print(\"No new messages found. Waiting...\")\n",
    "                \n",
    "                # Wait before polling again\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error polling stream: {str(e)}\")\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nReceived interrupt signal, shutting down...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "    \n",
    "    # Print summary\n",
    "    run_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"\\nProcessor summary:\")\n",
    "    print(f\"- Run time: {run_time:.2f} seconds\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {output_dir}\")\n",
    "    \n",
    "    return messages_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa13364-111b-4dc4-a378-0c68cd70b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = 3600  # 1 hour\n",
    "\n",
    "# Set the output directory for results\n",
    "output_directory = \"output\"\n",
    "\n",
    "poll_interval = 1\n",
    "start_from_beginning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c39660-3a16-413e-9b7c-9166b4a306fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor only new messages\n",
    "messages_processed = await monitor_stream_for_new_messages(\n",
    "    output_dir=output_directory,\n",
    "    run_time_seconds=run_time,\n",
    "    poll_interval=poll_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f17286-1482-442d-96dd-c307781978c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process queue from begining\n",
    "messages_processed = await process_and_monitor_stream(\n",
    "    output_dir=output_directory,\n",
    "    run_time_seconds=run_time,\n",
    "    poll_interval=poll_interval,\n",
    "    start_from_beginning=start_from_beginning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b26bb-d5f0-4e2f-a2d4-4cbab43d16b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43dabac-a0f3-4fc7-9302-17815703b09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nats)",
   "language": "python",
   "name": "nats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
