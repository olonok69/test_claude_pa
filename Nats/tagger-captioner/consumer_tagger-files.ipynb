{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff07662-81e9-499b-b06f-5a245ffe9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import nats\n",
    "from nats.js.api import StreamConfig, ConsumerConfig, AckPolicy, RetentionPolicy, DiscardPolicy\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, JSON, Image as IPImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(os.path.join(\"keys\", \".env\"))\n",
    "\n",
    "# NATS connection settings\n",
    "NAT_URL = os.getenv(\"NAT_URL\", \"nats://localhost:4222\")\n",
    "\n",
    "# Get mode-specific stream and subject settings - use the new separated streams\n",
    "OUTPUT_STREAM_TAGGER = os.getenv(\"OUTPUT_STREAM_TAGGER\", \"IMAGE-RESULTS-TAGGER\")\n",
    "OUTPUT_SUBJECT_TAGGER = os.getenv(\"OUTPUT_SUBJECT_TAGGER\", \"tagger.results.completed.>\")\n",
    "\n",
    "OUTPUT_STREAM_CAPTIONING = os.getenv(\"OUTPUT_STREAM_CAPTIONING\", \"IMAGE-RESULTS-CAPTIONING\")\n",
    "OUTPUT_SUBJECT_CAPTIONING = os.getenv(\"OUTPUT_SUBJECT_CAPTIONING\", \"caption.results.completed.>\")\n",
    "\n",
    "LOCAL_ENV = os.getenv(\"LOCAL_ENV\", \"1\")\n",
    "\n",
    "# Create output directories for results\n",
    "OUTPUT_DIR = \"output_images\"\n",
    "OUTPUT_DIR_TAGGING = os.path.join(OUTPUT_DIR, \"tagging\")\n",
    "OUTPUT_DIR_CAPTIONING = os.path.join(OUTPUT_DIR, \"captioning\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_TAGGING, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_CAPTIONING, exist_ok=True)\n",
    "\n",
    "# Display current configuration\n",
    "print(\"NATS Image Consumer Configuration:\")\n",
    "print(f\"NATS URL: {NAT_URL}\")\n",
    "print(f\"Tagging Stream: {OUTPUT_STREAM_TAGGER}\")\n",
    "print(f\"Tagging Subject: {OUTPUT_SUBJECT_TAGGER}\")\n",
    "print(f\"Captioning Stream: {OUTPUT_STREAM_CAPTIONING}\")\n",
    "print(f\"Captioning Subject: {OUTPUT_SUBJECT_CAPTIONING}\")\n",
    "print(f\"Local Environment: {LOCAL_ENV}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"  - Tagging Results: {OUTPUT_DIR_TAGGING}\")\n",
    "print(f\"  - Captioning Results: {OUTPUT_DIR_CAPTIONING}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1d245-5238-4b9a-8617-70bdf01dab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_results(data, mode=\"auto\"):\n",
    "    \"\"\"\n",
    "    Analyze image processing results from a single result\n",
    "\n",
    "    Args:\n",
    "        data: The result data to analyze\n",
    "        mode: Processing mode - \"tagging\", \"captioning\", or \"auto\" (detect)\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to analyze\")\n",
    "        return\n",
    "\n",
    "    # Extract the data section from the result\n",
    "    documents = data.get(\"data\", [])\n",
    "\n",
    "    if not documents:\n",
    "        print(\"No documents found in result\")\n",
    "        return\n",
    "\n",
    "    # Detect mode if set to auto\n",
    "    if mode == \"auto\":\n",
    "        # Check the first document's content format to determine the mode\n",
    "        if documents and \"source\" in documents[0]:\n",
    "            content = documents[0][\"source\"].get(\"content\", [])\n",
    "            # If content is a list of dictionaries with 'label' and 'confidence', it's tagging\n",
    "            if isinstance(content, list) and content and isinstance(content, list):\n",
    "                if content and isinstance(content[0], dict) and \"label\" in content[0] and \"confidence\" in content[0]:\n",
    "                    mode = \"tagging\"\n",
    "                # If content is a list of strings, it's captioning\n",
    "                elif content and isinstance(content[0], str):\n",
    "                    mode = \"captioning\"\n",
    "                else:\n",
    "                    mode = \"unknown\"\n",
    "\n",
    "    print(f\"Analyzing results in {mode.upper()} mode\")\n",
    "\n",
    "    # Analyze based on detected or specified mode\n",
    "    if mode == \"tagging\":\n",
    "        analyze_tagging_results(documents)\n",
    "    elif mode == \"captioning\":\n",
    "        analyze_captioning_results(documents)\n",
    "    else:\n",
    "        print(f\"Unknown result format - cannot analyze\")\n",
    "\n",
    "\n",
    "def analyze_tagging_results(documents):\n",
    "    \"\"\"Analyze image tagging results\"\"\"\n",
    "    total_documents = len(documents)\n",
    "    total_tags = 0\n",
    "    tags_by_confidence = {}\n",
    "\n",
    "    for document in documents:\n",
    "        # Extract source information for display\n",
    "        source_info = document.get(\"source\", {})\n",
    "        file_name = source_info.get(\"file_name\", \"unknown\")\n",
    "\n",
    "        print(f\"\\nDocument: {document.get('id', 'unknown')}\")\n",
    "        print(f\"File: {file_name}\")\n",
    "\n",
    "        # Extract tags/labels\n",
    "        tags = source_info.get(\"content\", [])\n",
    "        total_tags += len(tags)\n",
    "\n",
    "        # Display tags with confidence\n",
    "        if tags:\n",
    "            print(\"\\nTags:\")\n",
    "            for tag in tags:\n",
    "                label = tag.get(\"label\", \"unknown\")\n",
    "                confidence = tag.get(\"confidence\", 0)\n",
    "\n",
    "                # Group tags by confidence level\n",
    "                confidence_level = round(confidence * 10) / 10  # Round to 1 decimal\n",
    "                if confidence_level in tags_by_confidence:\n",
    "                    tags_by_confidence[confidence_level].append(label)\n",
    "                else:\n",
    "                    tags_by_confidence[confidence_level] = [label]\n",
    "\n",
    "                print(f\"  - {label}: {confidence:.4f}\")\n",
    "        else:\n",
    "            print(\"No tags found for this document\")\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total documents analyzed: {total_documents}\")\n",
    "    print(f\"Total tags found: {total_tags}\")\n",
    "    print(\"\\nTags by confidence level:\")\n",
    "    for confidence, tags in sorted(tags_by_confidence.items(), key=lambda x: x[0], reverse=True):\n",
    "        print(f\"  Confidence {confidence:.1f}: {len(tags)} tags\")\n",
    "        if confidence >= 0.5:  # Only show high confidence tags in summary\n",
    "            tag_list = \", \".join(tags)\n",
    "            print(f\"    Tags: {tag_list}\")\n",
    "\n",
    "\n",
    "def analyze_captioning_results(documents):\n",
    "    \"\"\"Analyze image captioning results\"\"\"\n",
    "    total_documents = len(documents)\n",
    "\n",
    "    print(f\"\\nCAPTIONING RESULTS\")\n",
    "    print(f\"Total documents analyzed: {total_documents}\")\n",
    "\n",
    "    for document in documents:\n",
    "        # Extract source information for display\n",
    "        source_info = document.get(\"source\", {})\n",
    "        file_name = source_info.get(\"file_name\", \"unknown\")\n",
    "\n",
    "        print(f\"\\nDocument: {document.get('id', 'unknown')}\")\n",
    "        print(f\"File: {file_name}\")\n",
    "\n",
    "        # Extract caption/description\n",
    "        captions = source_info.get(\"content\", [])\n",
    "\n",
    "        # Display captions\n",
    "        if captions:\n",
    "            print(\"\\nCaption:\")\n",
    "            for caption in captions:\n",
    "                print(f\"  {caption}\")\n",
    "        else:\n",
    "            print(\"No caption found for this document\")\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Processed {total_documents} image(s) with the captioning model\")\n",
    "\n",
    "\n",
    "def visualize_top_tags(data, max_tags=10):\n",
    "    \"\"\"Create a simple visualization of top tags from the data\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    # Extract the data section from the result\n",
    "    documents = data.get(\"data\", [])\n",
    "\n",
    "    if not documents:\n",
    "        return\n",
    "\n",
    "    # Check if this is tagging data\n",
    "    if not documents or \"source\" not in documents[0]:\n",
    "        print(\"No tagging data to visualize\")\n",
    "        return\n",
    "\n",
    "    # Get first document to check content format\n",
    "    first_doc = documents[0]\n",
    "    content = first_doc.get(\"source\", {}).get(\"content\", [])\n",
    "\n",
    "    # Check if this is tagging data\n",
    "    if not content or not isinstance(content, list) or not isinstance(content[0], dict) or \"label\" not in content[0]:\n",
    "        print(\"This appears to be captioning data, not tagging data - no visualization available\")\n",
    "        return\n",
    "\n",
    "    # Collect all tags with their confidences\n",
    "    tag_counts = {}\n",
    "\n",
    "    for document in documents:\n",
    "        tags = document.get(\"source\", {}).get(\"content\", [])\n",
    "\n",
    "        for tag in tags:\n",
    "            label = tag.get(\"label\", \"unknown\")\n",
    "            confidence = tag.get(\"confidence\", 0)\n",
    "\n",
    "            if label in tag_counts:\n",
    "                tag_counts[label] = max(tag_counts[label], confidence)  # Keep highest confidence\n",
    "            else:\n",
    "                tag_counts[label] = confidence\n",
    "\n",
    "    # Sort by confidence and get top tags\n",
    "    top_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:max_tags]\n",
    "\n",
    "    if not top_tags:\n",
    "        print(\"No tags to visualize\")\n",
    "        return\n",
    "\n",
    "    # Create visualization\n",
    "    labels = [tag[0] for tag in top_tags]\n",
    "    confidences = [tag[1] for tag in top_tags]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(labels, confidences, color='skyblue')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.title('Top Tags by Confidence')\n",
    "    plt.xlim(0, 1.0)\n",
    "    plt.gca().invert_yaxis()  # Highest confidence at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "async def monitor_stream_for_new_messages(\n",
    "    mode=\"tagging\",\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1  # Seconds between polling the stream\n",
    "):\n",
    "    \"\"\"\n",
    "    Monitor a NATS stream for new messages based on the last seen sequence.\n",
    "\n",
    "    Args:\n",
    "        mode: Which mode to monitor - \"tagging\", \"captioning\", or \"both\"\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "    \"\"\"\n",
    "    # Determine which streams and subjects to monitor based on mode\n",
    "    streams_to_monitor = {}\n",
    "    \n",
    "    if mode == \"tagging\":\n",
    "        streams_to_monitor[OUTPUT_STREAM_TAGGER] = [OUTPUT_SUBJECT_TAGGER]\n",
    "        result_dir = OUTPUT_DIR_TAGGING\n",
    "    elif mode == \"captioning\":\n",
    "        streams_to_monitor[OUTPUT_STREAM_CAPTIONING] = [OUTPUT_SUBJECT_CAPTIONING]\n",
    "        result_dir = OUTPUT_DIR_CAPTIONING\n",
    "    elif mode == \"both\":\n",
    "        streams_to_monitor[OUTPUT_STREAM_TAGGER] = [OUTPUT_SUBJECT_TAGGER]\n",
    "        streams_to_monitor[OUTPUT_STREAM_CAPTIONING] = [OUTPUT_SUBJECT_CAPTIONING]\n",
    "        result_dir = OUTPUT_DIR  # Use parent directory for both modes\n",
    "    else:\n",
    "        print(f\"Invalid mode: {mode}. Please use 'tagging', 'captioning', or 'both'\")\n",
    "        return 0\n",
    "\n",
    "    if not streams_to_monitor:\n",
    "        print(f\"No streams to monitor for mode: {mode}\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"Monitoring {mode} mode with streams: {list(streams_to_monitor.keys())}\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "\n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "\n",
    "    # Initialize start_time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    try:\n",
    "        # Get stream info to find the current last sequence for each stream\n",
    "        current_seq_by_stream = {}\n",
    "        \n",
    "        for stream_name in streams_to_monitor:\n",
    "            try:\n",
    "                stream_info = await js.stream_info(stream_name)\n",
    "                last_seq = stream_info.state.last_seq\n",
    "                print(f\"Connected to stream '{stream_name}'\")\n",
    "                print(f\"Stream contains {stream_info.state.messages} messages\")\n",
    "                print(f\"Last sequence is {last_seq}\")\n",
    "                \n",
    "                # Set current sequence to start from\n",
    "                current_seq_by_stream[stream_name] = last_seq + 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting stream info for {stream_name}: {e}\")\n",
    "                current_seq_by_stream[stream_name] = 1  # Start from beginning if error\n",
    "\n",
    "        print(f\"Stream monitor will run for {run_time_seconds} seconds or until interrupted\")\n",
    "        print(f\"Results will be saved to {result_dir}\")\n",
    "        print(\"Monitoring for new messages...\")\n",
    "\n",
    "        # Poll the streams until the run time is reached\n",
    "        while (datetime.now() - start_time).total_seconds() < run_time_seconds:\n",
    "            any_new_messages = False\n",
    "            \n",
    "            # Check each stream for new messages\n",
    "            for stream_name, subjects in streams_to_monitor.items():\n",
    "                try:\n",
    "                    # Get the current stream info\n",
    "                    stream_info = await js.stream_info(stream_name)\n",
    "                    new_last_seq = stream_info.state.last_seq\n",
    "                    current_seq = current_seq_by_stream[stream_name]\n",
    "\n",
    "                    # Check if there are new messages in this stream\n",
    "                    if new_last_seq >= current_seq:\n",
    "                        print(f\"Found {new_last_seq - current_seq + 1} new messages in stream {stream_name}\")\n",
    "                        any_new_messages = True\n",
    "\n",
    "                        # Get messages from current_seq to new_last_seq\n",
    "                        for seq in range(current_seq, new_last_seq + 1):\n",
    "                            try:\n",
    "                                # Get the message at this sequence\n",
    "                                msg = await js.get_msg(stream_name, seq)\n",
    "\n",
    "                                # Check if message subject is in our list of subjects to monitor\n",
    "                                if msg.subject not in subjects:\n",
    "                                    print(f\"Skipping message with subject {msg.subject}\")\n",
    "                                    continue\n",
    "\n",
    "                                # Determine the mode from the stream and subject\n",
    "                                if stream_name == OUTPUT_STREAM_TAGGER:\n",
    "                                    msg_mode = \"tagging\"\n",
    "                                    msg_result_dir = OUTPUT_DIR_TAGGING\n",
    "                                else:\n",
    "                                    msg_mode = \"captioning\"\n",
    "                                    msg_result_dir = OUTPUT_DIR_CAPTIONING\n",
    "\n",
    "                                # Parse message data\n",
    "                                data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "\n",
    "                                # Extract filename from headers if available\n",
    "                                if hasattr(msg, 'headers') and msg.headers and \"filename\" in msg.headers:\n",
    "                                    orig_filename = msg.headers[\"filename\"]\n",
    "                                    filename = f\"result_{orig_filename}.json\"\n",
    "                                else:\n",
    "                                    # Generate a unique filename\n",
    "                                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                    filename = f\"result_{timestamp}_{seq}.json\"\n",
    "\n",
    "                                # Save result to file\n",
    "                                output_path = os.path.join(msg_result_dir, filename)\n",
    "                                with open(output_path, \"w\") as f:\n",
    "                                    json.dump(data, f, indent=2)\n",
    "\n",
    "                                # Increment counter and display info\n",
    "                                messages_processed += 1\n",
    "                                print(f\"Received {msg_mode} message #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "\n",
    "                                # Analyze the results based on mode\n",
    "                                print(f\"\\n{msg_mode.upper()} Analysis:\")\n",
    "                                analyze_image_results(data, mode=msg_mode)\n",
    "\n",
    "                                # Visualize top tags for tagging mode\n",
    "                                if msg_mode == \"tagging\":\n",
    "                                    print(\"\\nVisualizing top tags:\")\n",
    "                                    visualize_top_tags(data)\n",
    "\n",
    "                                print(\"-\" * 50)\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing message from {stream_name} with seq={seq}: {str(e)}\")\n",
    "                                continue\n",
    "\n",
    "                        # Update current_seq for this stream\n",
    "                        current_seq_by_stream[stream_name] = new_last_seq + 1\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error polling stream {stream_name}: {str(e)}\")\n",
    "            \n",
    "            if not any_new_messages:\n",
    "                # No new messages in any stream\n",
    "                print(\"No new messages found. Waiting...\")\n",
    "\n",
    "            # Wait before polling again\n",
    "            await asyncio.sleep(poll_interval)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nReceived interrupt signal, shutting down...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in monitor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "\n",
    "    # Print summary\n",
    "    run_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"\\nMonitor summary:\")\n",
    "    print(f\"- Run time: {run_time:.2f} seconds\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {result_dir}\")\n",
    "\n",
    "    return messages_processed\n",
    "\n",
    "\n",
    "# Alternative approach: Process existing messages and then monitor for new ones\n",
    "async def process_and_monitor_stream(\n",
    "    mode=\"tagging\",\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1,  # Seconds between polling the stream\n",
    "    start_from_beginning=False  # Whether to process all existing messages\n",
    "):\n",
    "    \"\"\"\n",
    "    Process existing messages in a stream and then monitor for new ones.\n",
    "\n",
    "    Args:\n",
    "        mode: Which mode to monitor - \"tagging\", \"captioning\", or \"both\"\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "        start_from_beginning: Whether to process all existing messages\n",
    "    \"\"\"\n",
    "    # Determine which streams and subjects to monitor based on mode\n",
    "    streams_to_monitor = {}\n",
    "    \n",
    "    if mode == \"tagging\":\n",
    "        streams_to_monitor[OUTPUT_STREAM_TAGGER] = [OUTPUT_SUBJECT_TAGGER]\n",
    "        result_dir = OUTPUT_DIR_TAGGING\n",
    "    elif mode == \"captioning\":\n",
    "        streams_to_monitor[OUTPUT_STREAM_CAPTIONING] = [OUTPUT_SUBJECT_CAPTIONING]\n",
    "        result_dir = OUTPUT_DIR_CAPTIONING\n",
    "    elif mode == \"both\":\n",
    "        streams_to_monitor[OUTPUT_STREAM_TAGGER] = [OUTPUT_SUBJECT_TAGGER]\n",
    "        streams_to_monitor[OUTPUT_STREAM_CAPTIONING] = [OUTPUT_SUBJECT_CAPTIONING]\n",
    "        result_dir = OUTPUT_DIR  # Use parent directory for both modes\n",
    "    else:\n",
    "        print(f\"Invalid mode: {mode}. Please use 'tagging', 'captioning', or 'both'\")\n",
    "        return 0\n",
    "\n",
    "    if not streams_to_monitor:\n",
    "        print(f\"No streams to monitor for mode: {mode}\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"Processing and monitoring {mode} mode with streams: {list(streams_to_monitor.keys())}\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if mode == \"both\":\n",
    "        os.makedirs(OUTPUT_DIR_TAGGING, exist_ok=True)\n",
    "        os.makedirs(OUTPUT_DIR_CAPTIONING, exist_ok=True)\n",
    "    else:\n",
    "        os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "\n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "\n",
    "    # Initialize start_time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    try:\n",
    "        # Get stream info for each stream\n",
    "        stream_info_by_stream = {}\n",
    "        current_seq_by_stream = {}\n",
    "        \n",
    "        for stream_name in streams_to_monitor:\n",
    "            try:\n",
    "                stream_info = await js.stream_info(stream_name)\n",
    "                stream_info_by_stream[stream_name] = stream_info\n",
    "                \n",
    "                total_messages = stream_info.state.messages\n",
    "                first_seq = stream_info.state.first_seq\n",
    "                last_seq = stream_info.state.last_seq\n",
    "\n",
    "                print(f\"Connected to stream '{stream_name}'\")\n",
    "                print(f\"Stream contains {total_messages} messages\")\n",
    "                print(f\"Sequence range: {first_seq} to {last_seq}\")\n",
    "                \n",
    "                # Determine starting sequence based on start_from_beginning flag\n",
    "                if start_from_beginning and total_messages > 0:\n",
    "                    current_seq_by_stream[stream_name] = first_seq\n",
    "                    print(f\"Will process all existing messages in {stream_name} starting from sequence {first_seq}\")\n",
    "                else:\n",
    "                    current_seq_by_stream[stream_name] = last_seq + 1\n",
    "                    print(f\"Will only process new messages in {stream_name} starting from sequence {last_seq + 1}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error getting stream info for {stream_name}: {e}\")\n",
    "                current_seq_by_stream[stream_name] = 1  # Start from beginning if error\n",
    "\n",
    "        print(f\"Stream processor will run for {run_time_seconds} seconds or until interrupted\")\n",
    "        print(f\"Results will be saved to {output_dir}\")\n",
    "        print(\"Processing messages...\")\n",
    "\n",
    "        # Process messages until the run time is reached\n",
    "        while (datetime.now() - start_time).total_seconds() < run_time_seconds:\n",
    "            any_new_messages = False\n",
    "            \n",
    "            # Check each stream for messages to process\n",
    "            for stream_name, subjects in streams_to_monitor.items():\n",
    "                try:\n",
    "                    # Get the current stream info\n",
    "                    stream_info = await js.stream_info(stream_name)\n",
    "                    new_last_seq = stream_info.state.last_seq\n",
    "                    current_seq = current_seq_by_stream[stream_name]\n",
    "                    \n",
    "                    # Get last seen sequence from previous check\n",
    "                    prev_last_seq = stream_info_by_stream.get(stream_name, stream_info).state.last_seq\n",
    "\n",
    "                    # Check if there are messages to process in this stream\n",
    "                    if new_last_seq >= current_seq:\n",
    "                        if current_seq <= prev_last_seq:\n",
    "                            print(f\"Processing {min(new_last_seq, prev_last_seq) - current_seq + 1} existing messages in {stream_name}\")\n",
    "                        else:\n",
    "                            print(f\"Found {new_last_seq - current_seq + 1} new messages in {stream_name}\")\n",
    "                            \n",
    "                        any_new_messages = True\n",
    "\n",
    "                        # Get messages from current_seq to new_last_seq\n",
    "                        for seq in range(current_seq, new_last_seq + 1):\n",
    "                            try:\n",
    "                                # Get the message at this sequence\n",
    "                                msg = await js.get_msg(stream_name, seq)\n",
    "\n",
    "                                # Check if message subject is in our list of subjects to monitor\n",
    "                                if msg.subject not in subjects:\n",
    "                                    print(f\"Skipping message with subject {msg.subject}\")\n",
    "                                    continue\n",
    "\n",
    "                                # Determine the mode and result directory from the stream\n",
    "                                if stream_name == OUTPUT_STREAM_TAGGER:\n",
    "                                    msg_mode = \"tagging\"\n",
    "                                    msg_result_dir = OUTPUT_DIR_TAGGING\n",
    "                                else:\n",
    "                                    msg_mode = \"captioning\"\n",
    "                                    msg_result_dir = OUTPUT_DIR_CAPTIONING\n",
    "\n",
    "                                # Parse message data\n",
    "                                data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "\n",
    "                                # Extract filename from headers if available\n",
    "                                if hasattr(msg, 'headers') and msg.headers and \"filename\" in msg.headers:\n",
    "                                    orig_filename = msg.headers[\"filename\"]\n",
    "                                    filename = f\"result_{orig_filename}.json\"\n",
    "                                else:\n",
    "                                    # Generate a unique filename\n",
    "                                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                    filename = f\"result_{timestamp}_{seq}.json\"\n",
    "\n",
    "                                # Save result to file\n",
    "                                output_path = os.path.join(msg_result_dir, filename)\n",
    "                                with open(output_path, \"w\") as f:\n",
    "                                    json.dump(data, f, indent=2)\n",
    "\n",
    "                                # Increment counter and display info\n",
    "                                messages_processed += 1\n",
    "                                print(f\"Processed {msg_mode} message #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "\n",
    "                                # Analyze the results based on mode\n",
    "                                print(f\"\\n{msg_mode.upper()} Analysis:\")\n",
    "                                analyze_image_results(data, mode=msg_mode)\n",
    "\n",
    "                                # Visualize top tags for tagging mode\n",
    "                                if msg_mode == \"tagging\":\n",
    "                                    print(\"\\nVisualizing top tags:\")\n",
    "                                    visualize_top_tags(data)\n",
    "\n",
    "                                print(\"-\" * 50)\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing message from {stream_name} with seq={seq}: {str(e)}\")\n",
    "                                continue\n",
    "\n",
    "                        # Update current_seq for this stream\n",
    "                        current_seq_by_stream[stream_name] = new_last_seq + 1\n",
    "                        \n",
    "                    # Update stored stream info\n",
    "                    stream_info_by_stream[stream_name] = stream_info\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error polling stream {stream_name}: {str(e)}\")\n",
    "            \n",
    "            if not any_new_messages:\n",
    "                # No new messages in any stream\n",
    "                print(\"No new messages found. Waiting...\")\n",
    "\n",
    "            # Wait before polling again\n",
    "            await asyncio.sleep(poll_interval)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nReceived interrupt signal, shutting down...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "\n",
    "    # Print summary\n",
    "    run_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"\\nProcessor summary:\")\n",
    "    print(f\"- Run time: {run_time:.2f} seconds\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {output_dir}\")\n",
    "\n",
    "    return messages_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e721c4e-680d-40f1-a48d-75e0ff86960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Monitor only tagging results using the dedicated tagging stream\n",
    "await monitor_stream_for_new_messages(\n",
    "    mode=\"tagging\", \n",
    "    run_time_seconds=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0c8b4-d3f6-4bec-8e1e-db1a39a2194a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Option 2: Monitor only captioning results using the dedicated captioning stream\n",
    "await monitor_stream_for_new_messages(\n",
    "    mode=\"captioning\", \n",
    "    run_time_seconds=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4741c-223e-4463-8f19-a6a2923e75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Process existing tagging messages and monitor for new ones\n",
    "await process_and_monitor_stream(\n",
    "    mode=\"tagging\",\n",
    "    run_time_seconds=3600,\n",
    "    poll_interval=1,\n",
    "    start_from_beginning=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3b531-6ba7-42ae-926d-b4d7758868b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 4: Process existing captioning messages and monitor for new ones\n",
    "await process_and_monitor_stream(\n",
    "    mode=\"captioning\",\n",
    "    run_time_seconds=3600,\n",
    "    poll_interval=1,\n",
    "    start_from_beginning=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b0977-b8bd-44bc-ace7-95950c949b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Option 5: Monitor both tagging and captioning streams for new messages\n",
    "await monitor_stream_for_new_messages(\n",
    "    mode=\"both\",\n",
    "    run_time_seconds=3600,\n",
    "    poll_interval=1\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Option 6: Process all existing messages from both streams and monitor for new ones\n",
    "await process_and_monitor_stream(\n",
    "    mode=\"both\",\n",
    "    run_time_seconds=3600,\n",
    "    poll_interval=1,\n",
    "    start_from_beginning=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e59596-c76e-4a59-aced-956fa6d0ca05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pii)",
   "language": "python",
   "name": "pii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
