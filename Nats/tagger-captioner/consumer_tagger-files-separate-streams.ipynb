{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff07662-81e9-499b-b06f-5a245ffe9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import nats\n",
    "from nats.js.api import StreamConfig, ConsumerConfig, AckPolicy, RetentionPolicy, DiscardPolicy\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, JSON, Image as IPImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(os.path.join(\"keys\", \".env\"))\n",
    "\n",
    "# NATS connection settings\n",
    "NAT_URL = os.getenv(\"NAT_URL\", \"nats://localhost:4222\")\n",
    "OUTPUT_STREAM = os.getenv(\"OUTPUT_STREAM\", \"IMAGE-RESULTS\")\n",
    "\n",
    "# Get mode-specific subjects\n",
    "OUTPUT_SUBJECT_TAGGER = os.getenv(\"OUTPUT_SUBJECT_TAGGER\", \"tagger.results.completed\")\n",
    "OUTPUT_SUBJECT_CAPTIONING = os.getenv(\"OUTPUT_SUBJECT_CAPTIONING\", \"caption.results.completed\")\n",
    "\n",
    "LOCAL_ENV = os.getenv(\"LOCAL_ENV\", \"1\")\n",
    "\n",
    "# Create output directories for results\n",
    "OUTPUT_DIR = \"output_images\"\n",
    "OUTPUT_DIR_TAGGING = os.path.join(OUTPUT_DIR, \"tagging\")\n",
    "OUTPUT_DIR_CAPTIONING = os.path.join(OUTPUT_DIR, \"captioning\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_TAGGING, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_CAPTIONING, exist_ok=True)\n",
    "\n",
    "# Display current configuration\n",
    "print(\"NATS Image Consumer Configuration:\")\n",
    "print(f\"NATS URL: {NAT_URL}\")\n",
    "print(f\"Output Stream: {OUTPUT_STREAM}\")\n",
    "print(f\"Tagging Subject: {OUTPUT_SUBJECT_TAGGER}\")\n",
    "print(f\"Captioning Subject: {OUTPUT_SUBJECT_CAPTIONING}\")\n",
    "print(f\"Local Environment: {LOCAL_ENV}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"  - Tagging Results: {OUTPUT_DIR_TAGGING}\")\n",
    "print(f\"  - Captioning Results: {OUTPUT_DIR_CAPTIONING}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1d245-5238-4b9a-8617-70bdf01dab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_results(data, mode=\"auto\"):\n",
    "    \"\"\"\n",
    "    Analyze image processing results from a single result\n",
    "    \n",
    "    Args:\n",
    "        data: The result data to analyze\n",
    "        mode: Processing mode - \"tagging\", \"captioning\", or \"auto\" (detect)\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Extract the data section from the result\n",
    "    documents = data.get(\"data\", [])\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"No documents found in result\")\n",
    "        return\n",
    "    \n",
    "    # Detect mode if set to auto\n",
    "    if mode == \"auto\":\n",
    "        # Check the first document's content format to determine the mode\n",
    "        if documents and \"source\" in documents[0]:\n",
    "            content = documents[0][\"source\"].get(\"content\", [])\n",
    "            # If content is a list of dictionaries with 'label' and 'confidence', it's tagging\n",
    "            if isinstance(content, list) and content and isinstance(content, list):\n",
    "                if content and isinstance(content[0], dict) and \"label\" in content[0] and \"confidence\" in content[0]:\n",
    "                    mode = \"tagging\"\n",
    "                # If content is a list of strings, it's captioning\n",
    "                elif content and isinstance(content[0], str):\n",
    "                    mode = \"captioning\"\n",
    "                else:\n",
    "                    mode = \"unknown\"\n",
    "    \n",
    "    print(f\"Analyzing results in {mode.upper()} mode\")\n",
    "    \n",
    "    # Analyze based on detected or specified mode\n",
    "    if mode == \"tagging\":\n",
    "        analyze_tagging_results(documents)\n",
    "    elif mode == \"captioning\":\n",
    "        analyze_captioning_results(documents)\n",
    "    else:\n",
    "        print(f\"Unknown result format - cannot analyze\")\n",
    "\n",
    "\n",
    "def analyze_tagging_results(documents):\n",
    "    \"\"\"Analyze image tagging results\"\"\"\n",
    "    total_documents = len(documents)\n",
    "    total_tags = 0\n",
    "    tags_by_confidence = {}\n",
    "    \n",
    "    for document in documents:\n",
    "        # Extract source information for display\n",
    "        source_info = document.get(\"source\", {})\n",
    "        file_name = source_info.get(\"file_name\", \"unknown\")\n",
    "        \n",
    "        print(f\"\\nDocument: {document.get('id', 'unknown')}\")\n",
    "        print(f\"File: {file_name}\")\n",
    "        \n",
    "        # Extract tags/labels\n",
    "        tags = source_info.get(\"content\", [])\n",
    "        total_tags += len(tags)\n",
    "        \n",
    "        # Display tags with confidence\n",
    "        if tags:\n",
    "            print(\"\\nTags:\")\n",
    "            for tag in tags:\n",
    "                label = tag.get(\"label\", \"unknown\")\n",
    "                confidence = tag.get(\"confidence\", 0)\n",
    "                \n",
    "                # Group tags by confidence level\n",
    "                confidence_level = round(confidence * 10) / 10  # Round to 1 decimal\n",
    "                if confidence_level in tags_by_confidence:\n",
    "                    tags_by_confidence[confidence_level].append(label)\n",
    "                else:\n",
    "                    tags_by_confidence[confidence_level] = [label]\n",
    "                \n",
    "                print(f\"  - {label}: {confidence:.4f}\")\n",
    "        else:\n",
    "            print(\"No tags found for this document\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total documents analyzed: {total_documents}\")\n",
    "    print(f\"Total tags found: {total_tags}\")\n",
    "    print(\"\\nTags by confidence level:\")\n",
    "    for confidence, tags in sorted(tags_by_confidence.items(), key=lambda x: x[0], reverse=True):\n",
    "        print(f\"  Confidence {confidence:.1f}: {len(tags)} tags\")\n",
    "        if confidence >= 0.5:  # Only show high confidence tags in summary\n",
    "            tag_list = \", \".join(tags)\n",
    "            print(f\"    Tags: {tag_list}\")\n",
    "\n",
    "\n",
    "def analyze_captioning_results(documents):\n",
    "    \"\"\"Analyze image captioning results\"\"\"\n",
    "    total_documents = len(documents)\n",
    "    \n",
    "    print(f\"\\nCAPTIONING RESULTS\")\n",
    "    print(f\"Total documents analyzed: {total_documents}\")\n",
    "    \n",
    "    for document in documents:\n",
    "        # Extract source information for display\n",
    "        source_info = document.get(\"source\", {})\n",
    "        file_name = source_info.get(\"file_name\", \"unknown\")\n",
    "        \n",
    "        print(f\"\\nDocument: {document.get('id', 'unknown')}\")\n",
    "        print(f\"File: {file_name}\")\n",
    "        \n",
    "        # Extract caption/description\n",
    "        captions = source_info.get(\"content\", [])\n",
    "        \n",
    "        # Display captions\n",
    "        if captions:\n",
    "            print(\"\\nCaption:\")\n",
    "            for caption in captions:\n",
    "                print(f\"  {caption}\")\n",
    "        else:\n",
    "            print(\"No caption found for this document\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Processed {total_documents} image(s) with the captioning model\")\n",
    "\n",
    "\n",
    "def visualize_top_tags(data, max_tags=10):\n",
    "    \"\"\"Create a simple visualization of top tags from the data\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "    \n",
    "    # Extract the data section from the result\n",
    "    documents = data.get(\"data\", [])\n",
    "    \n",
    "    if not documents:\n",
    "        return\n",
    "    \n",
    "    # Check if this is tagging data\n",
    "    if not documents or \"source\" not in documents[0]:\n",
    "        print(\"No tagging data to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Get first document to check content format\n",
    "    first_doc = documents[0]\n",
    "    content = first_doc.get(\"source\", {}).get(\"content\", [])\n",
    "    \n",
    "    # Check if this is tagging data\n",
    "    if not content or not isinstance(content, list) or not isinstance(content[0], dict) or \"label\" not in content[0]:\n",
    "        print(\"This appears to be captioning data, not tagging data - no visualization available\")\n",
    "        return\n",
    "    \n",
    "    # Collect all tags with their confidences\n",
    "    tag_counts = {}\n",
    "    \n",
    "    for document in documents:\n",
    "        tags = document.get(\"source\", {}).get(\"content\", [])\n",
    "        \n",
    "        for tag in tags:\n",
    "            label = tag.get(\"label\", \"unknown\")\n",
    "            confidence = tag.get(\"confidence\", 0)\n",
    "            \n",
    "            if label in tag_counts:\n",
    "                tag_counts[label] = max(tag_counts[label], confidence)  # Keep highest confidence\n",
    "            else:\n",
    "                tag_counts[label] = confidence\n",
    "    \n",
    "    # Sort by confidence and get top tags\n",
    "    top_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:max_tags]\n",
    "    \n",
    "    if not top_tags:\n",
    "        print(\"No tags to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Create visualization\n",
    "    labels = [tag[0] for tag in top_tags]\n",
    "    confidences = [tag[1] for tag in top_tags]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(labels, confidences, color='skyblue')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.title('Top Tags by Confidence')\n",
    "    plt.xlim(0, 1.0)\n",
    "    plt.gca().invert_yaxis()  # Highest confidence at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e721c4e-680d-40f1-a48d-75e0ff86960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def monitor_stream_for_new_messages(\n",
    "    mode=\"both\",\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    stream_name=OUTPUT_STREAM,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1  # Seconds between polling the stream\n",
    "):\n",
    "    \"\"\"\n",
    "    Monitor a NATS stream for new messages based on the last seen sequence.\n",
    "    \n",
    "    Args:\n",
    "        mode: Which mode to monitor - \"tagging\", \"captioning\", or \"both\"\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        stream_name: The stream name to read from\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "    \"\"\"\n",
    "    # Determine which subjects to monitor\n",
    "    subjects_to_monitor = []\n",
    "    if mode == \"tagging\" or mode == \"both\":\n",
    "        subjects_to_monitor.append(OUTPUT_SUBJECT_TAGGER)\n",
    "    if mode == \"captioning\" or mode == \"both\":\n",
    "        subjects_to_monitor.append(OUTPUT_SUBJECT_CAPTIONING)\n",
    "    \n",
    "    if not subjects_to_monitor:\n",
    "        print(f\"Invalid mode: {mode}. Please use 'tagging', 'captioning', or 'both'\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"Monitoring {mode} mode with subjects: {subjects_to_monitor}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "    \n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "    \n",
    "    # Initialize start_time\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Get stream info to find the current last sequence\n",
    "        try:\n",
    "            stream_info = await js.stream_info(stream_name)\n",
    "            last_seq = stream_info.state.last_seq\n",
    "            print(f\"Connected to stream '{stream_name}'\")\n",
    "            print(f\"Stream contains {stream_info.state.messages} messages\")\n",
    "            print(f\"Last sequence is {last_seq}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting stream info: {e}\")\n",
    "            return messages_processed\n",
    "        \n",
    "        print(f\"Stream monitor will run for {run_time_seconds} seconds or until interrupted\")\n",
    "        print(f\"Results will be saved to {output_dir}\")\n",
    "        print(\"Monitoring for new messages...\")\n",
    "        \n",
    "        # Current sequence to start from\n",
    "        current_seq = last_seq + 1\n",
    "        \n",
    "        # Poll the stream until the run time is reached\n",
    "        while (datetime.now() - start_time).total_seconds() < run_time_seconds:\n",
    "            try:\n",
    "                # Get the current stream info\n",
    "                stream_info = await js.stream_info(stream_name)\n",
    "                new_last_seq = stream_info.state.last_seq\n",
    "                \n",
    "                # Check if there are new messages\n",
    "                if new_last_seq >= current_seq:\n",
    "                    print(f\"Found {new_last_seq - current_seq + 1} new messages\")\n",
    "                    \n",
    "                    # Get messages from current_seq to new_last_seq\n",
    "                    for seq in range(current_seq, new_last_seq + 1):\n",
    "                        try:\n",
    "                            # Get the message at this sequence\n",
    "                            msg = await js.get_msg(stream_name, seq)\n",
    "                            \n",
    "                            # Check if message subject is in our list of subjects to monitor\n",
    "                            if msg.subject not in subjects_to_monitor:\n",
    "                                print(f\"Skipping message with subject {msg.subject}\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Determine the mode from the subject\n",
    "                            msg_mode = \"tagging\" if msg.subject == OUTPUT_SUBJECT_TAGGER else \"captioning\"\n",
    "                            \n",
    "                            # Set appropriate output directory based on mode\n",
    "                            if msg_mode == \"tagging\":\n",
    "                                result_dir = OUTPUT_DIR_TAGGING\n",
    "                            else:\n",
    "                                result_dir = OUTPUT_DIR_CAPTIONING\n",
    "                            \n",
    "                            # Parse message data\n",
    "                            data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "                            \n",
    "                            # Extract filename from headers if available\n",
    "                            if hasattr(msg, 'headers') and msg.headers and \"filename\" in msg.headers:\n",
    "                                orig_filename = msg.headers[\"filename\"]\n",
    "                                filename = f\"result_{orig_filename}.json\"\n",
    "                            else:\n",
    "                                # Generate a unique filename\n",
    "                                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                filename = f\"result_{timestamp}_{seq}.json\"\n",
    "                            \n",
    "                            # Save result to file\n",
    "                            output_path = os.path.join(result_dir, filename)\n",
    "                            with open(output_path, \"w\") as f:\n",
    "                                json.dump(data, f, indent=2)\n",
    "                            \n",
    "                            # Increment counter and display info\n",
    "                            messages_processed += 1\n",
    "                            print(f\"Received {msg_mode} message #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "                            \n",
    "                            # Analyze the results based on mode\n",
    "                            print(f\"\\n{msg_mode.upper()} Analysis:\")\n",
    "                            analyze_image_results(data, mode=msg_mode)\n",
    "                            \n",
    "                            # Visualize top tags for tagging mode\n",
    "                            if msg_mode == \"tagging\":\n",
    "                                print(\"\\nVisualizing top tags:\")\n",
    "                                visualize_top_tags(data)\n",
    "                            \n",
    "                            print(\"-\" * 50)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing message with seq={seq}: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Update current_seq\n",
    "                    current_seq = new_last_seq + 1\n",
    "                else:\n",
    "                    # No new messages\n",
    "                    print(\"No new messages found. Waiting...\")\n",
    "                \n",
    "                # Wait before polling again\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error polling stream: {str(e)}\")\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nReceived interrupt signal, shutting down...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in monitor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "    \n",
    "    # Print summary\n",
    "    run_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"\\nMonitor summary:\")\n",
    "    print(f\"- Run time: {run_time:.2f} seconds\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {output_dir}\")\n",
    "    \n",
    "    return messages_processed\n",
    "\n",
    "\n",
    "# Alternative approach: Process existing messages and then monitor for new ones\n",
    "async def process_and_monitor_stream(\n",
    "    mode=\"both\",\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    nats_url=NAT_URL,\n",
    "    stream_name=OUTPUT_STREAM,\n",
    "    run_time_seconds=3600,  # Default to run for 1 hour\n",
    "    poll_interval=1,  # Seconds between polling the stream\n",
    "    start_from_beginning=False  # Whether to process all existing messages\n",
    "):\n",
    "    \"\"\"\n",
    "    Process existing messages in a stream and then monitor for new ones.\n",
    "    \n",
    "    Args:\n",
    "        mode: Which mode to monitor - \"tagging\", \"captioning\", or \"both\"\n",
    "        output_dir: Directory to save output files\n",
    "        nats_url: The NATS server URL\n",
    "        stream_name: The stream name to read from\n",
    "        run_time_seconds: How long to run the consumer (in seconds)\n",
    "        poll_interval: Seconds between polling the stream\n",
    "        start_from_beginning: Whether to process all existing messages\n",
    "    \"\"\"\n",
    "    # Determine which subjects to monitor\n",
    "    subjects_to_monitor = []\n",
    "    if mode == \"tagging\" or mode == \"both\":\n",
    "        subjects_to_monitor.append(OUTPUT_SUBJECT_TAGGER)\n",
    "    if mode == \"captioning\" or mode == \"both\":\n",
    "        subjects_to_monitor.append(OUTPUT_SUBJECT_CAPTIONING)\n",
    "    \n",
    "    if not subjects_to_monitor:\n",
    "        print(f\"Invalid mode: {mode}. Please use 'tagging', 'captioning', or 'both'\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"Processing and monitoring {mode} mode with subjects: {subjects_to_monitor}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR_TAGGING, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_DIR_CAPTIONING, exist_ok=True)\n",
    "    \n",
    "    # Connect to NATS\n",
    "    nc = await nats.connect(nats_url)\n",
    "    js = nc.jetstream()\n",
    "    \n",
    "    # Track number of messages processed\n",
    "    messages_processed = 0\n",
    "    \n",
    "    # Initialize start_time\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # Get stream info\n",
    "        try:\n",
    "            stream_info = await js.stream_info(stream_name)\n",
    "            total_messages = stream_info.state.messages\n",
    "            first_seq = stream_info.state.first_seq\n",
    "            last_seq = stream_info.state.last_seq\n",
    "            \n",
    "            print(f\"Connected to stream '{stream_name}'\")\n",
    "            print(f\"Stream contains {total_messages} messages\")\n",
    "            print(f\"Sequence range: {first_seq} to {last_seq}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting stream info: {e}\")\n",
    "            return messages_processed\n",
    "        \n",
    "        # Determine starting sequence\n",
    "        if start_from_beginning and total_messages > 0:\n",
    "            current_seq = first_seq\n",
    "            print(f\"Will process all existing messages starting from sequence {current_seq}\")\n",
    "        else:\n",
    "            current_seq = last_seq + 1\n",
    "            print(f\"Will only process new messages starting from sequence {current_seq}\")\n",
    "        \n",
    "        print(f\"Stream processor will run for {run_time_seconds} seconds or until interrupted\")\n",
    "        print(f\"Results will be saved to {output_dir}\")\n",
    "        print(\"Processing messages...\")\n",
    "        \n",
    "        # Process messages until the run time is reached\n",
    "        while (datetime.now() - start_time).total_seconds() < run_time_seconds:\n",
    "            try:\n",
    "                # Get the current stream info\n",
    "                stream_info = await js.stream_info(stream_name)\n",
    "                new_last_seq = stream_info.state.last_seq\n",
    "                \n",
    "                # Check if there are messages to process\n",
    "                if new_last_seq >= current_seq:\n",
    "                    if current_seq <= last_seq:\n",
    "                        print(f\"Processing {min(new_last_seq, last_seq) - current_seq + 1} existing messages\")\n",
    "                    else:\n",
    "                        print(f\"Found {new_last_seq - current_seq + 1} new messages\")\n",
    "                    \n",
    "                    # Get messages from current_seq to new_last_seq\n",
    "                    for seq in range(current_seq, new_last_seq + 1):\n",
    "                        try:\n",
    "                            # Get the message at this sequence\n",
    "                            msg = await js.get_msg(stream_name, seq)\n",
    "                            \n",
    "                            # Check if message subject is in our list of subjects to monitor\n",
    "                            if msg.subject not in subjects_to_monitor:\n",
    "                                print(f\"Skipping message with subject {msg.subject}\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Determine the mode from the subject\n",
    "                            msg_mode = \"tagging\" if msg.subject == OUTPUT_SUBJECT_TAGGER else \"captioning\"\n",
    "                            \n",
    "                            # Set appropriate output directory based on mode\n",
    "                            if msg_mode == \"tagging\":\n",
    "                                result_dir = OUTPUT_DIR_TAGGING\n",
    "                            else:\n",
    "                                result_dir = OUTPUT_DIR_CAPTIONING\n",
    "                            \n",
    "                            # Parse message data\n",
    "                            data = json.loads(msg.data.decode(\"utf-8\"))\n",
    "                            \n",
    "                            # Extract filename from headers if available\n",
    "                            if hasattr(msg, 'headers') and msg.headers and \"filename\" in msg.headers:\n",
    "                                orig_filename = msg.headers[\"filename\"]\n",
    "                                filename = f\"result_{orig_filename}.json\"\n",
    "                            else:\n",
    "                                # Generate a unique filename\n",
    "                                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                filename = f\"result_{timestamp}_{seq}.json\"\n",
    "                            \n",
    "                            # Save result to file\n",
    "                            output_path = os.path.join(result_dir, filename)\n",
    "                            with open(output_path, \"w\") as f:\n",
    "                                json.dump(data, f, indent=2)\n",
    "                            \n",
    "                            # Increment counter and display info\n",
    "                            messages_processed += 1\n",
    "                            print(f\"Processed {msg_mode} message #{messages_processed}, seq={seq}, saved to {output_path}\")\n",
    "                            \n",
    "                            # Analyze the results based on mode\n",
    "                            print(f\"\\n{msg_mode.upper()} Analysis:\")\n",
    "                            analyze_image_results(data, mode=msg_mode)\n",
    "                            \n",
    "                            # Visualize top tags for tagging mode\n",
    "                            if msg_mode == \"tagging\":\n",
    "                                print(\"\\nVisualizing top tags:\")\n",
    "                                visualize_top_tags(data)\n",
    "                            \n",
    "                            print(\"-\" * 50)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing message with seq={seq}: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Update current_seq\n",
    "                    current_seq = new_last_seq + 1\n",
    "                else:\n",
    "                    # No new messages\n",
    "                    print(\"No new messages found. Waiting...\")\n",
    "                \n",
    "                # Wait before polling again\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error polling stream: {str(e)}\")\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nReceived interrupt signal, shutting down...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processor: {str(e)}\")\n",
    "    finally:\n",
    "        # Close NATS connection\n",
    "        await nc.close()\n",
    "        print(\"NATS connection closed\")\n",
    "    \n",
    "    # Print summary\n",
    "    run_time = (datetime.now() - start_time).total_seconds()\n",
    "    print(f\"\\nProcessor summary:\")\n",
    "    print(f\"- Run time: {run_time:.2f} seconds\")\n",
    "    print(f\"- Messages processed: {messages_processed}\")\n",
    "    print(f\"- Results saved to: {output_dir}\")\n",
    "    \n",
    "    return messages_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0c8b4-d3f6-4bec-8e1e-db1a39a2194a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example usage - choose one of these to run:\n",
    "\n",
    "# Option 1: Monitor only tagging results\n",
    "# await monitor_stream_for_new_messages(mode=\"tagging\", run_time_seconds=3600)\n",
    "\n",
    "# Option 2: Monitor only captioning results\n",
    "# await monitor_stream_for_new_messages(mode=\"captioning\", run_time_seconds=3600)\n",
    "\n",
    "# Option 3: Monitor both types of results (default)\n",
    "await process_and_monitor_stream(\n",
    "    mode=\"tagging\",\n",
    "    run_time_seconds=3600,\n",
    "    poll_interval=1,\n",
    "    start_from_beginning=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4741c-223e-4463-8f19-a6a2923e75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only tagging\n",
    "await monitor_stream_for_new_messages(mode=\"captioning\", run_time_seconds=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3b531-6ba7-42ae-926d-b4d7758868b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_and_monitor_stream(\n",
    "    mode=\"captioning\",\n",
    "    run_time_seconds=3600,\n",
    "    poll_interval=1,\n",
    "    start_from_beginning=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b0977-b8bd-44bc-ace7-95950c949b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Option 1: Monitor only new messages\n",
    "await monitor_stream_for_new_messages(\n",
    "    output_dir=output_directory,\n",
    "    run_time_seconds=run_time,\n",
    "    poll_interval=poll_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530edf3-41a9-4800-a244-84bd14cd639c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Option 2: Process queue from beginning\n",
    "await process_and_monitor_stream(\n",
    "    output_dir=output_directory,\n",
    "    run_time_seconds=run_time,\n",
    "    poll_interval=poll_interval,\n",
    "    start_from_beginning=start_from_beginning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e59596-c76e-4a59-aced-956fa6d0ca05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pii)",
   "language": "python",
   "name": "pii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
