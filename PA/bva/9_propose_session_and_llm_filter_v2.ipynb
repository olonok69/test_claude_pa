{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946182cc-5f56-4dff-9b57-50ca5ce58256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "import logging\n",
    "import concurrent.futures\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from neo4j import GraphDatabase\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Optional imports (for LangChain approach)\n",
    "try:\n",
    "    from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "    from langchain_openai import ChatOpenAI, AzureChatOpenAI, AzureOpenAI\n",
    "    from azure.ai.inference import ChatCompletionsClient\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from dotenv import dotenv_values\n",
    "\n",
    "    has_langchain = True\n",
    "except ImportError:\n",
    "    has_langchain = False\n",
    "    print(\"LangChain not available. Will use rule-based filtering only.\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(\"session_recommendation\")\n",
    "\n",
    "# Neo4j connection parameters\n",
    "uri = \"bolt://127.0.0.1:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"\"  # Replace with your password\n",
    "\n",
    "# Initialize Neo4j driver\n",
    "# driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Load the same embedding model for consistency\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Define role groups (for rule processing)\n",
    "VET_ROLES = [\n",
    "    \"Vet/Vet Surgeon\",\n",
    "    \"Assistant Vet\",\n",
    "    \"Vet/Owner\",\n",
    "    \"Clinical or other Director\",\n",
    "    \"Locum Vet\",\n",
    "    \"Academic\",\n",
    "]\n",
    "\n",
    "NURSE_ROLES = [\"Head Nurse/Senior Nurse\", \"Vet Nurse\", \"Locum RVN\"]\n",
    "\n",
    "BUSINESS = [\"Practice Manager\", \"Practice Partner/Owner\"]\n",
    "# Other roles can attend any session\n",
    "OTHER_ROLES = [\"Student\", \"Receptionist\", \"Other (please specify)\"]\n",
    "\n",
    "# Cache for this year's sessions and embeddings\n",
    "_this_year_sessions_cache = None\n",
    "_visitor_cache = {}\n",
    "_similar_visitors_cache = {}\n",
    "\n",
    "# == Session Recommendation System ==\n",
    "\n",
    "\n",
    "def clear_caches():\n",
    "    \"\"\"Clear all caches.\"\"\"\n",
    "    global _this_year_sessions_cache, _visitor_cache, _similar_visitors_cache\n",
    "    _this_year_sessions_cache = None\n",
    "    _visitor_cache = {}\n",
    "    _similar_visitors_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a864dfc-f4bf-49ba-b9d9-8d1770bd3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_this_year_sessions(tx):\n",
    "    \"\"\"\n",
    "    Get all sessions for this year with their embeddings.\n",
    "    Uses caching for better performance.\n",
    "    \"\"\"\n",
    "    global _this_year_sessions_cache\n",
    "\n",
    "    if _this_year_sessions_cache is not None:\n",
    "        return _this_year_sessions_cache\n",
    "\n",
    "    # Query to get this year's sessions with embeddings\n",
    "    query = \"\"\"\n",
    "    MATCH (s:Sessions_this_year)\n",
    "    WHERE s.embedding IS NOT NULL\n",
    "    RETURN s.session_id as session_id, \n",
    "           s.title as title, \n",
    "           s.stream as stream, \n",
    "           s.synopsis_stripped as synopsis_stripped,\n",
    "           s.theatre__name as theatre__name,\n",
    "           s.embedding as embedding,\n",
    "           s.date as date,\n",
    "           s.start_time as start_time,\n",
    "           s.end_time as end_time,\n",
    "           s.sponsored_by as sponsored_by,\n",
    "           s.sponsored_session as sponsored_session\n",
    "    \"\"\"\n",
    "\n",
    "    results = tx.run(query).data()\n",
    "\n",
    "    # Process results and cache them\n",
    "    sessions = {}\n",
    "    for r in results:\n",
    "        embedding = np.array(json.loads(r[\"embedding\"])) if r[\"embedding\"] else None\n",
    "\n",
    "        if embedding is not None:\n",
    "            sessions[r[\"session_id\"]] = {\n",
    "                \"session_id\": r[\"session_id\"],\n",
    "                \"title\": r[\"title\"],\n",
    "                \"stream\": r[\"stream\"],\n",
    "                \"synopsis_stripped\": r[\"synopsis_stripped\"],\n",
    "                \"theatre__name\": r[\"theatre__name\"],\n",
    "                \"embedding\": embedding,\n",
    "                \"date\": r[\"date\"],\n",
    "                \"start_time\": r[\"start_time\"],\n",
    "                \"end_time\": r[\"end_time\"],\n",
    "                \"sponsored_by\": r[\"sponsored_by\"],\n",
    "                \"sponsored_session\": r[\"sponsored_session\"],\n",
    "            }\n",
    "\n",
    "    _this_year_sessions_cache = sessions\n",
    "    return sessions\n",
    "\n",
    "\n",
    "def get_visitor_info(tx, visitor_id):\n",
    "    \"\"\"\n",
    "    Get visitor information with caching.\n",
    "    \"\"\"\n",
    "    global _visitor_cache\n",
    "\n",
    "    if visitor_id in _visitor_cache:\n",
    "        return _visitor_cache[visitor_id]\n",
    "\n",
    "    visitor_query = \"\"\"\n",
    "    MATCH (v:Visitor_this_year {BadgeId: $visitor_id})\n",
    "    RETURN v\n",
    "    \"\"\"\n",
    "    visitor_data = tx.run(visitor_query, visitor_id=visitor_id).single()\n",
    "\n",
    "    if not visitor_data:\n",
    "        return None\n",
    "\n",
    "    visitor = visitor_data[\"v\"]\n",
    "    assisted = visitor.get(\"assist_year_before\", \"0\")\n",
    "\n",
    "    _visitor_cache[visitor_id] = {\"visitor\": visitor, \"assisted\": assisted}\n",
    "    return _visitor_cache[visitor_id]\n",
    "\n",
    "\n",
    "def get_past_sessions(tx, visitor_id):\n",
    "    \"\"\"\n",
    "    Get sessions the visitor attended last year.\n",
    "    Optimized with a more efficient query.\n",
    "    \"\"\"\n",
    "    # Single query combining both visitor types\n",
    "    query_past = \"\"\"\n",
    "    MATCH (v:Visitor_this_year {BadgeId: $visitor_id})-[:Same_Visitor]->(vp)-[:attended_session]->(sp:Sessions_past_year)\n",
    "    WHERE (vp:Visitor_last_year_bva OR vp:Visitor_last_year_lva)\n",
    "    RETURN DISTINCT sp.session_id as session_id, sp.embedding as embedding\n",
    "    \"\"\"\n",
    "\n",
    "    results = tx.run(query_past, visitor_id=visitor_id).data()\n",
    "\n",
    "    # Process embeddings\n",
    "    sessions = []\n",
    "    for r in results:\n",
    "        embedding = np.array(json.loads(r[\"embedding\"])) if r[\"embedding\"] else None\n",
    "        if embedding is not None:\n",
    "            sessions.append({\"session_id\": r[\"session_id\"], \"embedding\": embedding})\n",
    "\n",
    "    return sessions\n",
    "\n",
    "\n",
    "def find_similar_visitors_batch(tx, visitor, num_similar_visitors=3):\n",
    "    \"\"\"\n",
    "    Find similar visitors with batch processing.\n",
    "    Uses a more efficient query and caching.\n",
    "    \"\"\"\n",
    "    global _similar_visitors_cache\n",
    "\n",
    "    visitor_id = visitor[\"BadgeId\"]\n",
    "\n",
    "    # Check cache first\n",
    "    if visitor_id in _similar_visitors_cache:\n",
    "        return _similar_visitors_cache[visitor_id]\n",
    "\n",
    "    # Get all visitors with sessions in one query\n",
    "    query = \"\"\"\n",
    "    MATCH (v:Visitor_this_year)\n",
    "    WHERE v.assist_year_before = '1' AND v.BadgeId <> $visitor_id\n",
    "    // Pre-filter to avoid processing all visitors\n",
    "    WITH v, \n",
    "         CASE WHEN v.job_role = $job_role THEN 1 ELSE 0 END + \n",
    "         CASE WHEN v.what_type_does_your_practice_specialise_in = $practice_type THEN 1 ELSE 0 END +\n",
    "         CASE WHEN v.organisation_type = $org_type THEN 1 ELSE 0 END +\n",
    "         CASE WHEN v.Country = $country THEN 1 ELSE 0 END AS base_similarity\n",
    "    // Only process those with some similarity\n",
    "    WHERE base_similarity > 0\n",
    "    // Check if they have attended sessions (to save processing visitors without sessions)\n",
    "    MATCH (v)-[:Same_Visitor]->(vp)-[:attended_session]->(sp:Sessions_past_year)\n",
    "    WHERE (vp:Visitor_last_year_bva OR vp:Visitor_last_year_lva)\n",
    "    WITH v, base_similarity, COUNT(DISTINCT sp) AS session_count\n",
    "    WHERE session_count > 0\n",
    "    RETURN v, base_similarity\n",
    "    ORDER BY base_similarity DESC, session_count DESC\n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "\n",
    "    visitors_data = tx.run(\n",
    "        query,\n",
    "        visitor_id=visitor_id,\n",
    "        job_role=visitor.get(\"job_role\", \"\"),\n",
    "        practice_type=visitor.get(\"what_type_does_your_practice_specialise_in\", \"\"),\n",
    "        org_type=visitor.get(\"organisation_type\", \"\"),\n",
    "        country=visitor.get(\"Country\", \"\"),\n",
    "    ).data()\n",
    "\n",
    "    # If we can't find enough similar visitors with the pre-filtering,\n",
    "    # try a more general query\n",
    "    if len(visitors_data) < num_similar_visitors:\n",
    "        query = \"\"\"\n",
    "        MATCH (v:Visitor_this_year)\n",
    "        WHERE v.assist_year_before = '1' AND v.BadgeId <> $visitor_id\n",
    "        // Check if they have attended sessions\n",
    "        MATCH (v)-[:Same_Visitor]->(vp)-[:attended_session]->(sp:Sessions_past_year)\n",
    "        WHERE (vp:Visitor_last_year_bva OR vp:Visitor_last_year_lva)\n",
    "        WITH v, COUNT(DISTINCT sp) AS session_count\n",
    "        WHERE session_count > 0\n",
    "        RETURN v, 0 AS base_similarity\n",
    "        ORDER BY session_count DESC\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "        visitors_data = tx.run(query, visitor_id=visitor_id).data()\n",
    "\n",
    "    # Extract visitor features for comparison\n",
    "    def get_visitor_features(v):\n",
    "        attributes = [\n",
    "            v.get(\"what_type_does_your_practice_specialise_in\", \"\"),\n",
    "            v.get(\"job_role\", \"\"),\n",
    "            v.get(\"organisation_type\", \"\"),\n",
    "            v.get(\"JobTitle\", \"\"),\n",
    "            v.get(\"Country\", \"\"),\n",
    "        ]\n",
    "        return \" \".join(\n",
    "            [\n",
    "                str(attr)\n",
    "                for attr in attributes\n",
    "                if attr and str(attr).strip() and str(attr) != \"NA\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Get embedding for our visitor\n",
    "    visitor_text = get_visitor_features(visitor)\n",
    "    if not visitor_text.strip():\n",
    "        visitor_text = \"default visitor profile\"\n",
    "\n",
    "    try:\n",
    "        # Load model here to ensure it's available\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        visitor_embedding = model.encode(visitor_text)\n",
    "\n",
    "        # Calculate similarities for top 20 pre-filtered visitors\n",
    "        similarities = []\n",
    "        for vdata in visitors_data:\n",
    "            v_compare = vdata[\"v\"]\n",
    "            base_similarity = vdata[\"base_similarity\"]\n",
    "\n",
    "            compare_text = get_visitor_features(v_compare)\n",
    "            if not compare_text.strip():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                compare_embedding = model.encode(compare_text)\n",
    "                sim = cosine_similarity([visitor_embedding], [compare_embedding])[0][0]\n",
    "                # Combine neural and rule-based similarity\n",
    "                combined_sim = (sim * 0.7) + (\n",
    "                    base_similarity * 0.3 / 4\n",
    "                )  # Max base_similarity is 4\n",
    "                similarities.append((v_compare[\"BadgeId\"], combined_sim))\n",
    "            except Exception as e:\n",
    "                print(f\"Error comparing with visitor {v_compare['BadgeId']}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Sort by similarity (highest first) and get top N\n",
    "        similarities.sort(key=lambda x: -x[1])\n",
    "        similar_visitors = [sid for sid, _ in similarities[:num_similar_visitors]]\n",
    "\n",
    "        # Cache for future use\n",
    "        _similar_visitors_cache[visitor_id] = similar_visitors\n",
    "        return similar_visitors\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding visitor profile: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_similar_visitor_sessions_batch(tx, similar_visitor_badge_ids):\n",
    "    \"\"\"\n",
    "    Get sessions attended by similar visitors using a batch query.\n",
    "    \"\"\"\n",
    "    if not similar_visitor_badge_ids:\n",
    "        return []\n",
    "\n",
    "    # Single query to get all sessions at once\n",
    "    query = \"\"\"\n",
    "    MATCH (v:Visitor_this_year)-[:Same_Visitor]->(vp)-[:attended_session]->(sp:Sessions_past_year)\n",
    "    WHERE v.BadgeId IN $similar_visitor_ids AND \n",
    "          (vp:Visitor_last_year_bva OR vp:Visitor_last_year_lva)\n",
    "    RETURN DISTINCT sp.session_id AS session_id, sp.embedding AS embedding\n",
    "    \"\"\"\n",
    "\n",
    "    results = tx.run(query, similar_visitor_ids=similar_visitor_badge_ids).data()\n",
    "\n",
    "    # Process embeddings\n",
    "    sessions = []\n",
    "    for r in results:\n",
    "        embedding = np.array(json.loads(r[\"embedding\"])) if r[\"embedding\"] else None\n",
    "        if embedding is not None:\n",
    "            sessions.append({\"session_id\": r[\"session_id\"], \"embedding\": embedding})\n",
    "\n",
    "    return sessions\n",
    "\n",
    "\n",
    "def calculate_session_similarities_parallel(\n",
    "    past_sessions, this_year_sessions, min_score=0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate similarities between past sessions and this year's sessions in parallel.\n",
    "\n",
    "    Args:\n",
    "        past_sessions: List of past session objects with embeddings\n",
    "        this_year_sessions: Dict of this year's session objects with embeddings\n",
    "        min_score: Minimum similarity score threshold\n",
    "\n",
    "    Returns:\n",
    "        List of recommended sessions with similarity scores\n",
    "    \"\"\"\n",
    "    if not past_sessions or not this_year_sessions:\n",
    "        return []\n",
    "\n",
    "    # Function to calculate similarity for a single past session against all this year sessions\n",
    "    def process_past_session(past_sess):\n",
    "        recommendations = []\n",
    "        past_emb = past_sess[\"embedding\"]\n",
    "\n",
    "        for sid, current_sess in this_year_sessions.items():\n",
    "            try:\n",
    "                current_emb = current_sess[\"embedding\"]\n",
    "                sim = cosine_similarity([past_emb], [current_emb])[0][0]\n",
    "\n",
    "                if sim >= min_score:\n",
    "                    recommendations.append(\n",
    "                        {\n",
    "                            \"session_id\": sid,\n",
    "                            \"title\": current_sess[\"title\"],\n",
    "                            \"stream\": current_sess[\"stream\"],\n",
    "                            \"theatre__name\": current_sess[\"theatre__name\"],\n",
    "                            \"date\": current_sess[\"date\"],\n",
    "                            \"start_time\": current_sess[\"start_time\"],\n",
    "                            \"end_time\": current_sess[\"end_time\"],\n",
    "                            \"sponsored_by\": current_sess.get(\"sponsored_by\", \"\"),\n",
    "                            \"sponsored_session\": current_sess.get(\n",
    "                                \"sponsored_session\", \"\"\n",
    "                            ),\n",
    "                            \"similarity\": sim,\n",
    "                        }\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating similarity for session {sid}: {e}\")\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    # Use parallel processing for faster calculation\n",
    "    all_recommendations = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(\n",
    "        max_workers=min(8, len(past_sessions))\n",
    "    ) as executor:\n",
    "        future_to_session = {\n",
    "            executor.submit(process_past_session, ps): ps for ps in past_sessions\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_session):\n",
    "            try:\n",
    "                recommendations = future.result()\n",
    "                all_recommendations.extend(recommendations)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing session: {e}\")\n",
    "\n",
    "    # Deduplicate recommendations, keeping the highest similarity score\n",
    "    session_to_best_rec = {}\n",
    "    for rec in all_recommendations:\n",
    "        sid = rec[\"session_id\"]\n",
    "        if (\n",
    "            sid not in session_to_best_rec\n",
    "            or rec[\"similarity\"] > session_to_best_rec[sid][\"similarity\"]\n",
    "        ):\n",
    "            session_to_best_rec[sid] = rec\n",
    "\n",
    "    # Convert back to list and sort by similarity\n",
    "    recommendations = list(session_to_best_rec.values())\n",
    "    recommendations.sort(key=lambda x: -x[\"similarity\"])\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581b047-28e2-435c-9d14-648709c01bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_sessions_optimized(\n",
    "    badge_id,\n",
    "    assist_year_before=\"1\",\n",
    "    min_score=0.0,\n",
    "    max_recommendations=None,\n",
    "    num_similar_visitors=3,\n",
    "    use_neo4j=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimized version of the recommend_sessions function.\n",
    "\n",
    "    Args:\n",
    "        badge_id: Visitor's badge ID\n",
    "        assist_year_before: \"1\" if visitor attended last year, \"0\" otherwise\n",
    "        min_score: Minimum similarity score for recommendations (0.0-1.0)\n",
    "        max_recommendations: Maximum number of recommendations to return\n",
    "        num_similar_visitors: Number of similar visitors to consider for case 2\n",
    "        use_neo4j: Whether to use Neo4j for real recommendations or mock data\n",
    "\n",
    "    Returns:\n",
    "        List of recommended sessions with details\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use mock recommendations if Neo4j is not available\n",
    "    if not use_neo4j:\n",
    "        print(f\"Using mock recommendations for visitor {badge_id}\")\n",
    "        recommendations = mock_get_recommendations(\n",
    "            badge_id, count=max_recommendations or 10\n",
    "        )\n",
    "        print(\n",
    "            f\"Generated {len(recommendations)} mock recommendations in {time.time() - start_time:.2f}s\"\n",
    "        )\n",
    "        return recommendations\n",
    "\n",
    "    # Initialize Neo4j driver and get recommendations\n",
    "    with GraphDatabase.driver(uri, auth=(username, password)) as driver:\n",
    "        with driver.session() as session:\n",
    "            # Get visitor information\n",
    "            visitor_info = session.execute_read(get_visitor_info, visitor_id=badge_id)\n",
    "            if not visitor_info:\n",
    "                print(f\"Visitor with BadgeId {badge_id} not found.\")\n",
    "                return []\n",
    "\n",
    "            visitor = visitor_info[\"visitor\"]\n",
    "            assisted = visitor_info[\"assisted\"]\n",
    "\n",
    "            # Get all this year's sessions in one go (uses caching)\n",
    "            this_year_sessions = session.execute_read(get_this_year_sessions)\n",
    "            print(\n",
    "                f\"Loaded {len(this_year_sessions)} sessions for this year in {time.time() - start_time:.2f}s\"\n",
    "            )\n",
    "\n",
    "            past_sessions = []\n",
    "\n",
    "            if assisted == \"1\":\n",
    "                # Case 1: Visitor attended last year\n",
    "                print(f\"Case 1: Visitor {badge_id} attended last year\")\n",
    "                case_start = time.time()\n",
    "\n",
    "                # Get sessions the visitor attended last year\n",
    "                past_sessions = session.execute_read(\n",
    "                    get_past_sessions, visitor_id=badge_id\n",
    "                )\n",
    "                print(\n",
    "                    f\"Found {len(past_sessions)} past sessions in {time.time() - case_start:.2f}s\"\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                # Case 2: New visitor - find similar visitors\n",
    "                print(\n",
    "                    f\"Case 2: Finding {num_similar_visitors} similar visitors for {badge_id}\"\n",
    "                )\n",
    "                case_start = time.time()\n",
    "\n",
    "                # Find similar visitors in batch\n",
    "                similar_visitors = session.execute_read(\n",
    "                    find_similar_visitors_batch,\n",
    "                    visitor=visitor,\n",
    "                    num_similar_visitors=num_similar_visitors,\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    f\"Found {len(similar_visitors)} similar visitors in {time.time() - case_start:.2f}s\"\n",
    "                )\n",
    "                sim_sessions_start = time.time()\n",
    "\n",
    "                if similar_visitors:\n",
    "                    # Get sessions attended by similar visitors in batch\n",
    "                    past_sessions = session.execute_read(\n",
    "                        get_similar_visitor_sessions_batch,\n",
    "                        similar_visitor_badge_ids=similar_visitors,\n",
    "                    )\n",
    "\n",
    "                    print(\n",
    "                        f\"Found {len(past_sessions)} sessions from similar visitors in {time.time() - sim_sessions_start:.2f}s\"\n",
    "                    )\n",
    "\n",
    "            # Calculate similarities in parallel\n",
    "            sim_calc_start = time.time()\n",
    "            recommendations = calculate_session_similarities_parallel(\n",
    "                past_sessions=past_sessions,\n",
    "                this_year_sessions=this_year_sessions,\n",
    "                min_score=min_score,\n",
    "            )\n",
    "            print(f\"Calculated similarities in {time.time() - sim_calc_start:.2f}s\")\n",
    "\n",
    "            # Apply maximum recommendations limit\n",
    "            if max_recommendations and len(recommendations) > max_recommendations:\n",
    "                recommendations = recommendations[:max_recommendations]\n",
    "\n",
    "            print(f\"Total recommendation time: {time.time() - start_time:.2f}s\")\n",
    "            return recommendations\n",
    "\n",
    "\n",
    "# == Session Filtering System ==\n",
    "\n",
    "\n",
    "class SessionFilter:\n",
    "    \"\"\"\n",
    "    Class for filtering recommended sessions based on business rules.\n",
    "    Designed to be flexible to accommodate changing business rules.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rules_config: Optional[Dict] = None):\n",
    "        \"\"\"\n",
    "        Initialize the session filter with optional rules configuration.\n",
    "\n",
    "        Args:\n",
    "            rules_config: Dictionary of rule configurations that can override defaults\n",
    "        \"\"\"\n",
    "        # Default rule set - can be overridden via rules_config\n",
    "        self.rules_config = {\n",
    "            \"equine_mixed_exclusions\": [\n",
    "                \"exotics\",\n",
    "                \"feline\",\n",
    "                \"exotic animal\",\n",
    "                \"farm\",\n",
    "                \"small animal\",\n",
    "            ],\n",
    "            \"small_animal_exclusions\": [\n",
    "                \"equine\",\n",
    "                \"farm animal\",\n",
    "                \"farm\",\n",
    "                \"large animal\",\n",
    "            ],\n",
    "            \"vet_exclusions\": [\"nursing\"],\n",
    "            \"nurse_streams\": [\"nursing\", \"wellbeing\", \"welfare\"],\n",
    "            \"rule_priority\": [\"practice_type\", \"role\"],  # Order of rule application\n",
    "        }\n",
    "\n",
    "        # Override defaults with provided config if any\n",
    "        if rules_config:\n",
    "            self.rules_config.update(rules_config)\n",
    "\n",
    "        # Register rule implementations\n",
    "        self.rule_implementations = {\n",
    "            \"practice_type\": self._apply_practice_type_rules,\n",
    "            \"role\": self._apply_role_rules,\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Session filter initialized with rules: {self.rules_config}\")\n",
    "\n",
    "    def _contains_any(self, text: str, keywords: List[str]) -> bool:\n",
    "        \"\"\"Check if text contains any of the keywords (case-insensitive).\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return False\n",
    "\n",
    "        text_lower = text.lower()\n",
    "        return any(keyword.lower() in text_lower for keyword in keywords)\n",
    "\n",
    "    def _apply_practice_type_rules(\n",
    "        self, visitor: Dict[str, Any], sessions: List[Dict[str, Any]]\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Apply practice type filtering rules.\"\"\"\n",
    "        if not visitor or \"what_type_does_your_practice_specialise_in\" not in visitor:\n",
    "            return sessions, []  # No filtering if practice type is missing\n",
    "\n",
    "        practice_type = visitor.get(\"what_type_does_your_practice_specialise_in\", \"\")\n",
    "        if not practice_type or practice_type == \"NA\":\n",
    "            return sessions, []\n",
    "\n",
    "        filtered_sessions = []\n",
    "        rules_applied = []\n",
    "\n",
    "        # Check if practice contains equine or mixed\n",
    "        if self._contains_any(practice_type, [\"equine\", \"mixed\"]):\n",
    "            exclusions = self.rules_config[\"equine_mixed_exclusions\"]\n",
    "            # Filter out sessions with excluded streams\n",
    "            filtered_sessions = [\n",
    "                session\n",
    "                for session in sessions\n",
    "                if not session.get(\"stream\")\n",
    "                or not self._contains_any(session[\"stream\"], exclusions)\n",
    "            ]\n",
    "            rules_applied.append(\n",
    "                f\"practice_type: mixed/equine - excluded {', '.join(exclusions)}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Applied equine/mixed rule: filtered from {len(sessions)} to {len(filtered_sessions)} sessions\"\n",
    "            )\n",
    "\n",
    "        # Check if practice contains small animal\n",
    "        elif self._contains_any(practice_type, [\"small animal\"]):\n",
    "            exclusions = self.rules_config[\"small_animal_exclusions\"]\n",
    "            # Filter out sessions with excluded streams\n",
    "            filtered_sessions = [\n",
    "                session\n",
    "                for session in sessions\n",
    "                if not session.get(\"stream\")\n",
    "                or not self._contains_any(session[\"stream\"], exclusions)\n",
    "            ]\n",
    "            rules_applied.append(\n",
    "                f\"practice_type: small animal - excluded {', '.join(exclusions)}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Applied small animal rule: filtered from {len(sessions)} to {len(filtered_sessions)} sessions\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # No specific practice type rule applies\n",
    "            filtered_sessions = sessions\n",
    "\n",
    "        return filtered_sessions, rules_applied\n",
    "\n",
    "    def _apply_role_rules(\n",
    "        self, visitor: Dict[str, Any], sessions: List[Dict[str, Any]]\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Apply job role filtering rules.\"\"\"\n",
    "        if not visitor or \"job_role\" not in visitor:\n",
    "            return sessions, []  # No filtering if job role is missing\n",
    "\n",
    "        job_role = visitor.get(\"job_role\", \"\")\n",
    "        if not job_role or job_role == \"NA\":\n",
    "            return sessions, []\n",
    "\n",
    "        filtered_sessions = []\n",
    "        rules_applied = []\n",
    "\n",
    "        # Rule for VET_ROLES\n",
    "        if job_role in VET_ROLES:\n",
    "            exclusions = self.rules_config[\"vet_exclusions\"]\n",
    "            # Filter out sessions with excluded streams\n",
    "            filtered_sessions = [\n",
    "                session\n",
    "                for session in sessions\n",
    "                if not session.get(\"stream\")\n",
    "                or not self._contains_any(session[\"stream\"], exclusions)\n",
    "            ]\n",
    "            rules_applied.append(f\"role: vet - excluded {', '.join(exclusions)}\")\n",
    "            logger.info(\n",
    "                f\"Applied vet role rule: filtered from {len(sessions)} to {len(filtered_sessions)} sessions\"\n",
    "            )\n",
    "\n",
    "        # Rule for NURSE_ROLES\n",
    "        elif job_role in NURSE_ROLES:\n",
    "            allowed_streams = self.rules_config[\"nurse_streams\"]\n",
    "            # Only keep sessions with allowed streams\n",
    "            filtered_sessions = [\n",
    "                session\n",
    "                for session in sessions\n",
    "                if session.get(\"stream\")\n",
    "                and self._contains_any(session[\"stream\"], allowed_streams)\n",
    "            ]\n",
    "            rules_applied.append(\n",
    "                f\"role: nurse - limited to {', '.join(allowed_streams)}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"Applied nurse role rule: filtered from {len(sessions)} to {len(filtered_sessions)} sessions\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # No specific role rule applies\n",
    "            filtered_sessions = sessions\n",
    "\n",
    "        return filtered_sessions, rules_applied\n",
    "\n",
    "    def filter_sessions(\n",
    "        self, visitor: Dict[str, Any], sessions: List[Dict[str, Any]]\n",
    "    ) -> (List[Dict[str, Any]], List[str]):\n",
    "        \"\"\"\n",
    "        Filter sessions based on visitor profile and business rules.\n",
    "\n",
    "        Args:\n",
    "            visitor: Dictionary containing visitor profile\n",
    "            sessions: List of session dictionaries to filter\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (filtered_sessions, rules_applied) where rules_applied is a list of rule descriptions\n",
    "        \"\"\"\n",
    "        if not sessions:\n",
    "            return [], []\n",
    "\n",
    "        filtered_sessions = sessions\n",
    "        rule_priority = self.rules_config[\"rule_priority\"]\n",
    "        all_rules_applied = []\n",
    "\n",
    "        # Apply rules in priority order\n",
    "        for rule_type in rule_priority:\n",
    "            if rule_type in self.rule_implementations:\n",
    "                rule_func = self.rule_implementations[rule_type]\n",
    "                filtered_sessions, rules_applied = rule_func(visitor, filtered_sessions)\n",
    "                all_rules_applied.extend(rules_applied)\n",
    "            else:\n",
    "                logger.warning(f\"Unknown rule type: {rule_type}\")\n",
    "\n",
    "        # Sort by similarity score (highest first)\n",
    "        filtered_sessions.sort(\n",
    "            key=lambda x: float(x.get(\"similarity\", 0)), reverse=True\n",
    "        )\n",
    "\n",
    "        return filtered_sessions, all_rules_applied\n",
    "\n",
    "    def update_rules(self, new_rules: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Update rule configurations at runtime.\n",
    "\n",
    "        Args:\n",
    "            new_rules: Dictionary of rule configurations to update\n",
    "        \"\"\"\n",
    "        self.rules_config.update(new_rules)\n",
    "        logger.info(f\"Updated rules configuration: {new_rules}\")\n",
    "\n",
    "    def add_rule_implementation(self, rule_name: str, rule_func: Callable) -> None:\n",
    "        \"\"\"\n",
    "        Add a new rule implementation or override an existing one.\n",
    "\n",
    "        Args:\n",
    "            rule_name: Name of the rule\n",
    "            rule_func: Function that implements the rule, should accept visitor and sessions parameters\n",
    "        \"\"\"\n",
    "        self.rule_implementations[rule_name] = rule_func\n",
    "        logger.info(f\"Added rule implementation: {rule_name}\")\n",
    "\n",
    "        # Ensure rule is in priority list\n",
    "        if rule_name not in self.rules_config[\"rule_priority\"]:\n",
    "            self.rules_config[\"rule_priority\"].append(rule_name)\n",
    "\n",
    "\n",
    "# == LangChain Filtering Approach ==\n",
    "\n",
    "\n",
    "def filter_with_langchain(visitor, recommendations, rules):\n",
    "    \"\"\"\n",
    "    Filter recommendations using LangChain and LLM.\n",
    "\n",
    "    Args:\n",
    "        visitor: Visitor profile dictionary\n",
    "        recommendations: List of recommended sessions\n",
    "        rules: Business rules text\n",
    "\n",
    "    Returns:\n",
    "        Filtered list of recommendations\n",
    "    \"\"\"\n",
    "    if not has_langchain:\n",
    "        logger.warning(\"LangChain not available. Cannot filter using LLM.\")\n",
    "        return recommendations, [\"LangChain filtering not available\"]\n",
    "\n",
    "    try:\n",
    "        # Load .env file\n",
    "        config = dotenv_values(\".env\")\n",
    "\n",
    "        # Initialize Azure OpenAI client\n",
    "        llm = AzureChatOpenAI(\n",
    "            azure_endpoint=config[\"AZURE_ENDPOINT\"],\n",
    "            azure_deployment=config[\"AZURE_DEPLOYMENT\"],\n",
    "            api_key=config[\"AZURE_API_KEY\"],\n",
    "            api_version=config[\"AZURE_API_VERSION\"],\n",
    "            temperature=0.5,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "\n",
    "        # Get keys from visitor and recommendations\n",
    "        list_keys_vis = list(visitor.keys())\n",
    "        if recommendations:\n",
    "            list_keys = list(recommendations[0].keys())\n",
    "        else:\n",
    "            list_keys = [\n",
    "                \"session_id\",\n",
    "                \"title\",\n",
    "                \"stream\",\n",
    "                \"theatre__name\",\n",
    "                \"date\",\n",
    "                \"start_time\",\n",
    "                \"end_time\",\n",
    "                \"sponsored_by\",\n",
    "                \"sponsored_session\",\n",
    "                \"similarity\",\n",
    "            ]\n",
    "\n",
    "        # Generate the prompt\n",
    "        system_prompt = f\"\"\"\n",
    "        you are an assistant specialized in filter sessions of an Event based in bussiness rules and profiles of users.\\n\n",
    "        - you will receive a profile of a visitor with the following keys: {list_keys_vis}\\n\n",
    "          the attribute what_type_does_your_practice_specialise_in can be a list of specializations separated by \";\"\n",
    "        - you will receive a list of session with the following keys: {list_keys}\\n\n",
    "          stream in session can be a list of tpocis separated by \";\". When you evaluate the rule you need to consider all of them \\n\n",
    "        - each session you return must have the same format.\n",
    "        - different Job_Roles Groups:\\n\n",
    "        VET_ROLES = [\n",
    "        \"Vet/Vet Surgeon\",\n",
    "        \"Assistant Vet\",\n",
    "        \"Vet/Owner\",\n",
    "        \"Clinical or other Director\",\n",
    "        \"Locum Vet\", \n",
    "        \"Academic\",\n",
    "        ]\\n\n",
    "        \n",
    "        NURSE_ROLES = [\"Head Nurse/Senior Nurse\", \"Vet Nurse\", \"Locum RVN\"]\\n\n",
    "        \n",
    "        BUSINESS = [\"Practice Manager\", \"Practice Partner/Owner\"]\\n\n",
    "        # Other roles can attend any session\n",
    "        OTHER_ROLES = [\"Student\", \"Receptionist\", \"Other (please specify)\"]\\n\n",
    "        - only return the sessions in json format\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"sessions\", \"rules\", \"profile\"],\n",
    "            template=system_prompt\n",
    "            + \"\"\"For the Visitor with profile {profile}\\n, based on the attributes of these session: {sessions} and implementing the following rules {rules}.\\n Filter them and just return from the list those that meet the requirements in the rules\"\"\",\n",
    "        )\n",
    "\n",
    "        # Create chain\n",
    "        chain = prompt | llm\n",
    "\n",
    "        # Convert recommendations to text\n",
    "        text_rec = json.dumps(recommendations)\n",
    "\n",
    "        # Invoke the chain\n",
    "        logger.info(\"Invoking LangChain for session filtering\")\n",
    "        ai_msg = chain.invoke(\n",
    "            {\"sessions\": text_rec, \"profile\": visitor, \"rules\": rules}\n",
    "        )\n",
    "\n",
    "        # Parse the response to extract the filtered recommendations\n",
    "        response_text = ai_msg.content\n",
    "\n",
    "        # Try to extract JSON from the response\n",
    "        import re\n",
    "\n",
    "        json_match = re.search(r\"```json\\n(.*?)\\n```\", response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(1)\n",
    "        else:\n",
    "            # Try to find JSON without markdown\n",
    "            json_match = re.search(r\"\\[\\s*{.*}\\s*\\]\", response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "            else:\n",
    "                json_str = response_text\n",
    "\n",
    "        try:\n",
    "            filtered_recommendations = json.loads(json_str)\n",
    "            logger.info(\n",
    "                f\"Successfully filtered recommendations using LangChain: {len(filtered_recommendations)} sessions\"\n",
    "            )\n",
    "            return filtered_recommendations, [\"Filtered using LLM-based rules\"]\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"Error parsing LangChain response: {e}\")\n",
    "            return recommendations, [\"Error in LLM filtering\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error using LangChain for filtering: {e}\")\n",
    "        return recommendations, [\"Error in LLM filtering: \" + str(e)]\n",
    "\n",
    "\n",
    "# == Combined Recommendation & Filtering System ==\n",
    "\n",
    "\n",
    "def get_recommendations_and_filter(\n",
    "    badge_id: str,\n",
    "    min_score: float = 0.5,\n",
    "    max_recommendations: int = 30,\n",
    "    rules_config: Optional[Dict] = None,\n",
    "    visitor_data: Optional[pd.DataFrame] = None,\n",
    "    use_neo4j: bool = True,\n",
    "    use_langchain: bool = False,\n",
    "    business_rules: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get session recommendations and filter them based on business rules.\n",
    "\n",
    "    Args:\n",
    "        badge_id: Visitor's badge ID\n",
    "        min_score: Minimum similarity score\n",
    "        max_recommendations: Maximum number of recommendations to return\n",
    "        rules_config: Optional rules configuration\n",
    "        visitor_data: Optional DataFrame containing visitor data\n",
    "        use_neo4j: Whether to use Neo4j for recommendations\n",
    "        use_langchain: Whether to filter using LangChain\n",
    "        business_rules: Optional business rules text for LangChain\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with visitor profile, raw recommendations, filtered recommendations,\n",
    "        and metadata about the filtering process\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    processing_steps = []\n",
    "\n",
    "    # Get visitor profile\n",
    "    visitor = None\n",
    "    if visitor_data is not None:\n",
    "        visitor_rows = visitor_data[visitor_data[\"BadgeId\"] == badge_id]\n",
    "        if not visitor_rows.empty:\n",
    "            visitor = visitor_rows.iloc[0].to_dict()\n",
    "            processing_steps.append(f\"Found visitor {badge_id} in provided data\")\n",
    "\n",
    "    if visitor is None and use_neo4j:\n",
    "        logger.warning(f\"Visitor with BadgeId {badge_id} not found in provided data\")\n",
    "        # Try to get basic visitor info from Neo4j\n",
    "        try:\n",
    "            with GraphDatabase.driver(uri, auth=(username, password)) as driver:\n",
    "                with driver.session() as session:\n",
    "                    result = session.run(\n",
    "                        \"MATCH (v:Visitor_this_year {BadgeId: $badge_id}) RETURN v\",\n",
    "                        badge_id=badge_id,\n",
    "                    ).single()\n",
    "\n",
    "                    if result:\n",
    "                        visitor = dict(result[\"v\"])\n",
    "                        processing_steps.append(f\"Found visitor {badge_id} in Neo4j\")\n",
    "                    else:\n",
    "                        processing_steps.append(\n",
    "                            f\"Visitor {badge_id} not found in Neo4j\"\n",
    "                        )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error connecting to Neo4j: {e}\")\n",
    "            processing_steps.append(f\"Neo4j connection error: {e}\")\n",
    "\n",
    "    # If visitor still not found, create a mock visitor for testing\n",
    "    if visitor is None:\n",
    "        visitor = {\n",
    "            \"BadgeId\": badge_id,\n",
    "            \"job_role\": \"Vet/Vet Surgeon\",\n",
    "            \"what_type_does_your_practice_specialise_in\": \"Mixed\",\n",
    "            \"Email\": \"test@example.com\",\n",
    "            \"Email_domain\": \"example.com\",\n",
    "            \"Company\": \"Test Company\",\n",
    "            \"JobTitle\": \"veterinary surgeon\",\n",
    "            \"Country\": \"UK\",\n",
    "            \"BadgeType\": \"Delegate\",\n",
    "            \"ShowRef\": \"BVA2025\",\n",
    "            \"Source\": \"Test\",\n",
    "            \"Days_since_registration\": 100,\n",
    "            \"assist_year_before\": 1,\n",
    "            \"organisation_type\": \"Independent\",\n",
    "        }\n",
    "        processing_steps.append(\"Created mock visitor profile for testing\")\n",
    "\n",
    "    # Get recommendations\n",
    "    try:\n",
    "        # Get raw recommendations\n",
    "        recommendations = recommend_sessions_optimized(\n",
    "            badge_id=badge_id,\n",
    "            assist_year_before=str(visitor.get(\"assist_year_before\", \"1\")),\n",
    "            min_score=min_score,\n",
    "            max_recommendations=max_recommendations,\n",
    "            use_neo4j=use_neo4j,\n",
    "        )\n",
    "\n",
    "        processing_steps.append(f\"Retrieved {len(recommendations)} raw recommendations\")\n",
    "\n",
    "        # Choose filtering approach\n",
    "        if use_langchain and has_langchain and business_rules:\n",
    "            # Use LangChain filtering\n",
    "            processing_steps.append(\"Using LangChain for filtering\")\n",
    "            filtered_recommendations, filter_notes = filter_with_langchain(\n",
    "                visitor=visitor, recommendations=recommendations, rules=business_rules\n",
    "            )\n",
    "            processing_steps.extend(filter_notes)\n",
    "        else:\n",
    "            # Use rule-based filtering\n",
    "            processing_steps.append(\"Using rule-based filtering\")\n",
    "            session_filter = SessionFilter(rules_config)\n",
    "            filtered_recommendations, filter_notes = session_filter.filter_sessions(\n",
    "                visitor, recommendations\n",
    "            )\n",
    "            processing_steps.extend(filter_notes)\n",
    "\n",
    "        processing_steps.append(\n",
    "            f\"Filtered to {len(filtered_recommendations)} recommendations\"\n",
    "        )\n",
    "\n",
    "        # Create result dictionary\n",
    "        result = {\n",
    "            \"visitor\": visitor,\n",
    "            \"raw_recommendations\": recommendations,\n",
    "            \"filtered_recommendations\": filtered_recommendations,\n",
    "            \"metadata\": {\n",
    "                \"badge_id\": badge_id,\n",
    "                \"num_raw_recommendations\": len(recommendations),\n",
    "                \"num_filtered_recommendations\": len(filtered_recommendations),\n",
    "                \"processing_time\": time.time() - start_time,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"processing_steps\": processing_steps,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting recommendations: {str(e)}\")\n",
    "        return {\n",
    "            \"visitor\": visitor,\n",
    "            \"raw_recommendations\": [],\n",
    "            \"filtered_recommendations\": [],\n",
    "            \"metadata\": {\n",
    "                \"error\": str(e),\n",
    "                \"processing_time\": time.time() - start_time,\n",
    "                \"processing_steps\": processing_steps,\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "def save_recommendations_to_json(result: Dict[str, Any], output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save recommendations to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        result: Result dictionary from get_recommendations_and_filter\n",
    "        output_path: Path to save the JSON file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(result, f, indent=2, default=str)\n",
    "        logger.info(f\"Saved recommendations to {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving recommendations to {output_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Standard rules for filtering\n",
    "default_rules = \"\"\"\n",
    "1.) if visitor what_type_does_your_practice_specialise_in contains \"equine\" or \"mixed\", you can't propose session on stream \"exotics\", \"feline\", \"exotic animal\", \"farm\", \"small animal\"\\n\n",
    "2.) if visitor what_type_does_your_practice_specialise_in contains \"small animal\", you can't propose session on stream \"equine\", \"farm animal\", \"farm\", \"large animal\"\\n\n",
    "3.) if job_role in VET_ROLES session.stream cant be \"nursing\"\\n\n",
    "4.) if job_role in NURSE_ROLES you only recommend sessions in stream \"nursing\", \"wellbeing\", \"welfare\"\\n\n",
    "5.) rule 1 and 2 are mutually exclusive and apply first then apply 3 and 4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908d3a8-f415-458d-9f1c-1dc01d08cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run a test with a visitor\n",
    "print(\"Session Recommendation and Filtering Notebook Ready!\")\n",
    "print(\"This notebook supports both Neo4j-based and mock recommendations\")\n",
    "print(\"It also supports both rule-based and LangChain-based filtering\")\n",
    "\n",
    "# Check if we're running in a Jupyter notebook\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    if get_ipython() is not None:\n",
    "        # We're in a notebook, try to import display libraries\n",
    "        from IPython.display import display, HTML, JSON\n",
    "\n",
    "        in_notebook = True\n",
    "        print(\"Running in Jupyter notebook environment\")\n",
    "    else:\n",
    "        in_notebook = False\n",
    "except ImportError:\n",
    "    in_notebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddab28a-e795-484d-a881-be39c99ed206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load visitor data if available\n",
    "try:\n",
    "    data_this = pd.read_csv(\"data/bva/output/df_reg_demo_this.csv\")\n",
    "    print(f\"Loaded visitor data with {len(data_this)} visitors\")\n",
    "\n",
    "    # Display a sample of the visitor data\n",
    "    if in_notebook:\n",
    "        display(data_this.head(2))\n",
    "    else:\n",
    "        print(data_this.head(2))\n",
    "except Exception as e:\n",
    "    print(f\"Could not load visitor data: {e}\")\n",
    "    data_this = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ee5c6-d3bf-4152-a440-a96a2cc485c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = get_recommendations_and_filter(\n",
    "    badge_id=\"EL7CTM9\",  # Replace with an actual badge ID\n",
    "    min_score=0.3,\n",
    "    max_recommendations=10,\n",
    "    rules_config=None,  # Use default rules\n",
    "    visitor_data=data_this,\n",
    "    use_neo4j=True,  # Use real Neo4j data\n",
    "    use_langchain=True,  # Use rule-based filtering\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fecf71-0792-43df-900b-8018ce2a7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbb07b-dd94-45a1-b23f-dba606f1ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c69c7-4ea3-4e6a-a5d7-f1f2168eb773",
   "metadata": {},
   "source": [
    "# Custom Rules\n",
    "\n",
    "```\n",
    "# Create the session filter with default rules\n",
    "session_filter = SessionFilter()\n",
    "\n",
    "# Define a new rule function for excluding Exhibitor Showcase sessions\n",
    "def exclude_exhibitor_showcase(visitor, sessions):\n",
    "    \"\"\"Custom rule to exclude sessions in the Exhibitor Showcase theatre.\"\"\"\n",
    "    # Filter out sessions in the Exhibitor Showcase\n",
    "    filtered_sessions = [\n",
    "        session for session in sessions\n",
    "        if not session.get(\"theatre__name\") or \"Exhibitor Showcase\" not in session[\"theatre__name\"]\n",
    "    ]\n",
    "    \n",
    "    # Create a rule description for logging\n",
    "    rules_applied = [f\"theatre: excluded Exhibitor Showcase sessions\"]\n",
    "    \n",
    "    # Log what happened\n",
    "    logger.info(f\"Applied Exhibitor Showcase exclusion: filtered from {len(sessions)} to {len(filtered_sessions)} sessions\")\n",
    "    \n",
    "    return filtered_sessions, rules_applied\n",
    "\n",
    "# Register the new rule\n",
    "session_filter.add_rule_implementation(\"exclude_showcase\", exclude_exhibitor_showcase)\n",
    "\n",
    "# Update priority to include the new rule\n",
    "session_filter.update_rules({\n",
    "    \"rule_priority\": [\"practice_type\", \"role\", \"exclude_showcase\"]\n",
    "})\n",
    "\n",
    "# Now use the session filter with the new rule\n",
    "filtered_recommendations, filter_notes = session_filter.filter_sessions(visitor, recommendations)\n",
    "\n",
    "OR\n",
    "\n",
    "# Define custom rules that include Exhibitor Showcase exclusion\n",
    "custom_rules = {\n",
    "    \"equine_mixed_exclusions\": [\"exotics\", \"feline\", \"exotic animal\", \"farm\", \"small animal\"],\n",
    "    \"small_animal_exclusions\": [\"equine\", \"farm animal\", \"farm\", \"large animal\"],\n",
    "    \"vet_exclusions\": [\"nursing\"],\n",
    "    \"nurse_streams\": [\"nursing\", \"wellbeing\", \"welfare\"],\n",
    "    \"excluded_theatres\": [\"Exhibitor Showcase\"]  # New rule for excluded theatres\n",
    "}\n",
    "\n",
    "# Update the _apply_practice_type\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e5303-3a26-43d8-b67c-5b0080ba9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_rules = {\n",
    "    \"equine_mixed_exclusions\": [\n",
    "        \"exotics\",\n",
    "        \"feline\",\n",
    "        \"exotic animal\",\n",
    "        \"farm\",\n",
    "        \"small animal\",\n",
    "    ],\n",
    "    \"small_animal_exclusions\": [\"equine\", \"farm animal\", \"farm\", \"large animal\"],\n",
    "    \"vet_exclusions\": [\"nursing\"],\n",
    "    \"nurse_streams\": [\"nursing\", \"wellbeing\", \"welfare\"],\n",
    "    \"excluded_theatres\": [\"Exhibitor Showcase 1\"],  # New rule for excluded theatres\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba87aa7-371d-45bf-b0fe-a3a773915322",
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = get_recommendations_and_filter(\n",
    "    badge_id=\"EL7CTM9\",  # Replace with an actual badge ID\n",
    "    min_score=0.3,\n",
    "    max_recommendations=10,\n",
    "    rules_config=custom_rules,  # Use default rules\n",
    "    visitor_data=data_this,\n",
    "    use_neo4j=True,  # Use real Neo4j data\n",
    "    use_langchain=True,  # Use rule-based filtering\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39d54c-750d-48e9-b968-f9e08712ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result4[\"filtered_recommendations\"]), len(result3[\"filtered_recommendations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e3112-e5fd-4e13-92c3-ce3e78beb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "data_this = pd.read_csv(\"data/bva/output/df_reg_demo_this.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b68ca-0c2d-4780-9af2-0411290dd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visistors this year\n",
    "visitors_this = list(data_this[\"BadgeId\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f5901-b9fd-478f-9a21-0672702659f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visitors_this_recs = []\n",
    "for vis in visitors_this:\n",
    "    result = get_recommendations_and_filter(\n",
    "        badge_id=vis,  # Replace with an actual badge ID\n",
    "        min_score=0.3,\n",
    "        max_recommendations=10,\n",
    "        rules_config=None,  # Use default rules\n",
    "        visitor_data=data_this,\n",
    "        use_neo4j=True,  # Use real Neo4j data\n",
    "        use_langchain=True,  # Use rule-based filtering\n",
    "    )\n",
    "    visitors_this_recs.append({vis: result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1c180-e756-4ada-91c6-f722ca017f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
