{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3293c1f-fe75-481a-b228-1203c77a2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from neo4j import GraphDatabase\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "uri = \"bolt://127.0.0.1:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"\"  # Replace with your password.\n",
    "\n",
    "# Initialize Neo4j driver\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Load a good text embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ad952-1028-4c7b-a844-63e2525e2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values for properties\n",
    "default_properties = {\n",
    "    \"Days_since_registration\": \"119\",\n",
    "    \"Country\": \"UK\",\n",
    "    \"Source\": \"BVA Key Stakeholders\",\n",
    "    \"Email_domain\": \"effem.com\",\n",
    "    \"assist_year_before\": \"1\",\n",
    "    \"job_role\": \"NA\",\n",
    "    \"what_type_does_your_practice_specialise_in\": \"NA\",\n",
    "    \"organisation_type\": \"NA\",\n",
    "    \"JobTitle\": \"NA\",\n",
    "}\n",
    "\n",
    "\n",
    "def set_default_properties(tx, properties):\n",
    "    query = \"\"\"\n",
    "    MATCH (n:Visitor_this_year)\n",
    "    SET\n",
    "    \"\"\" + \",\\n    \".join(\n",
    "        [f\"n.{key} = COALESCE(n.{key}, $props.{key})\" for key in properties.keys()]\n",
    "    )\n",
    "\n",
    "    tx.run(query, props=properties)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(set_default_properties, default_properties)\n",
    "    driver.close()\n",
    "    print(\"Missing properties set to default values for all Visitor_this_year nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fddd99-3df7-4742-a4cf-129ad343d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc493c1d-6786-42f6-b079-c4f924d60147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a good text embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# define session embedding\n",
    "def create_session_embedding(session, stream_descriptions=None):\n",
    "    # Include title, synopsis_stripped, theatre__name, and now the sponsored attributes\n",
    "    base_text = f\"{session['title']} {session['synopsis_stripped']} {session['theatre__name']} {session['sponsored_by']} {session['sponsored_session']}\"\n",
    "\n",
    "    # Add stream descriptions if provided\n",
    "    if stream_descriptions and len(stream_descriptions) > 0:\n",
    "        stream_desc_text = \" \".join(stream_descriptions)\n",
    "        text = f\"{base_text} {stream_desc_text}\"\n",
    "    else:\n",
    "        text = base_text\n",
    "\n",
    "    return model.encode(text)\n",
    "\n",
    "\n",
    "# Embedding function for all sessions\n",
    "def embed_all_sessions(tx):\n",
    "    # Query all Sessions from past_year_dva, past_year_lva, Sessions_past_year (for compatibility) and this_year\n",
    "    # Now including sponsored_by and sponsored_session fields\n",
    "    query = \"\"\"\n",
    "    MATCH (s)\n",
    "    WHERE s:Sessions_past_year_dva OR s:Sessions_past_year_lva OR s:Sessions_this_year OR s:Sessions_past_year\n",
    "    RETURN s.session_id as session_id, s.title as title, \n",
    "           s.stream as stream, s.synopsis_stripped as synopsis_stripped,\n",
    "           s.theatre__name as theatre__name, s.sponsored_by as sponsored_by,\n",
    "           s.sponsored_session as sponsored_session, labels(s)[0] as type\n",
    "    \"\"\"\n",
    "    sessions = tx.run(query).data()\n",
    "\n",
    "    # Fetch all stream descriptions once to avoid multiple queries\n",
    "    stream_query = \"\"\"\n",
    "    MATCH (s:Stream)\n",
    "    RETURN s.stream as stream, s.description as description\n",
    "    \"\"\"\n",
    "    stream_data = tx.run(stream_query).data()\n",
    "\n",
    "    # Create a dictionary of stream descriptions for quick lookup\n",
    "    stream_descriptions = {s[\"stream\"].lower(): s[\"description\"] for s in stream_data}\n",
    "\n",
    "    embeddings = {}\n",
    "    for s in sessions:\n",
    "        # Process the stream field - split by semicolon and handle duplicates\n",
    "        session_streams = []\n",
    "        if s[\"stream\"]:\n",
    "            # Split the stream string and strip whitespace\n",
    "            stream_list = [stream.strip().lower() for stream in s[\"stream\"].split(\";\")]\n",
    "            # Remove duplicates by converting to set and back to list\n",
    "            stream_list = list(set(stream_list))\n",
    "\n",
    "            # Get the description for each stream\n",
    "            for stream in stream_list:\n",
    "                if stream in stream_descriptions:\n",
    "                    session_streams.append(stream_descriptions[stream])\n",
    "\n",
    "        # Handle possible None values for sponsored attributes\n",
    "        s[\"sponsored_by\"] = s[\"sponsored_by\"] if s[\"sponsored_by\"] else \"Not Sponsored\"\n",
    "        s[\"sponsored_session\"] = (\n",
    "            s[\"sponsored_session\"] if s[\"sponsored_session\"] else \"False\"\n",
    "        )\n",
    "\n",
    "        # Create embedding with the session data and stream descriptions\n",
    "        embeddings[s[\"session_id\"]] = {\n",
    "            \"type\": s[\"type\"],\n",
    "            \"embedding\": create_session_embedding(s, session_streams),\n",
    "            \"sponsored_by\": s[\"sponsored_by\"],\n",
    "            \"sponsored_session\": s[\"sponsored_session\"],\n",
    "        }\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_session_attributes(session_ids):\n",
    "    # Handle empty session_ids to prevent errors\n",
    "    if not session_ids:\n",
    "        return []\n",
    "\n",
    "    # Updated to include sponsored attributes\n",
    "    query = \"\"\"\n",
    "    MATCH (s:Sessions_this_year)\n",
    "    WHERE s.session_id IN $session_ids\n",
    "    RETURN s {\n",
    "        .stream,\n",
    "        .session_id,\n",
    "        .title,\n",
    "        .synopsis_stripped,\n",
    "        .end_time,\n",
    "        .start_time,\n",
    "        .date,\n",
    "        .theatre__name,\n",
    "        .sponsored_by,\n",
    "        .sponsored_session\n",
    "    } AS session_details\n",
    "    \"\"\"\n",
    "\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query, session_ids=session_ids)\n",
    "        session_details = [record[\"session_details\"] for record in results]\n",
    "\n",
    "    return session_details\n",
    "\n",
    "\n",
    "# visitor-based similarity\n",
    "def visitor_similarity(v1, v2, attrs):\n",
    "    vec1 = np.array([1 if v1[a] == v2[a] else 0 for a in attrs])\n",
    "    return vec1.mean()\n",
    "\n",
    "\n",
    "# Recommend sessions with sponsored content handling\n",
    "def recommend_sessions(tx, visitor_id, session_embeddings):\n",
    "    # First check if visitor assisted last year\n",
    "    visitor_query = \"\"\"\n",
    "    MATCH (v:Visitor_this_year {BadgeId: $visitor_id})\n",
    "    RETURN v\n",
    "    \"\"\"\n",
    "    visitor_data = tx.run(visitor_query, visitor_id=visitor_id).single()\n",
    "    if not visitor_data:\n",
    "        return []\n",
    "    visitor = visitor_data[\"v\"]\n",
    "    assisted = visitor[\"assist_year_before\"]\n",
    "\n",
    "    recommendations = []\n",
    "    sponsored_recommendations = []\n",
    "\n",
    "    if assisted == \"1\":\n",
    "        # Directly using past year attended session\n",
    "        query_past = \"\"\"\n",
    "        MATCH (v:Visitor_this_year {BadgeId: $visitor_id})-[:Same_Visitor]->(vp_bva:Visitor_last_year_bva)-[:attended_session]->(sp_bva:Sessions_past_year)\n",
    "        RETURN sp_bva.session_id as session_id\n",
    "        UNION\n",
    "        MATCH (v:Visitor_this_year {BadgeId: $visitor_id})-[:Same_Visitor]->(vp_lva:Visitor_last_year_lva)-[:attended_session]->(sp_lva:Sessions_past_year)\n",
    "        RETURN sp_lva.session_id as session_id\n",
    "        \"\"\"\n",
    "        past_sessions = tx.run(query_past, visitor_id=visitor_id).data()\n",
    "        for past_sess in past_sessions:\n",
    "            # Check if the session_id exists in embeddings\n",
    "            if past_sess[\"session_id\"] not in session_embeddings:\n",
    "                continue  # Skip this session if it's not in our embeddings\n",
    "\n",
    "            past_emb = session_embeddings[past_sess[\"session_id\"]][\"embedding\"]\n",
    "\n",
    "            this_year_sessions = {\n",
    "                k: v\n",
    "                for k, v in session_embeddings.items()\n",
    "                if v[\"type\"] == \"Sessions_this_year\"\n",
    "            }\n",
    "            similarities = []\n",
    "            for sid, data in this_year_sessions.items():\n",
    "                sim = cosine_similarity([past_emb], [data[\"embedding\"]])[0][0]\n",
    "                similarities.append(\n",
    "                    (sid, sim, data[\"sponsored_session\"], data[\"sponsored_by\"])\n",
    "                )\n",
    "\n",
    "            # Sort by similarity and pick top 2 most similar\n",
    "            similarities.sort(key=lambda x: -x[1])\n",
    "\n",
    "            # Separate sponsored from non-sponsored content\n",
    "            for sid, sim, is_sponsored, sponsor in similarities[\n",
    "                :4\n",
    "            ]:  # Check more to ensure we have enough of each type\n",
    "                if is_sponsored.lower() == \"true\":\n",
    "                    sponsored_recommendations.append((sid, sim, sponsor))\n",
    "                else:\n",
    "                    recommendations.append((sid, sim))\n",
    "\n",
    "    else:\n",
    "        # For new visitors, find similar visitor with history\n",
    "        visitor_attrs = [\n",
    "            \"Days_since_registration\",\n",
    "            \"Country\",\n",
    "            \"Source\",\n",
    "            \"Email_domain\",\n",
    "            \"JobTitle\",\n",
    "            \"assist_year_before\",\n",
    "            \"job_role\",\n",
    "            \"what_type_does_your_practice_specialise_in\",\n",
    "            \"organisation_type\",\n",
    "        ]\n",
    "\n",
    "        all_visitors = tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (v:Visitor_this_year)\n",
    "            WHERE v.assist_year_before = '1'\n",
    "            RETURN v\n",
    "        \"\"\"\n",
    "        ).data()\n",
    "\n",
    "        similarities = []\n",
    "        for vdata in all_visitors:\n",
    "            v_compare = vdata[\"v\"]\n",
    "            sim = visitor_similarity(visitor, v_compare, visitor_attrs)\n",
    "            similarities.append((v_compare[\"BadgeId\"], sim))\n",
    "\n",
    "        similarities.sort(key=lambda x: -x[1])\n",
    "        similar_visitor_badge_ids = [sid for sid, _ in similarities[:2]]\n",
    "\n",
    "        for similar_vid in similar_visitor_badge_ids:\n",
    "            query_sim_past = \"\"\"\n",
    "                MATCH (v:Visitor_this_year {BadgeId: $similar_vid})-[:Same_Visitor]->(vp)-[:attended_session]->(sp:Sessions_past_year)\n",
    "                WHERE vp:Visitor_last_year_bva OR vp:Visitor_last_year_lva\n",
    "                RETURN sp.session_id AS session_id\n",
    "            \"\"\"\n",
    "            user_past_sessions = tx.run(query_sim_past, similar_vid=similar_vid).data()\n",
    "\n",
    "            for past_sess in user_past_sessions:\n",
    "                # Check if the session_id exists in embeddings\n",
    "                if past_sess[\"session_id\"] not in session_embeddings:\n",
    "                    continue  # Skip this session if it's not in our embeddings\n",
    "\n",
    "                past_emb = session_embeddings[past_sess[\"session_id\"]][\"embedding\"]\n",
    "\n",
    "                this_year_sessions = {\n",
    "                    k: v\n",
    "                    for k, v in session_embeddings.items()\n",
    "                    if v[\"type\"] == \"Sessions_this_year\"\n",
    "                }\n",
    "                session_similarities = []\n",
    "                for sid, data in this_year_sessions.items():\n",
    "                    sim = cosine_similarity([past_emb], [data[\"embedding\"]])[0][0]\n",
    "                    session_similarities.append(\n",
    "                        (sid, sim, data[\"sponsored_session\"], data[\"sponsored_by\"])\n",
    "                    )\n",
    "\n",
    "                session_similarities.sort(key=lambda x: -x[1])\n",
    "\n",
    "                # Separate sponsored from non-sponsored content\n",
    "                for sid, sim, is_sponsored, sponsor in session_similarities[\n",
    "                    :4\n",
    "                ]:  # Check more to ensure we have enough of each type\n",
    "                    if is_sponsored.lower() == \"true\":\n",
    "                        sponsored_recommendations.append((sid, sim, sponsor))\n",
    "                    else:\n",
    "                        recommendations.append((sid, sim))\n",
    "\n",
    "    # Create final recommendation list with a mix of sponsored and non-sponsored content\n",
    "    # Take top 2 from each, prioritizing non-sponsored but ensuring some sponsored content is included\n",
    "    final_recommendations = []\n",
    "\n",
    "    # Add top non-sponsored recommendations (limit to 3)\n",
    "    final_recommendations.extend(\n",
    "        [r[0] for r in sorted(recommendations, key=lambda x: -x[1])[:3]]\n",
    "    )\n",
    "\n",
    "    # Add top sponsored recommendations (limit to 2)\n",
    "    if sponsored_recommendations:\n",
    "        final_recommendations.extend(\n",
    "            [r[0] for r in sorted(sponsored_recommendations, key=lambda x: -x[1])[:2]]\n",
    "        )\n",
    "\n",
    "    # Remove duplicates and return\n",
    "    return list(set(final_recommendations))\n",
    "\n",
    "\n",
    "# Scoring function that boosts sponsored sessions slightly\n",
    "def score_session(\n",
    "    session_embedding, candidate_embedding, is_sponsored, sponsor_relevance=0.1\n",
    "):\n",
    "    # Base similarity score\n",
    "    base_score = cosine_similarity([session_embedding], [candidate_embedding])[0][0]\n",
    "\n",
    "    # Boost for sponsored content (smaller boost to not overwhelm relevance)\n",
    "    sponsor_boost = sponsor_relevance if is_sponsored.lower() == \"true\" else 0\n",
    "\n",
    "    return base_score + sponsor_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff025d3-c9af-46ef-856b-626c0d54e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sessions_by_visitor_stream_relationships(tx, visitor_id, session_ids):\n",
    "    \"\"\"\n",
    "    Filter sessions to keep only those where the visitor has a relationship\n",
    "    (specialization_to_stream or job_to_stream) to any Stream that has a HAS_STREAM\n",
    "    relationship to the session.\n",
    "    \"\"\"\n",
    "    if not session_ids:\n",
    "        return []\n",
    "\n",
    "    # Query to find sessions with valid stream relationships to the visitor\n",
    "    query = \"\"\"\n",
    "    MATCH (v:Visitor_this_year {BadgeId: $visitor_id})\n",
    "    MATCH (s:Sessions_this_year)\n",
    "    WHERE s.session_id IN $session_ids\n",
    "    MATCH (s)-[:HAS_STREAM]->(stream:Stream)<-[r]-(v)\n",
    "    WHERE type(r) IN ['specialization_to_stream', 'job_to_stream']\n",
    "    RETURN DISTINCT s.session_id as session_id\n",
    "    \"\"\"\n",
    "\n",
    "    results = tx.run(query, visitor_id=visitor_id, session_ids=session_ids).data()\n",
    "    valid_session_ids = [r[\"session_id\"] for r in results]\n",
    "\n",
    "    return valid_session_ids\n",
    "\n",
    "\n",
    "# Cached embeddings at the module level\n",
    "_session_embeddings = None\n",
    "\n",
    "\n",
    "def get_recommendations(visitor_id):\n",
    "    global _session_embeddings\n",
    "\n",
    "    # Create session embeddings once if they don't exist\n",
    "    if _session_embeddings is None:\n",
    "        with driver.session() as session:\n",
    "            _session_embeddings = session.execute_read(embed_all_sessions)\n",
    "\n",
    "    # Use the cached embeddings for recommendations\n",
    "    with driver.session() as session:\n",
    "        # Get initial recommended session IDs based on existing logic\n",
    "        recommended_session_ids = session.execute_read(\n",
    "            recommend_sessions,\n",
    "            visitor_id=visitor_id,\n",
    "            session_embeddings=_session_embeddings,\n",
    "        )\n",
    "\n",
    "        # Apply the additional filter for stream relationships\n",
    "        filtered_session_ids = session.execute_read(\n",
    "            filter_sessions_by_visitor_stream_relationships,\n",
    "            visitor_id=visitor_id,\n",
    "            session_ids=recommended_session_ids,\n",
    "        )\n",
    "\n",
    "    # Get the details of the filtered recommended sessions\n",
    "    recommended_sessions_details = get_session_attributes(filtered_session_ids)\n",
    "\n",
    "    return recommended_sessions_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cff019-fc6a-4b62-8c92-e1c56a73fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cached embeddings at the module level\n",
    "# _session_embeddings = None\n",
    "\n",
    "# def get_recommendations(visitor_id):\n",
    "#     global _session_embeddings\n",
    "\n",
    "#     # Create session embeddings once if they don't exist\n",
    "#     if _session_embeddings is None:\n",
    "#         with driver.session() as session:\n",
    "#             _session_embeddings = session.execute_read(embed_all_sessions)\n",
    "\n",
    "#     # Use the cached embeddings for recommendations\n",
    "#     with driver.session() as session:\n",
    "#         recommended_session_ids = session.execute_read(\n",
    "#             recommend_sessions,\n",
    "#             visitor_id=visitor_id,\n",
    "#             session_embeddings=_session_embeddings\n",
    "#         )\n",
    "\n",
    "#     # Get the details of the recommended sessions\n",
    "#     recommended_sessions_details = get_session_attributes(recommended_session_ids)\n",
    "\n",
    "# return recommended_sessions_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213991d1-1fa8-448a-8b77-3068cac41b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "visitor_id_example = \"MV4H3PQ\"  #  No visit last year\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "recommended_sessions = get_recommendations(visitor_id_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534c299-3a26-4918-b196-1ba8aea542a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in recommended_sessions:\n",
    "    print(session)\n",
    "    print(\"*\" * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e69b79-4474-431a-990f-6c1b5bbc47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRKLA7T Visit last year\n",
    "\n",
    "visitor_id_example = \"Z642DJP\"  # Visitor_this_year BadgeId Example No visit last year\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "recommended_sessions = get_recommendations(visitor_id_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2d7b7-bdac-41e2-8479-c4412522168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in recommended_sessions:\n",
    "    print(session)\n",
    "    print(\"*\" * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42756b8-b458-4789-a32c-7a5688a13cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"data/bva/output/df_reg_demo_this.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d172fae-f4e8-4f8e-9751-12c8feccd5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_file_path)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9738030-31fe-4554-ad7a-a16890aac51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_badgeId_this = list(data[\"BadgeId\"].unique())\n",
    "len(list_badgeId_this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd9b8a-399f-4c5a-81e7-8d6899157173",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_recommendations = {}\n",
    "counter = 0  # Initialize a counter\n",
    "\n",
    "for badge in list_badgeId_this:\n",
    "    recommended_sessions = get_recommendations(badge)\n",
    "    pa_recommendations[badge] = recommended_sessions\n",
    "\n",
    "    # Increment the counter\n",
    "    counter += 1\n",
    "\n",
    "    # Print the badge every 50 iterations\n",
    "    if counter % 30 == 0:\n",
    "        print(f\"Processed {counter} badges so far. Current badge: {badge}\")\n",
    "\n",
    "# Optionally, print the total count at the end\n",
    "print(f\"Total badges processed: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e34570-1505-418c-901b-06a2809a15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd5d36-63b5-46d8-8f78-733de3a9d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/bva/bva_pa_recomendations.json\", \"w\") as f:\n",
    "    json.dump(pa_recommendations, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71bbf6-f181-40da-92de-a14d2f2dc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_recommendations_to_dataframe(pa_recommendations):\n",
    "    \"\"\"\n",
    "    Transforms a dictionary of session recommendations to a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        pa_recommendations (dict): A dictionary where keys are badge IDs (strings)\n",
    "            and values are lists of session dictionaries.  Each session dictionary\n",
    "            contains information about a recommended session.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with columns 'badgeid', 'session_id', 'stream',\n",
    "            'title', 'end_time', 'synopsis_stripped', 'start_time', 'date',\n",
    "            and 'theatre__name'. Returns an empty DataFrame if the input dictionary is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []  # List to hold the rows of the DataFrame\n",
    "    for badgeid, session_list in pa_recommendations.items():\n",
    "        for session in session_list:\n",
    "            row = {\n",
    "                \"badgeid\": badgeid,\n",
    "                \"session_id\": session.get(\"session_id\", None),  # Use .get() for safety\n",
    "                \"stream\": session.get(\"stream\", None),\n",
    "                \"title\": session.get(\"title\", None),\n",
    "                \"end_time\": session.get(\"end_time\", None),\n",
    "                \"synopsis_stripped\": session.get(\"synopsis_stripped\", None),\n",
    "                \"start_time\": session.get(\"start_time\", None),\n",
    "                \"date\": session.get(\"date\", None),\n",
    "                \"theatre__name\": session.get(\"theatre__name\", None),\n",
    "            }\n",
    "            data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = transform_recommendations_to_dataframe(pa_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32eb0f-308f-43b9-b1ed-aa4f747be1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ec320-1c46-41c0-acba-d0e12c12b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#\n",
    "def flag_overlapping_sessions(df):\n",
    "    # Convert string time columns to datetime\n",
    "    df[\"start_datetime\"] = pd.to_datetime(df[\"date\"] + \" \" + df[\"start_time\"])\n",
    "    df[\"end_datetime\"] = pd.to_datetime(df[\"date\"] + \" \" + df[\"end_time\"])\n",
    "\n",
    "    # Create a column to store overlapping session_ids\n",
    "    df[\"overlapping_sessions\"] = None\n",
    "\n",
    "    # Group by badgeid to check overlaps for each visitor\n",
    "    for badge_id, group in df.groupby(\"badgeid\"):\n",
    "        # If there's only one session for this badge, no need to check\n",
    "        if len(group) <= 1:\n",
    "            continue\n",
    "\n",
    "        # For each session in the group\n",
    "        for idx1, row1 in group.iterrows():\n",
    "            overlaps = []\n",
    "\n",
    "            # Compare with all other sessions for the same badge\n",
    "            for idx2, row2 in group.iterrows():\n",
    "                if idx1 == idx2:  # Skip comparing with itself\n",
    "                    continue\n",
    "\n",
    "                # Check if sessions overlap\n",
    "                # Session1 starts before Session2 ends AND Session1 ends after Session2 starts\n",
    "                if (\n",
    "                    row1[\"start_datetime\"] < row2[\"end_datetime\"]\n",
    "                    and row1[\"end_datetime\"] > row2[\"start_datetime\"]\n",
    "                ):\n",
    "                    overlaps.append(row2[\"session_id\"])\n",
    "\n",
    "            # If overlaps found, update the column\n",
    "            if overlaps:\n",
    "                df.at[idx1, \"overlapping_sessions\"] = \",\".join(map(str, overlaps))\n",
    "\n",
    "    # Drop the temporary datetime columns if not needed\n",
    "    df.drop([\"start_datetime\", \"end_datetime\"], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "df = flag_overlapping_sessions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d017fac-7de3-451e-bd7e-078ae59df61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.overlapping_sessions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ccd67-3131-41a8-b730-5f6aba8176aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5781b0-a7c2-4ca3-b891-23be479dc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/bva/output/streams.json\", \"r\") as f:\n",
    "    streams = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272df7c-4d54-4571-b39c-3bd38c3ef58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c0537-6754-41f1-a29b-a16fe28ce681",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38a0b8-05a0-4f4c-a7bd-ab64523852a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/bva/bva_pa_recomendations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d0f20-bbbe-4154-b4dd-475b326c627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_24_25_bva_valid_columns = pd.read_csv(\n",
    "    \"data/bva/csv/Registration_data_bva_24_25_only_valid.csv\"\n",
    ")\n",
    "df_reg_24_25_lva_valid_columns = pd.read_csv(\n",
    "    \"data/bva/csv/Registration_data_lva_24_25_only_valid.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84272de8-b875-4896-a9f6-95d17a061d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_24_25_bva_valid_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a670c-777f-492f-ad3d-aa80ad4bbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dva_24_25 = set(list(df_reg_24_25_bva_valid_columns[\"BadgeId\"].unique()))\n",
    "list_lva_24_25 = set(list(df_reg_24_25_lva_valid_columns[\"BadgeId\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c689a6d-7de2-4f54-8d1f-db105e3b59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vistor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52467e56-0d0b-4162-b233-49f39fcf0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"visit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd480ae1-baad-4e86-a8d1-37b3abf19659",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd552035-21d2-4e48-9629-32438306c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\n",
    "    \"Email\",\n",
    "    \"Email_domain\",\n",
    "    \"Company\",\n",
    "    \"JobTitle\",\n",
    "    \"Country\",\n",
    "    \"BadgeType\",\n",
    "    \"ShowRef\",\n",
    "    \"badgeid\",\n",
    "    \"Source\",\n",
    "    \"Days_since_registration\",\n",
    "    \"assist_year_before\",\n",
    "    \"BadgeId_last_year_bva\",\n",
    "    \"BadgeId_last_year_lva\",\n",
    "    \"what_type_does_your_practice_specialise_in\",\n",
    "    \"organisation_type\",\n",
    "    \"job_role\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07523c-08bf-4d0c-9563-4841d097fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.merge(df, data, on=[\"badgeid\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ef460-8895-4621-a208-a2f02d638807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv(\"data/bva/bva_pa_recomendations_with_demo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587347c2-fb8b-4069-8d2b-4b664dd076d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ad426-f142-47d9-9677-14e429e37cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graphdatascience import GraphDataScience\n",
    "\n",
    "# # Connect to Neo4j (Please update URI, USER and PASSWORD )\n",
    "# NEO4J_URI =  \"bolt://127.0.0.1:7687\"\n",
    "# USER = \"neo4j\"\n",
    "# PASSWORD = \"\"\n",
    "\n",
    "# # Connect to Neo4j\n",
    "# gds = GraphDataScience(NEO4J_URI, auth=(USER, PASSWORD))\n",
    "\n",
    "# # Check existing relationships\n",
    "# existing_rels = gds.run_cypher(\"CALL db.relationshipTypes()\")\n",
    "# print(\"Existing Relationship Types in database:\")\n",
    "# print(existing_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe379e-e3a2-4f5a-8098-e83c6e881e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adjust these variables exactly as they appear in the print statement above\n",
    "# SAME_PERSON_REL = \"Same_Visitor\"          # <-- adjust as per exact output\n",
    "# ATTENDED_SESSION_REL = \"attended_session\" # <-- adjust as per exact output\n",
    "# HAS_STREAM_REL = \"HAS_STREAM\"             # <-- adjust as per exact output\n",
    "\n",
    "# graph_name = \"visitor_session_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1bb865-0d13-468c-9688-0649dfcac27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the graph if previously exists\n",
    "# if gds.graph.exists(graph_name)[\"exists\"]:\n",
    "#     gds.graph.drop(graph_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019e41b-24e5-4345-bea9-ef5e1af36901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH (node:Label)\n",
    "# WHERE node.propertyName = \"Embeddings\"\n",
    "# MATCH (node:Visitor_last_year)\n",
    "# SET node.Embeddings = null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c441d5-c9b9-43d6-8546-d901369b4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-create graph with correctly adjusted relationship names\n",
    "# try:\n",
    "#     g, result = gds.graph.project(\n",
    "#         graph_name,\n",
    "#         ['Visitor_this_year'],\n",
    "#         {\n",
    "#             SAME_PERSON_REL: {'orientation': 'UNDIRECTED'},\n",
    "\n",
    "#         }\n",
    "#     )\n",
    "#     print(f\"Graph '{graph_name}' projected successfully:\")\n",
    "#     print(result)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"Failed to project graph:\")\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20afd6-8c2f-4bbe-b620-2a60364bd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEP 2 - FastRP Embeddings for each Node Type individually\n",
    "# EMBEDDING_SIZE = 128\n",
    "\n",
    "# # Function to generate embeddings\n",
    "# def generate_embeddings(label, embedding_property):\n",
    "#     result = gds.fastRP.write(\n",
    "#         g,\n",
    "#         embeddingDimension=EMBEDDING_SIZE,\n",
    "#         iterationWeights=[0.8, 1, 1, 1],\n",
    "#         nodeLabels=[label],\n",
    "#         writeProperty=embedding_property\n",
    "#     )\n",
    "#     print(f\"Embeddings created for nodes '{label}' written to property '{embedding_property}':\")\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368e978-7caf-48e3-a40b-357803f8545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visitor_last_year embeddings\n",
    "# generate_embeddings(\"Visitor_this_year\", \"Embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d5713-43eb-4ef2-9088-50450fb6bb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
