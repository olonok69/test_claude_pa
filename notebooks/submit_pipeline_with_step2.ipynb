{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3042fc6",
   "metadata": {},
   "source": [
    "# Azure ML Pipeline with Step 1 and Step 2\n",
    "\n",
    "This notebook creates and submits a pipeline with:\n",
    "1. Step 1: Data Preparation (Registration, Scan, Session)\n",
    "2. Step 2: Neo4J Preparation (Visitor, Session, Streams, Relationships)\n",
    "\n",
    "Based on the working Step 1 pipeline configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12c3e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 AZURE ML PIPELINE WITH NEO4J STEP\n",
      "============================================================\n",
      "✅ Environment variables loaded\n",
      "  • Workspace: strategicai-mlw-uks-dev-01\n",
      "  • Resource Group: strategicai-rg-uks-dev-01\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient, command, Input, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import ClientSecretCredential\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🚀 AZURE ML PIPELINE WITH NEO4J STEP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "client_id = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\")\n",
    "workspace_name = os.getenv(\"AZUREML_WORKSPACE_NAME\")\n",
    "\n",
    "print(\"✅ Environment variables loaded\")\n",
    "print(f\"  • Workspace: {workspace_name}\")\n",
    "print(f\"  • Resource Group: {resource_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58b4032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace: strategicai-mlw-uks-dev-01\n"
     ]
    }
   ],
   "source": [
    "# Create credential\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=tenant_id,\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret\n",
    ")\n",
    "\n",
    "# Initialize ML Client\n",
    "ml_client = MLClient(\n",
    "    credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name\n",
    ")\n",
    "\n",
    "print(f\"Connected to workspace: {workspace_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83007678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa\n"
     ]
    }
   ],
   "source": [
    "# Determine project root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f26ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing environment: pa-env:5\n",
      "Environment pa-env version 5 ready\n"
     ]
    }
   ],
   "source": [
    "# Setup environment directory\n",
    "dependencies_dir = \"./env\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)\n",
    "\n",
    "# Create or get environment\n",
    "custom_env_name = \"pa-env\"\n",
    "try:\n",
    "    # Try to get existing environment version 5\n",
    "    job_env = ml_client.environments.get(name=custom_env_name, version=\"5\")\n",
    "    env_version = job_env.version\n",
    "    print(f\"Using existing environment: {custom_env_name}:{env_version}\")\n",
    "except:\n",
    "    # Create new environment if not found\n",
    "    job_env = Environment(\n",
    "        name=custom_env_name,\n",
    "        description=\"Environment for Personal Agendas pipeline with Neo4j support\",\n",
    "        conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
    "        image=\"mcr.microsoft.com/azureml/openmpi5.0-ubuntu24.04:20250601.v1\",\n",
    "    )\n",
    "    job_env = ml_client.environments.create_or_update(job_env)\n",
    "    env_version = job_env.version\n",
    "    print(f\"Created environment: {custom_env_name}:{env_version}\")\n",
    "\n",
    "print(f\"Environment {job_env.name} version {job_env.version} ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07aeed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from notebooks folder\n",
      "Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa\n",
      "✓ PA directory found\n",
      "✓ azureml_pipeline directory found\n",
      "✓ Step 1 script found\n",
      "✓ Step 2 script found\n",
      "✓ config_ecomm.yaml found\n",
      "✓ config_vet.yaml found\n"
     ]
    }
   ],
   "source": [
    "# Verify local directory structure\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "    print(f\"Running from notebooks folder\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "    print(f\"Running from project root\")\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Check required directories\n",
    "pa_dir = project_root / \"PA\"\n",
    "if not pa_dir.exists():\n",
    "    print(f\"ERROR: PA directory not found at {pa_dir}\")\n",
    "else:\n",
    "    print(f\"✓ PA directory found\")\n",
    "\n",
    "pipeline_dir = project_root / \"azureml_pipeline\"\n",
    "if not pipeline_dir.exists():\n",
    "    print(f\"Creating azureml_pipeline directory\")\n",
    "    pipeline_dir.mkdir(exist_ok=True)\n",
    "else:\n",
    "    print(f\"✓ azureml_pipeline directory found\")\n",
    "\n",
    "# Check for step scripts\n",
    "step1_script = pipeline_dir / \"azureml_step1_data_prep.py\"\n",
    "step2_script = pipeline_dir / \"azureml_step2_neo4j_prep.py\"\n",
    "\n",
    "if not step1_script.exists():\n",
    "    print(f\"WARNING: Step 1 script not found at {step1_script}\")\n",
    "else:\n",
    "    print(f\"✓ Step 1 script found\")\n",
    "\n",
    "if not step2_script.exists():\n",
    "    print(f\"WARNING: Step 2 script not found at {step2_script}\")\n",
    "    print(f\"  Please ensure azureml_step2_neo4j_prep.py is in azureml_pipeline folder\")\n",
    "else:\n",
    "    print(f\"✓ Step 2 script found\")\n",
    "\n",
    "# Check config files\n",
    "config_vet = pa_dir / \"config\" / \"config_vet.yaml\"\n",
    "config_ecomm = pa_dir / \"config\" / \"config_ecomm.yaml\"\n",
    "\n",
    "if config_ecomm.exists():\n",
    "    print(f\"✓ config_ecomm.yaml found\")\n",
    "if config_vet.exists():\n",
    "    print(f\"✓ config_vet.yaml found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883dfba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Step 1: Data Preparation Component (NON-INCREMENTAL)\n",
    "data_preparation_component = command(\n",
    "    name=\"data_preparation\",\n",
    "    display_name=\"Step 1: Data Preparation\",\n",
    "    description=\"Process registration, scan, and session data\",\n",
    "    inputs={\n",
    "        \"input_uri\": Input(type=\"uri_folder\"),\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\")\n",
    "    },\n",
    "    outputs={\n",
    "        \"registration_output\": Output(type=\"uri_folder\"),\n",
    "        \"scan_output\": Output(type=\"uri_folder\"),\n",
    "        \"session_output\": Output(type=\"uri_folder\"),\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    # NO --incremental flag for standard processing\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step1_data_prep.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_uri ${{inputs.input_uri}} \\\n",
    "        --output_registration ${{outputs.registration_output}} \\\n",
    "        --output_scan ${{outputs.scan_output}} \\\n",
    "        --output_session ${{outputs.session_output}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables={\n",
    "        \"KEYVAULT_NAME\": \"strategicai-kv-uks-dev\"\n",
    "    },\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdfa487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Step 2: Neo4J Preparation Component (NON-INCREMENTAL)\n",
    "neo4j_preparation_component = command(\n",
    "    name=\"neo4j_preparation\",\n",
    "    display_name=\"Step 2: Neo4J Preparation\",\n",
    "    description=\"Upload data to Neo4j database - create all nodes and relationships\",\n",
    "    inputs={\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "        \"input_registration\": Input(type=\"uri_folder\"),\n",
    "        \"input_scan\": Input(type=\"uri_folder\"),\n",
    "        \"input_session\": Input(type=\"uri_folder\")\n",
    "    },\n",
    "    outputs={\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    # NO --incremental flag for standard processing (will recreate all nodes)\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step2_neo4j_prep.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_registration ${{inputs.input_registration}} \\\n",
    "        --input_scan ${{inputs.input_scan}} \\\n",
    "        --input_session ${{inputs.input_session}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables={\n",
    "        \"KEYVAULT_NAME\": \"strategicai-kv-uks-dev\"\n",
    "    },\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8bd44",
   "metadata": {},
   "source": [
    "### Alternative: Incremental Components\n",
    "\n",
    "If you need incremental processing, use these component definitions instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b96257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Incremental version of Step 1\n",
    "data_preparation_component_incremental = command(\n",
    "    name=\"data_preparation_incremental\",\n",
    "    display_name=\"Step 1: Data Preparation (Incremental)\",\n",
    "    description=\"Process registration, scan, and session data - incremental mode\",\n",
    "    inputs={\n",
    "        \"input_uri\": Input(type=\"uri_folder\"),\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\")\n",
    "    },\n",
    "    outputs={\n",
    "        \"registration_output\": Output(type=\"uri_folder\"),\n",
    "        \"scan_output\": Output(type=\"uri_folder\"),\n",
    "        \"session_output\": Output(type=\"uri_folder\"),\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step1_data_prep.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_uri ${{inputs.input_uri}} \\\n",
    "        --incremental \\\n",
    "        --output_registration ${{outputs.registration_output}} \\\n",
    "        --output_scan ${{outputs.scan_output}} \\\n",
    "        --output_session ${{outputs.session_output}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables={\n",
    "        \"KEYVAULT_NAME\": \"strategicai-kv-uks-dev\"\n",
    "    },\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")\n",
    "\n",
    "# OPTIONAL: Incremental version of Step 2\n",
    "neo4j_preparation_component_incremental = command(\n",
    "    name=\"neo4j_preparation_incremental\",\n",
    "    display_name=\"Step 2: Neo4J Preparation (Incremental)\",\n",
    "    description=\"Upload data to Neo4j - only add new nodes/relationships\",\n",
    "    inputs={\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "        \"input_registration\": Input(type=\"uri_folder\"),\n",
    "        \"input_scan\": Input(type=\"uri_folder\"),\n",
    "        \"input_session\": Input(type=\"uri_folder\")\n",
    "    },\n",
    "    outputs={\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step2_neo4j_prep.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --incremental \\\n",
    "        --input_registration ${{inputs.input_registration}} \\\n",
    "        --input_scan ${{inputs.input_scan}} \\\n",
    "        --input_session ${{inputs.input_session}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment=f\"{job_env.name}:{job_env.version}\",\n",
    "    environment_variables={\n",
    "        \"KEYVAULT_NAME\": \"strategicai-kv-uks-dev\"\n",
    "    },\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31012d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline (NON-INCREMENTAL VERSION)\n",
    "@pipeline(\n",
    "    compute=\"cpu-cluster\",\n",
    "    description=\"Personal Agendas pipeline with Neo4j preparation\",\n",
    ")\n",
    "def personal_agendas_pipeline(\n",
    "    pipeline_input_data: Input,\n",
    "    pipeline_config_type: str = \"ecomm\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Personal Agendas Pipeline\n",
    "    Step 1: Data Preparation (Registration, Scan, Session)\n",
    "    Step 2: Neo4J Preparation (Upload to database)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Data Preparation\n",
    "    step1 = data_preparation_component(\n",
    "        input_uri=pipeline_input_data,\n",
    "        config_type=pipeline_config_type\n",
    "    )\n",
    "    \n",
    "    # Step 2: Neo4J Preparation - uses outputs from Step 1\n",
    "    step2 = neo4j_preparation_component(\n",
    "        config_type=pipeline_config_type,\n",
    "        input_registration=step1.outputs.registration_output,\n",
    "        input_scan=step1.outputs.scan_output,\n",
    "        input_session=step1.outputs.session_output\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"registration_data\": step1.outputs.registration_output,\n",
    "        \"scan_data\": step1.outputs.scan_output,\n",
    "        \"session_data\": step1.outputs.session_output,\n",
    "        \"step1_metadata\": step1.outputs.metadata_output,\n",
    "        \"neo4j_metadata\": step2.outputs.metadata_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f66de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input data URI: azureml://subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01/datastores/landing_pa/paths/landing/azureml/\n"
     ]
    }
   ],
   "source": [
    "# Configure input data URI\n",
    "input_data_uri = f\"azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace_name}/datastores/landing_pa/paths/landing/azureml/\"\n",
    "\n",
    "print(f\"\\nInput data URI: {input_data_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb5b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline instance\n",
    "pipeline_job = personal_agendas_pipeline(\n",
    "    pipeline_input_data=Input(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=input_data_uri\n",
    "    ),\n",
    "    pipeline_config_type=\"ecomm\"\n",
    ")\n",
    "\n",
    "# Configure pipeline metadata\n",
    "pipeline_job.display_name = \"Personal Agendas Pipeline with Neo4j - ECOMM\"\n",
    "pipeline_job.tags = {\n",
    "    \"project\": \"personal_agendas\",\n",
    "    \"event_type\": \"ecomm\",\n",
    "    \"storage_fixed\": \"true\",\n",
    "    \"environment\": \"dev\",\n",
    "    \"includes_neo4j\": \"true\",\n",
    "    \"incremental\": \"false\"\n",
    "}\n",
    "pipeline_job.experiment_name = \"personal_agendas_neo4j_experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b61ab5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBMITTING PIPELINE WITH NEO4J\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading azure_ml_pipelines_pa (1.12 MBs): 100%|██████████| 1116165/1116165 [00:00<00:00, 1801987.74it/s]\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ SUCCESS! Pipeline submitted!\n",
      "\n",
      "📊 Job Details:\n",
      "  • Name: heroic_answer_nnt8bpnm2m\n",
      "  • Status: NotStarted\n",
      "  • Type: pipeline\n",
      "\n",
      "🔗 Monitor your pipeline at:\n",
      "  https://ml.azure.com/runs/heroic_answer_nnt8bpnm2m?wsid=/subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01&tid=3540e7dc-31b3-4057-9e31-43e9fe938179\n",
      "\n",
      "📋 Pipeline Steps:\n",
      "  Step 1: Data Preparation\n",
      "    - Registration processing\n",
      "    - Scan processing\n",
      "    - Session processing\n",
      "  Step 2: Neo4J Preparation\n",
      "    - Visitor nodes (this year, last year BVA/LVA)\n",
      "    - Session nodes and stream relationships\n",
      "    - Job to stream mappings\n",
      "    - Specialization to stream mappings\n",
      "    - Cross-year visitor relationships\n",
      "\n",
      "💡 Tips:\n",
      "  • Click the link above to watch pipeline progress\n",
      "  • Check 'Outputs + logs' for detailed execution logs\n",
      "  • Neo4j credentials loaded from Key Vault\n",
      "  • The first run may take longer due to environment setup\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Submit the pipeline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMITTING PIPELINE WITH NEO4J\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    submitted_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    \n",
    "    print(f\"\\n✅ SUCCESS! Pipeline submitted!\")\n",
    "    print(f\"\\n📊 Job Details:\")\n",
    "    print(f\"  • Name: {submitted_job.name}\")\n",
    "    print(f\"  • Status: {submitted_job.status}\")\n",
    "    print(f\"  • Type: {submitted_job.type}\")\n",
    "    print(f\"\\n🔗 Monitor your pipeline at:\")\n",
    "    print(f\"  {submitted_job.studio_url}\")\n",
    "    \n",
    "    print(\"\\n📋 Pipeline Steps:\")\n",
    "    print(\"  Step 1: Data Preparation\")\n",
    "    print(\"    - Registration processing\")\n",
    "    print(\"    - Scan processing\")\n",
    "    print(\"    - Session processing\")\n",
    "    print(\"  Step 2: Neo4J Preparation\")\n",
    "    print(\"    - Visitor nodes (this year, last year BVA/LVA)\")\n",
    "    print(\"    - Session nodes and stream relationships\")\n",
    "    print(\"    - Job to stream mappings\")\n",
    "    print(\"    - Specialization to stream mappings\")\n",
    "    print(\"    - Cross-year visitor relationships\")\n",
    "    \n",
    "    print(\"\\n💡 Tips:\")\n",
    "    print(\"  • Click the link above to watch pipeline progress\")\n",
    "    print(\"  • Check 'Outputs + logs' for detailed execution logs\")\n",
    "    print(\"  • Neo4j credentials loaded from Key Vault\")\n",
    "    print(\"  • The first run may take longer due to environment setup\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Submission failed: {str(e)}\")\n",
    "    print(\"\\n🔧 Troubleshooting:\")\n",
    "    \n",
    "    if \"AuthorizationFailure\" in str(e):\n",
    "        print(\"  Storage authorization issue. Try:\")\n",
    "        print(f\"  1. Run: az ml workspace sync-keys --resource-group {resource_group} --workspace-name {workspace_name}\")\n",
    "        print(\"  2. Wait 2 minutes and retry\")\n",
    "    elif \"compute\" in str(e).lower():\n",
    "        print(\"  Compute cluster issue. Check:\")\n",
    "        print(\"  1. Cluster 'cpu-cluster' exists\")\n",
    "        print(\"  2. Cluster is running (not stopped)\")\n",
    "        print(\"  3. You have permissions to use it\")\n",
    "    elif \"environment\" in str(e).lower():\n",
    "        print(\"  Environment issue. Ensure conda.yaml includes:\")\n",
    "        print(\"  - neo4j>=5.0.0\")\n",
    "        print(\"  - All other required packages\")\n",
    "    else:\n",
    "        print(\"  Check the error message above for details\")\n",
    "        print(\"  Verify all prerequisites are met\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5d6e4",
   "metadata": {},
   "source": [
    "## Monitor Pipeline Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67ccfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking pipeline status...\n",
      "\n",
      "Pipeline: heroic_answer_nnt8bpnm2m\n",
      "Status: Running\n",
      "\n",
      "To view detailed logs and outputs:\n",
      "  https://ml.azure.com/runs/heroic_answer_nnt8bpnm2m?wsid=/subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01&tid=3540e7dc-31b3-4057-9e31-43e9fe938179\n"
     ]
    }
   ],
   "source": [
    "# Optional: Check pipeline status after submission\n",
    "if 'submitted_job' in locals():\n",
    "    print(\"Checking pipeline status...\")\n",
    "    time.sleep(5)  # Wait a moment for job to initialize\n",
    "    \n",
    "    job = ml_client.jobs.get(submitted_job.name)\n",
    "    print(f\"\\nPipeline: {job.name}\")\n",
    "    print(f\"Status: {job.status}\")\n",
    "    print(f\"\\nTo view detailed logs and outputs:\")\n",
    "    print(f\"  {job.studio_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8210c4-6a7e-468f-a19a-8dec9a427969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
