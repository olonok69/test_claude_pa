{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a589082a-1a13-473d-8a51-acd6fdb82e03",
   "metadata": {
    "gather": {
     "logged": 1756838212865
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ FINAL PIPELINE SUBMISSION\n",
      "============================================================\n",
      "‚úÖ Checks completed:\n",
      "  ‚Ä¢ Storage keys synced\n",
      "  ‚Ä¢ Storage account verified: strategicaistuksdev02\n",
      "  ‚Ä¢ Service Principal has Storage Blob Data Contributor\n",
      "  ‚Ä¢ Default datastore confirmed: workspaceblobstore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient, command, Input, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import Environment\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import ClientSecretCredential\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ FINAL PIPELINE SUBMISSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "client_id = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\")\n",
    "workspace_name = os.getenv(\"AZUREML_WORKSPACE_NAME\")\n",
    "\n",
    "print(\"‚úÖ Checks completed:\")\n",
    "print(\"  ‚Ä¢ Storage keys synced\")\n",
    "print(\"  ‚Ä¢ Storage account verified: strategicaistuksdev02\")\n",
    "print(\"  ‚Ä¢ Service Principal has Storage Blob Data Contributor\")\n",
    "print(\"  ‚Ä¢ Default datastore confirmed: workspaceblobstore\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a27efd2-797c-47f8-87e4-45f7c817dd56",
   "metadata": {
    "gather": {
     "logged": 1756838213227
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace: strategicai-mlw-uks-dev-01\n"
     ]
    }
   ],
   "source": [
    "# Create credential\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=tenant_id,\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret\n",
    ")\n",
    "\n",
    "# Initialize ML Client\n",
    "ml_client = MLClient(\n",
    "    credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name\n",
    ")\n",
    "\n",
    "print(f\"Connected to workspace: {workspace_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eee8ce7-41c9-4c60-be48-019927026ccd",
   "metadata": {
    "gather": {
     "logged": 1756838213538
    }
   },
   "outputs": [],
   "source": [
    "# svc_pr_password = os.environ.get(\"AZURE_CLIENT_SECRET\")\n",
    "\n",
    "# svc_pr = ServicePrincipalAuthentication(\n",
    "#        tenant_id=os.environ.get(\"AZURE_TENANT_ID\"),\n",
    "#        service_principal_id=os.environ.get(\"AZURE_CLIENT_ID\"),\n",
    "#        service_principal_password=svc_pr_password,\n",
    "#        _enable_caching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94737f0-6d82-4db9-acd1-b6ac31ffc9e3",
   "metadata": {
    "gather": {
     "logged": 1756838213772
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa\n"
     ]
    }
   ],
   "source": [
    "# Determine project root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc94c36-4b1b-4c5d-8408-5501cdbb0745",
   "metadata": {
    "gather": {
     "logged": 1756838213997
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dependencies_dir = \"./env\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243856de",
   "metadata": {
    "gather": {
     "logged": 1756838221405
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment: pa-env:4\n",
      "Environment with name pa-env is registered to workspace, the environment version is 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create environment\n",
    "\n",
    "\n",
    "custom_env_name = \"pa-env\"\n",
    "try:\n",
    "    # Get latest version of environment\n",
    "    job_env = ml_client.environments.get(name=custom_env_name,version=\"4\")\n",
    "    env_version = job_env.version\n",
    "    print(f\"Created environment: {custom_env_name}:{env_version}\")\n",
    "except:\n",
    "    job_env = Environment(\n",
    "        name=custom_env_name,\n",
    "        description=\"Environment for Personal Agendas pipeline\",\n",
    "        conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi5.0-ubuntu24.04:20250601.v1\",\n",
    "    )\n",
    "    job_env = ml_client.environments.create_or_update(job_env)\n",
    "    env_version = job_env.version\n",
    "    print(f\"Created environment: {custom_env_name}:{env_version}\")\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {job_env.name} is registered to workspace, the environment version is {job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0984a7b1-34f7-47bf-a2c4-19cd757763b8",
   "metadata": {
    "gather": {
     "logged": 1756838221853
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from notebooks folder, using parent as project root\n",
      "Current working directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa/notebooks\n",
      "Project root: /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa\n",
      "‚úì PA directory found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa/PA\n",
      "‚úì azureml_pipeline directory found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-juan/code/Notebooks/repos/azure_ml_pipelines_pa/azureml_pipeline\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# Verify local directory structure\n",
    "# If running from notebooks/ folder, go up one level to project root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "    print(f\"Running from notebooks folder, using parent as project root\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "    print(f\"Running from project root directly\")\n",
    "\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Check if PA directory exists\n",
    "pa_dir = project_root / \"PA\"\n",
    "if not pa_dir.exists():\n",
    "    print(f\"ERROR: PA directory not found at {pa_dir}\")\n",
    "    print(\"Please ensure you're running from the correct directory\")\n",
    "else:\n",
    "    print(f\"‚úì PA directory found at {pa_dir}\")\n",
    "\n",
    "# Check if azureml_pipeline directory exists\n",
    "pipeline_dir = project_root / \"azureml_pipeline\"\n",
    "if not pipeline_dir.exists():\n",
    "    print(f\"Creating azureml_pipeline directory at {pipeline_dir}\")\n",
    "    pipeline_dir.mkdir(exist_ok=True)\n",
    "else:\n",
    "    print(f\"‚úì azureml_pipeline directory found at {pipeline_dir}\")\n",
    "\n",
    "# Check for config files\n",
    "config_vet = pa_dir / \"config\" / \"config_vet.yaml\"\n",
    "config_ecomm = pa_dir / \"config\" / \"config_ecomm.yaml\"\n",
    "\n",
    "if not config_vet.exists():\n",
    "    print(f\"WARNING: config_vet.yaml not found at {config_vet}\")\n",
    "if not config_ecomm.exists():\n",
    "    print(f\"WARNING: config_ecomm.yaml not found at {config_ecomm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc25273b",
   "metadata": {
    "gather": {
     "logged": 1756838222167
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define the data preparation component\n",
    "data_preparation_component = command(\n",
    "    name=\"data_preparation\",\n",
    "    display_name=\"Data Preparation - PA Pipeline\",\n",
    "    description=\"Process registration, scan, and session data\",\n",
    "    inputs={\n",
    "        \"input_uri\": Input(type=\"uri_folder\"),\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\")\n",
    "    },\n",
    "    outputs={\n",
    "        \"registration_output\": Output(type=\"uri_folder\"),\n",
    "        \"scan_output\": Output(type=\"uri_folder\"),\n",
    "        \"session_output\": Output(type=\"uri_folder\"),\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    # No --incremental flag, so it defaults to False\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step1_data_prep.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_uri ${{inputs.input_uri}} \\\n",
    "        --output_registration ${{outputs.registration_output}} \\\n",
    "        --output_scan ${{outputs.scan_output}} \\\n",
    "        --output_session ${{outputs.session_output}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment= f\"{job_env.name}:{job_env.version}\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")\n",
    "# include --incremental  to incremental version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33c1fa10-8a9f-48e8-9df3-130e3b6a251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Component with incremental support\n",
    "data_preparation_component_incremental = command(\n",
    "    name=\"data_preparation_incremental\",\n",
    "    display_name=\"Data Preparation - Incremental\",\n",
    "    description=\"Process registration, scan, and session data (incremental mode)\",\n",
    "    inputs={\n",
    "        \"input_uri\": Input(type=\"uri_folder\"),\n",
    "        \"config_type\": Input(type=\"string\", default=\"ecomm\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"registration_output\": Output(type=\"uri_folder\"),\n",
    "        \"scan_output\": Output(type=\"uri_folder\"),\n",
    "        \"session_output\": Output(type=\"uri_folder\"),\n",
    "        \"metadata_output\": Output(type=\"uri_folder\")\n",
    "    },\n",
    "    code=str(project_root),\n",
    "    # Add --incremental flag only when needed\n",
    "    command=\"\"\"python azureml_pipeline/azureml_step1_data_prep.py \\\n",
    "        --config PA/config/config_${{inputs.config_type}}.yaml \\\n",
    "        --input_uri ${{inputs.input_uri}} \\\n",
    "        --incremental \\\n",
    "        --output_registration ${{outputs.registration_output}} \\\n",
    "        --output_scan ${{outputs.scan_output}} \\\n",
    "        --output_session ${{outputs.session_output}} \\\n",
    "        --output_metadata ${{outputs.metadata_output}}\n",
    "    \"\"\",\n",
    "    environment= f\"{job_env.name}:{job_env.version}\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    is_deterministic=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797aa5a-d300-4c47-8cef-573e0081e293",
   "metadata": {},
   "source": [
    "# Alternative: \n",
    "\n",
    "Component with incremental support when incremental pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f68fac-e3df-480d-9b0d-9b7704ca6326",
   "metadata": {
    "gather": {
     "logged": 1756838222477
    }
   },
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    compute=\"cpu-cluster\",\n",
    "    description=\"Personal Agendas data processing pipeline\",\n",
    ")\n",
    "def personal_agendas_pipeline(\n",
    "    pipeline_input_data: Input,\n",
    "    pipeline_config_type: str = \"ecomm\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Personal Agendas Pipeline\n",
    "    Step 1: Data Preparation (Registration, Scan, Session)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Single component call - no conditionals\n",
    "    step1 = data_preparation_component(\n",
    "        input_uri=pipeline_input_data,\n",
    "        config_type=pipeline_config_type\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"registration_data\": step1.outputs.registration_output,\n",
    "        \"scan_data\": step1.outputs.scan_output,\n",
    "        \"session_data\": step1.outputs.session_output,\n",
    "        \"metadata\": step1.outputs.metadata_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f81059c7-aaff-42e8-a89d-7c43cc091b39",
   "metadata": {
    "gather": {
     "logged": 1756838222676
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input data URI: azureml://subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01/datastores/landing_pa/paths/landing/azureml/data/ecomm/\n"
     ]
    }
   ],
   "source": [
    "# Using the landing_pa datastore you have\n",
    "# \"azureml://subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01/datastores/landing_pa/paths/landing/azureml/\"\n",
    "input_data_uri = f\"azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace_name}/datastores/landing_pa/paths/landing/azureml/data/ecomm/\"\n",
    "#\"azureml://subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01/datastores/azureml_landing\"\n",
    "print(f\"\\nInput data URI: {input_data_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dd453eb",
   "metadata": {
    "gather": {
     "logged": 1756838222864
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input data URI: azureml://subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01/datastores/landing_pa/paths/landing/azureml/data/ecomm/\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nInput data URI: {input_data_uri}\")\n",
    "\n",
    "pipeline_job = personal_agendas_pipeline(\n",
    "    pipeline_input_data=Input(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=input_data_uri\n",
    "    ),\n",
    "    pipeline_config_type=\"ecomm\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Configure pipeline metadata\n",
    "pipeline_job.display_name = \"Personal Agendas Pipeline - ECOMM\"\n",
    "pipeline_job.tags = {\n",
    "    \"project\": \"personal_agendas\",\n",
    "    \"event_type\": \"ecomm\",\n",
    "    \"storage_fixed\": \"true\",\n",
    "    \"environment\": \"dev\"\n",
    "}\n",
    "pipeline_job.experiment_name = \"personal_agendas_experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01df2a29-8a87-475a-b0a6-417eac49daad",
   "metadata": {
    "gather": {
     "logged": 1756838238872
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBMITTING PIPELINE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SUCCESS! Pipeline submitted!\n",
      "\n",
      "üìä Job Details:\n",
      "  ‚Ä¢ Name: zen_raisin_zpfytcq3z8\n",
      "  ‚Ä¢ Status: NotStarted\n",
      "  ‚Ä¢ Type: pipeline\n",
      "\n",
      "üîó Monitor your pipeline at:\n",
      "  https://ml.azure.com/runs/zen_raisin_zpfytcq3z8?wsid=/subscriptions/b8d6d487-0bd2-4773-b318-12ab763ed178/resourcegroups/strategicai-rg-uks-dev-01/workspaces/strategicai-mlw-uks-dev-01&tid=3540e7dc-31b3-4057-9e31-43e9fe938179\n",
      "\n",
      "üí° Tips:\n",
      "  ‚Ä¢ Click the link above to watch the pipeline progress\n",
      "  ‚Ä¢ Check 'Outputs + logs' for detailed execution logs\n",
      "  ‚Ä¢ The first run may take longer due to environment setup\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Submit the pipeline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMITTING PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    submitted_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS! Pipeline submitted!\")\n",
    "    print(f\"\\nüìä Job Details:\")\n",
    "    print(f\"  ‚Ä¢ Name: {submitted_job.name}\")\n",
    "    print(f\"  ‚Ä¢ Status: {submitted_job.status}\")\n",
    "    print(f\"  ‚Ä¢ Type: {submitted_job.type}\")\n",
    "    print(f\"\\nüîó Monitor your pipeline at:\")\n",
    "    print(f\"  {submitted_job.studio_url}\")\n",
    "    \n",
    "    print(\"\\nüí° Tips:\")\n",
    "    print(\"  ‚Ä¢ Click the link above to watch the pipeline progress\")\n",
    "    print(\"  ‚Ä¢ Check 'Outputs + logs' for detailed execution logs\")\n",
    "    print(\"  ‚Ä¢ The first run may take longer due to environment setup\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Submission failed: {str(e)}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    \n",
    "    if \"AuthorizationFailure\" in str(e):\n",
    "        print(\"  Storage authorization issue still present. Try:\")\n",
    "        print(\"  1. Wait 2 more minutes and retry\")\n",
    "        print(\"  2. Run: az ml workspace sync-keys --resource-group {} --workspace-name {}\".format(resource_group, workspace_name))\n",
    "        print(\"  3. Use UserIdentityConfiguration instead (see previous examples)\")\n",
    "    elif \"compute\" in str(e).lower():\n",
    "        print(\"  Compute cluster issue. Check:\")\n",
    "        print(\"  1. Cluster 'cpu-cluster' exists\")\n",
    "        print(\"  2. Cluster is running (not stopped)\")\n",
    "        print(\"  3. You have permissions to use it\")\n",
    "    else:\n",
    "        print(\"  Check the error message above for details\")\n",
    "        print(\"  Verify all prerequisites are met\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28309f4d-5e7c-47a3-80f4-8d39c0eccf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
